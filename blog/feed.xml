<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title type="text">CC technical blog</title>
  <id>urn:uuid:cc6bc3c1-d0ad-365f-b7a6-1fcd73488c56</id>
  <updated>2020-08-26T00:00:00Z</updated>
  <link href="http://opensource.creativecommons.org/" />
  <link href="http://opensource.creativecommons.org/blog/feed.xml" rel="self" />
  <author>
    <name></name>
  </author>
  <generator uri="https://github.com/ajdavis/lektor-atom" version="0.3">Lektor Atom Plugin</generator>
  <entry xml:base="http://opensource.creativecommons.org/blog/entries/overview-of-the-gsoc-2020-project/">
    <title type="text">Overview of the GSoC 2020 Project</title>
    <id>urn:uuid:4cdfc111-c714-33e1-b521-390d487d46da</id>
    <updated>2020-08-26T00:00:00Z</updated>
    <link href="http://opensource.creativecommons.org/blog/entries/overview-of-the-gsoc-2020-project/" />
    <author>
      <name>charini</name>
    </author>
    <content type="html">&lt;p&gt;This is my final blog post under the &lt;a href=&quot;/blog/entries/overview-of-the-gsoc-2020-project/#series&quot;&gt;GSoC 2020: CC catalog&lt;/a&gt; series, where I will highlight and
summarize my contributions to Creative Commons (CC) as part of my GSoC project. The CC Catalog project collects and
stores CC licensed images scattered across the internet, such that they can be made accessible to the general public via
the &lt;a href=&quot;https://ccsearch.creativecommons.org/&quot;&gt;CC Search&lt;/a&gt; and &lt;a href=&quot;https://api.creativecommons.engineering/v1/&quot;&gt;CC Catalog API&lt;/a&gt; tools. I got the opportunity to work on different aspects of the
CC Catalog repository which ultimately enhances the user experience of the CC Search and CC Catalog API tools. My
primary contributions in the duration of GSoC, and the related pull requests (PR) are as follows.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Sub-provider retrieval&lt;/strong&gt;: The first task I completed as part of my GSoC project was the retrieval of sub-providers
(also known as &lt;em&gt;source&lt;/em&gt;) such that images could be categorised under these sources, ensuring an enhanced search
experience for the users. I completed the implementation of sub-provider retrieval for three providers; Flickr,
Europeana, and Smithsonian. If you are interested in learning how the retrieval logic works, please check my
&lt;a href=&quot;/blog/entries/flickr-sub-provider-retrieval/&quot;&gt;initial blog post&lt;/a&gt; of this series. The PRs related to this task are as follows.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;PR #&lt;a href=&quot;https://github.com/creativecommons/cccatalog/pull/420&quot;&gt;420&lt;/a&gt;: Retrieve sub-providers within Flickr&lt;/li&gt;
&lt;li&gt;PR #&lt;a href=&quot;https://github.com/creativecommons/cccatalog/pull/442&quot;&gt;442&lt;/a&gt;: Retrieve sub-providers within Europeana&lt;/li&gt;
&lt;li&gt;PR #&lt;a href=&quot;https://github.com/creativecommons/cccatalog/pull/455&quot;&gt;455&lt;/a&gt;: Retrieve sub-providers within Smithsonian&lt;/li&gt;
&lt;li&gt;PR #&lt;a href=&quot;https://github.com/creativecommons/cccatalog/pull/461&quot;&gt;461&lt;/a&gt;: Add new source as a sub-provider of Flickr&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Alert updates to Smithsonian unit codes&lt;/strong&gt;: For the Smithsonian provider, we rely on the field known as &lt;em&gt;unit code&lt;/em&gt;
to determine the sub-provider (for Smithsonian it is often a museum) each image belongs to. However, it is possible for
the &lt;em&gt;unit code&lt;/em&gt; values to change over time at the upstream, and if CC is unaware of these changes, it could hinder the
successful categorisation of Smithsonian images under unique sub-provider values. I have therefore introduced a
mechanism of alerting the CC code maintainers of potential changes to &lt;em&gt;unit code&lt;/em&gt; values at the upstream. More
information is provided in my &lt;a href=&quot;/blog/entries/smithsonian-unit-code-update/&quot;&gt;second blog post&lt;/a&gt; of this series. The PR related to this task
is #&lt;a href=&quot;https://github.com/creativecommons/cccatalog/pull/465&quot;&gt;465&lt;/a&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Improvements to the Smithsonian provider API script&lt;/strong&gt;: Smithsonian is an important provider which aggregates images
from 19 museums. However, due to the fact that the different museums have different data models and the resultant
incompatibility of the JSON responses returned from requests to the Smithsonian API, it is difficult to know which
fields to rely on to obtain the information necessary for CC. This results in CC missing out on certain important
information. As part of my GSoC project, I improved the completeness of &lt;em&gt;creator&lt;/em&gt; and &lt;em&gt;description&lt;/em&gt; information, by
identifying previously unknown fields from which these details could be retrieved. Even though my improvements did not
result in the identification of a comprehensive list of fields, the completeness of data was considerably improved for
some Smithsonian museums compared to how it was before. For more context about this issue please refer to the ticket
#&lt;a href=&quot;https://github.com/creativecommons/cccatalog/issues/397&quot;&gt;397&lt;/a&gt;. Apart from improving information of Smithsonian data, I was also able to identify issues with certain
Smithsonian API responses which did not contain mandatory information for some of the museums. We have informed the
Smithsonian technical team of these issues and they are highlighted in ticket #&lt;a href=&quot;https://github.com/creativecommons/cccatalog/issues/397&quot;&gt;397&lt;/a&gt; as well. The PRs related
to this task are as follows.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;PR #&lt;a href=&quot;https://github.com/creativecommons/cccatalog/pull/474&quot;&gt;474&lt;/a&gt;: Improve the creator and description information of the Smithsonian source &lt;em&gt;National Museum of
Natural History&lt;/em&gt; (NMNH). This is the largest museum (source) under the Smithsonian provider.&lt;/li&gt;
&lt;li&gt;PR #&lt;a href=&quot;https://github.com/creativecommons/cccatalog/pull/476&quot;&gt;476&lt;/a&gt;: Improve the &lt;em&gt;creator&lt;/em&gt; and &lt;em&gt;description&lt;/em&gt; information of other sources coming under the Smithsonian
provider.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Expiration of outdated images&lt;/strong&gt;: The final task I completed as part of my GSoC project was implementing a strategy
for expiring outdated images in the CC database. CC has a mechanism for keeping the images they have retrieved from
providers up-to-date, based on how old an image is. This is called the &lt;a href=&quot;/blog/entries/date-partitioned-data-reingestion/&quot;&gt;re-ingestion strategy&lt;/a&gt;,
where newer images are updated more frequently compared to older images. However, this re-ingestion strategy does not
detect images which have been deleted at the upstream. Thus, it is possible that some of the images stored in the CC
database are obsolete, which could result in broken links being presented via the &lt;a href=&quot;https://ccsearch.creativecommons.org/&quot;&gt;CC Search&lt;/a&gt; tool. As a
solution, I have implemented a mechanism of identifying whether images in the CC database are obsolete by looking at the
&lt;em&gt;updated_on&lt;/em&gt; column value of the CC image table. Depending on the re-ingestion strategy per provider, we can know what
the oldest &lt;em&gt;updated_on&lt;/em&gt; value, an image can assume. If the &lt;em&gt;updated_on&lt;/em&gt; value is older than the oldest valid value, we
flag the corresponding image record  as obsolete.  The PR related to this task is #&lt;a href=&quot;https://github.com/creativecommons/cccatalog/pull/483&quot;&gt;483&lt;/a&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;I will continue to take the responsibility for maintaining my code in the CC Catalog repository, and I hope to continue
contributing to the CC codebase. It has been a wonderful GSoC journey for me and special thanks goes to my supervisor
Brent for his guidance.&lt;/p&gt;
</content>
  </entry>
  <entry xml:base="http://opensource.creativecommons.org/blog/entries/automate-github-for-more-than-CI CD/">
    <title type="text">Automate GitHub for more than CI/CD</title>
    <id>urn:uuid:1f2b4dad-de07-33ab-b1c7-394778548e55</id>
    <updated>2020-08-26T00:00:00Z</updated>
    <link href="http://opensource.creativecommons.org/blog/entries/automate-github-for-more-than-CI CD/" />
    <author>
      <name>zackkrida</name>
    </author>
    <content type="html">&lt;blockquote&gt;&lt;p&gt;&lt;em&gt;Get started using GitHub bots and actions for community management and repository health.&lt;/em&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;In late 2018, in the midst of being acquired by Microsoft, GitHub &lt;a href=&quot;https://github.blog/2018-10-16-future-of-software/&quot;&gt;launched Github Actions&lt;/a&gt; into public beta, allowing users to run code on the popular development platform for the first time. With a straightforward &lt;code&gt;YAML&lt;/code&gt; configuration syntax and the power of Microsoft's Azure cloud, GitHub Actions quickly rose to compete with existing Continuous Integration (CI) and Continuous Deployment (CD) platforms like &lt;strong&gt;Circle CI&lt;/strong&gt; and &lt;strong&gt;Travis CI&lt;/strong&gt;. GitHub Actions made it easier than ever for developers to test and deploy software in the cloud, but from the beginning GitHub had bigger plans for the service.&lt;/p&gt;
&lt;p&gt;In a &lt;a href=&quot;https://techcrunch.com/2018/10/16/github-launches-actions-its-workflow-automation-tool/&quot;&gt;2018 TechCrunch interview&lt;/a&gt;, GitHub's then head of platform acknowledged the usefulness of actions for more than CI/CD. &quot;I see CI/CD as one narrow use case of actions. It‚Äôs so, so much more,‚Äù Lambert stressed. ‚ÄúAnd I think it‚Äôs going to revolutionize DevOps because people are now going to build best in breed deployment workflows for specific applications and frameworks, and those become the de facto standard shared on GitHub. [‚Ä¶] It‚Äôs going to do everything we did for open source again for the DevOps space and for all those different parts of that workflow ecosystem.&quot;&lt;/p&gt;
&lt;p&gt;At Creative Commons, we use Github Actions and Bots on many of &lt;a href=&quot;https://github.com/creativecommons?type=source&quot;&gt;our open-source projects&lt;/a&gt; for more than CI/CD‚Äîto manage our &lt;a href=&quot;/community/community-team/&quot;&gt;community team&lt;/a&gt;; to automate repository health; and to automate tedious but frequent tasks. The following examples are just a small snapshot of our existing and in-progress automations.&lt;/p&gt;
&lt;h2 id=&quot;example-automations&quot;&gt;Example automations&lt;/h2&gt;&lt;p&gt;&lt;!-- no toc --&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;/blog/entries/automate-github-for-more-than-CI CD/#automatic-release-note-generation&quot;&gt;Release note generation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;/blog/entries/automate-github-for-more-than-CI CD/#repository-normalization&quot;&gt;Repository normalization&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;/blog/entries/automate-github-for-more-than-CI CD/#automatic-dependency-updates&quot;&gt;Dependency updates&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&quot;release-note-generation&quot;&gt;Release note generation&lt;/h3&gt;&lt;p&gt;Our frontend Vue.js application for CC Search gets released weekly, and is subject to constant pull requests from myself, one-time volunteers making their first open source contribution, and long-term, dedicated community members who frequently contribute. It's important for us to highlight &lt;em&gt;all&lt;/em&gt; of these contributions in our release notes, regardless of size or scope. Additionally, we find it useful to group changes into categories, so our users have a clear sense of what kinds of updates we've made.&lt;/p&gt;
&lt;div style=&quot;text-align: center;&quot;&gt;
  &lt;figure class=&quot;margin-bottom-large&quot;&gt;
    &lt;img src=&quot;release-notes-screenshot.png&quot; alt=&quot;GitHub screenshot of release notes for CC Search&quot; /&gt;
    &lt;figcaption&gt;
      &lt;em&gt;
        An example of CC Search release notes generated by the &lt;a href=&quot;https://github.com/marketplace/actions/release-drafter&quot;&gt;Release Drafter&lt;/a&gt; GitHub Action.
      &lt;/em&gt;
    &lt;/figcaption&gt;
  &lt;/figure&gt;
&lt;/div&gt;&lt;p&gt;The quality of these release notes made them quite tedious to generate manually. With the &lt;a href=&quot;https://github.com/marketplace/actions/release-drafter&quot;&gt;release drafter action&lt;/a&gt;, we're able to automatically update a draft release note on every pull request to CC Search. The action lets us configure the line added for each pull request with some basic templating which includes variables for the pr number, title, and author (among others):&lt;/p&gt;
&lt;div class=&quot;hll&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;change-template&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&amp;#39;-&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;$TITLE:&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;#$NUMBER&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;by&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;@$AUTHOR&amp;#39;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;br /&gt;This means each pull request gets a line like this in our release notes:&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;Enable web monetization on single result pages: &lt;strong&gt;#1191&lt;/strong&gt; by &lt;strong&gt;@zackkrida&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Perfect! We can also map GitHub labels on our pull requests to the sections of our generated release notes, like so:&lt;/p&gt;
&lt;div class=&quot;hll&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;categories&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
  &lt;span class=&quot;p p-Indicator&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;title&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&amp;#39;New&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Features&amp;#39;&lt;/span&gt;
    &lt;span class=&quot;nt&quot;&gt;label&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&amp;#39;feature&amp;#39;&lt;/span&gt;
  &lt;span class=&quot;p p-Indicator&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;title&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&amp;#39;Bug&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Fixes&amp;#39;&lt;/span&gt;
    &lt;span class=&quot;nt&quot;&gt;label&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
      &lt;span class=&quot;p p-Indicator&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&amp;#39;bug&amp;#39;&lt;/span&gt;
      &lt;span class=&quot;p p-Indicator&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&amp;#39;critical&amp;#39;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;The resulting release notes require no manual editing at release time, and has saved us hours over time and allows our developers to focus on DevOps work instead of copywriting on release days. We also never miss a contribution or expression of gratitude to one of our contributors. You can read the &lt;a href=&quot;https://github.com/creativecommons/cccatalog-frontend/releases/latest&quot;&gt;latest CC Search release notes&lt;/a&gt; or &lt;a href=&quot;https://github.com/creativecommons/cccatalog-frontend/blob/develop/.github/release-drafter.yml&quot;&gt;see our full release-drafter.yml file here&lt;/a&gt;.&lt;/p&gt;
&lt;h3 id=&quot;repository-normalization&quot;&gt;Repository Normalization&lt;/h3&gt;&lt;p&gt;Within a private repository of internal helper scripts, the CC technical team has a number of Github Actions which trigger Python scripts to keep configuration standardized across our repositories. We casually call this process &quot;repository normalization&quot;. One such script ensures that we use a standard set of GitHub labels across all of our projects. This consistency helps us do things like direct users to &lt;a href=&quot;https://github.com/search?q=org%3Acreativecommons+label%3A%22help+wanted%22+state%3Aopen&amp;amp;type=Issues&quot;&gt;open issues in need of assistance&lt;/a&gt; across the organization, or issues &lt;a href=&quot;https://github.com/search?q=org%3Acreativecommons+label%3A%22good+first+issue%22+state%3Aopen&amp;amp;type=Issues&quot;&gt;good for first-time open source contributors&lt;/a&gt;. With GitHub Actions, its easy to set up scheduled tasks with only a few lines of human-readable configuration. Here's the gist of running a Python script daily, for example:&lt;/p&gt;
&lt;div class=&quot;hll&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;l l-Scalar l-Scalar-Plain&quot;&gt;Example scheduled python action&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;on&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;schedule&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
  &lt;span class=&quot;p p-Indicator&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;cron&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&amp;#39;0&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;*&amp;#39;&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;push&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;nt&quot;&gt;branches&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
      &lt;span class=&quot;p p-Indicator&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;l l-Scalar l-Scalar-Plain&quot;&gt;master&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;jobs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;build&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;nt&quot;&gt;runs-on&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;l l-Scalar l-Scalar-Plain&quot;&gt;ubuntu-latest&lt;/span&gt;
    &lt;span class=&quot;nt&quot;&gt;steps&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;p p-Indicator&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;uses&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;l l-Scalar l-Scalar-Plain&quot;&gt;actions/checkout@v2&lt;/span&gt;
    &lt;span class=&quot;p p-Indicator&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;l l-Scalar l-Scalar-Plain&quot;&gt;Set up Python 3.7&lt;/span&gt;
      &lt;span class=&quot;nt&quot;&gt;uses&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;l l-Scalar l-Scalar-Plain&quot;&gt;actions/setup-python@v1&lt;/span&gt;
      &lt;span class=&quot;nt&quot;&gt;with&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;nt&quot;&gt;python-version&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;l l-Scalar l-Scalar-Plain&quot;&gt;3.7&lt;/span&gt;
    &lt;span class=&quot;p p-Indicator&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;l l-Scalar l-Scalar-Plain&quot;&gt;Install dependencies&lt;/span&gt;
      &lt;span class=&quot;nt&quot;&gt;run&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;p p-Indicator&quot;&gt;|&lt;/span&gt;
        &lt;span class=&quot;no&quot;&gt;python -m pip install --upgrade pip&lt;/span&gt;
        &lt;span class=&quot;no&quot;&gt;python -m pip install pipenv&lt;/span&gt;
        &lt;span class=&quot;no&quot;&gt;pipenv install&lt;/span&gt;
    &lt;span class=&quot;p p-Indicator&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;l l-Scalar l-Scalar-Plain&quot;&gt;Export token to env and run our script&lt;/span&gt;
      &lt;span class=&quot;nt&quot;&gt;run&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;p p-Indicator&quot;&gt;|&lt;/span&gt;
        &lt;span class=&quot;no&quot;&gt;pipenv run python our-script.py&lt;/span&gt;
      &lt;span class=&quot;nt&quot;&gt;env&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;nt&quot;&gt;ADMIN_GITHUB_TOKEN&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;l l-Scalar l-Scalar-Plain&quot;&gt;${{ secrets.ADMIN_GITHUB_TOKEN }}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Internally and publicly, we use &lt;a href=&quot;https://github.com/orgs/creativecommons/projects&quot;&gt;GitHub Projects&lt;/a&gt; to manage our bi-weekly sprints and backlogs. The &lt;a href=&quot;https://github.com/subhamX/github-project-bot&quot;&gt;GitHub Project Bot&lt;/a&gt; action was built by &lt;a href=&quot;https://github.com/subhamX&quot;&gt;one of our community contributors&lt;/a&gt; and allows us to add pull requests to our project columns. Here's an example step in such a job:&lt;/p&gt;
&lt;div class=&quot;hll&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;p p-Indicator&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;l l-Scalar l-Scalar-Plain&quot;&gt;Handle cccatalog-frontend Repo&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;uses&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;l l-Scalar l-Scalar-Plain&quot;&gt;subhamX/github-project-bot@v1.0.0&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;with&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;nt&quot;&gt;ACCESS_TOKEN&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;l l-Scalar l-Scalar-Plain&quot;&gt;${{ secrets.ADMIN_GITHUB_TOKEN }}&lt;/span&gt;
    &lt;span class=&quot;nt&quot;&gt;COLUMN_NAME&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&amp;quot;In&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Progress&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;(Community)&amp;quot;&lt;/span&gt;
    &lt;span class=&quot;nt&quot;&gt;PROJECT_URL&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;l l-Scalar l-Scalar-Plain&quot;&gt;https://github.com/orgs/creativecommons/projects/7&lt;/span&gt;
    &lt;span class=&quot;nt&quot;&gt;REPO_URL&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;l l-Scalar l-Scalar-Plain&quot;&gt;https://github.com/creativecommons/cccatalog-frontend&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;We have additional scripts that sync our community team members across our open source website and GitHub, and several others that do even more of this cross-platform synchronization work. All of these scripts relive significant burden off of our engineering manager and open source community coordinator.&lt;/p&gt;
&lt;h3 id=&quot;dependency-updates&quot;&gt;Dependency Updates&lt;/h3&gt;&lt;p&gt;Modern JavaScript projects are built atop piles of 3rd party dependencies. This frees developers to focus on product code instead of writing the same utility code over and over again, but exposes projects to issues of security and dependency management. To help alleviate these issues, GitHub &lt;a href=&quot;https://github.blog/2019-05-23-introducing-new-ways-to-keep-your-code-secure/#automated-security-fixes-with-dependabot&quot;&gt;acquired a startup called Dependabot&lt;/a&gt; which initially focused on automatic security updates for repositories. Dependabot creates pull requests that update third-party code  with known security vulnerabilities to the latest safe and stable versions.&lt;/p&gt;
&lt;p&gt;This summer (June 2020), GitHub &lt;a href=&quot;https://github.blog/2020-06-01-keep-all-your-packages-up-to-date-with-dependabot/&quot;&gt;expanded dependabot's scope&lt;/a&gt; to keep &lt;em&gt;all&lt;/em&gt; third-party code up to date, regardless of security. By adding a &lt;code&gt;dependabot-config.yml&lt;/code&gt; file to any repo, developers no longer need to keep track of dependency updates on their own.&lt;/p&gt;
&lt;div style=&quot;text-align: center;&quot;&gt;
  &lt;figure class=&quot;margin-bottom-large&quot;&gt;
    &lt;img src=&quot;dependabot-example.png&quot; alt=&quot;GitHub screenshot of a Dependabot PR message&quot; /&gt;
    &lt;figcaption&gt;
      &lt;em&gt;
        Dependabot writes pull requests to bump JavaScript dependencies and will automatically resolve merge conflicts and keep the PR up to date.
      &lt;/em&gt;
    &lt;/figcaption&gt;
  &lt;/figure&gt;
&lt;/div&gt;&lt;p&gt;If your project has strong test coverage and a solid quality control process for release management, Dependabot pull requests can be made even more powerful with the &lt;a href=&quot;https://github.com/ridedott/merge-me-action&quot;&gt;Merge Me Action.&lt;/a&gt; Merge Me can be added to the end of any series of Github Actions to automatically merge pull requests that pass all CI tests which were authored by a particular user (the action assumes &lt;code&gt;dependabot&lt;/code&gt; by default). This means your repository can have highly-configurable, fully-automated dependency updates in just a few lines of &lt;code&gt;YAML&lt;/code&gt;.&lt;/p&gt;
&lt;h2 id=&quot;here-s-a-few-more&quot;&gt;Here's a few more&lt;/h2&gt;&lt;p&gt;Here's some smaller and simpler automations that can make a huge difference in your workflows.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;https://github.com/probot/stale&quot;&gt;Automatically close old PRs after a period of inactivity&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://github.blog/2020-08-24-automate-releases-and-more-with-the-new-sentry-release-github-action/&quot;&gt;Automate security releases on Sentry&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://github.com/probot/reminders&quot;&gt;Add reminders to issues and pull requests&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;These examples are a small sample of the non-CI/CD capabilities of GitHub Actions. You can peek in the &lt;code&gt;.github/&lt;/code&gt; directory of any of our open source repositories to see the actions we're using, and feel free to make an issue on any project if you have an idea for an automation of your own. As we increase the number and quality of integrations in our open source repositories, we may update this article or create follow-up posts with more examples.&lt;/p&gt;
&lt;p&gt;If you're interested in learning more about GitHub Actions, GitHub has a wonderful &lt;a href=&quot;https://github.com/marketplace?type=actions&quot;&gt;marketplace&lt;/a&gt; of avaliable actions you can explore, and the &lt;a href=&quot;https://docs.github.com/actions&quot;&gt;documentation for actions&lt;/a&gt; is avaliable in several languages.&lt;/p&gt;
</content>
  </entry>
  <entry xml:base="http://opensource.creativecommons.org/blog/entries/cc-catalog-wrapping-gsoc20/">
    <title type="text">CC Catalog: wrapping up GSoC20</title>
    <id>urn:uuid:ba947438-0d00-32ec-8ba7-acf6f5f15eb5</id>
    <updated>2020-08-25T00:00:00Z</updated>
    <link href="http://opensource.creativecommons.org/blog/entries/cc-catalog-wrapping-gsoc20/" />
    <author>
      <name>srinidhi</name>
    </author>
    <content type="html">&lt;p&gt;With the summer of code coming to an end, this blog post summarises the work done during the last three months. The project I have been working on is to add more provider API scripts to the CC Catalog. The CC Catalog project is responsible for collecting CC licensed images hosted across the web.&lt;/p&gt;
&lt;p&gt;The internship journey has been great , and I was glad to get the opportunity to understand more about the working of the data pipeline. My work during the internship mainly involved researching new API providers and checking if they meet the necessary conditions, then we decided on a strategy to crawl the API. The strategy varies according to different APIs:  some can be partitioned based on date, others have to be paginated . Script is written for the API according to the strategy. 
During the later phase of the internship, I had worked on the reingestion strategy for europeana and a script to merge Common Crawl tags and metadata to the corresponding image in the image table.&lt;/p&gt;
&lt;p&gt;Provider API implemented :&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Science Museum :  Science Museum collection has around 60,000 images and was initially crawled through Common Crawl and shifted to API based crawl. &lt;ul&gt;
&lt;li&gt;Issue: &lt;a href=&quot;https://github.com/creativecommons/cccatalog/issues/302&quot;&gt;Science Museum ticket&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Related PRs: &lt;a href=&quot;https://github.com/creativecommons/cccatalog/pull/400&quot;&gt;Science Museum script&lt;/a&gt;, &lt;a href=&quot;https://github.com/creativecommons/cccatalog/pull/411&quot;&gt;Science Museum workflow&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;ul&gt;
&lt;li&gt;Statens Museum : Statens Museum for Kunst is Denmark‚Äôs leading museum for artwork . This is a new integration and 39115 images have been collected.&lt;ul&gt;
&lt;li&gt;Issue: &lt;a href=&quot;https://github.com/creativecommons/cccatalog/issues/393&quot;&gt;Statens Museum ticket&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Related PRs: &lt;a href=&quot;https://github.com/creativecommons/cccatalog/pull/428&quot;&gt;Statens Museum implementation&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;ul&gt;
&lt;li&gt;Museums Victoria : It was initially ingested from Common Crawl later shifted to API based crawl. It has around 140,000 images.&lt;ul&gt;
&lt;li&gt;Issue: &lt;a href=&quot;https://github.com/creativecommons/cccatalog/issues/291&quot;&gt;Museums Victoria ticket&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Related PRs: &lt;a href=&quot;https://github.com/creativecommons/cccatalog/pull/447&quot;&gt;Museums Victoria implementation&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;ul&gt;
&lt;li&gt;NYPL : New York Public Library is a new integration , as of now it has around 1296 images.&lt;ul&gt;
&lt;li&gt;Issue: &lt;a href=&quot;https://github.com/creativecommons/cccatalog/issues/147&quot;&gt;NYPL ticket&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Related PRs: &lt;a href=&quot;https://github.com/creativecommons/cccatalog/pull/462&quot;&gt;NYPL implementation&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;ul&gt;
&lt;li&gt;Brooklyn Museum : This was an existing integration , changes were made to follow the new &lt;code&gt;ImageStore&lt;/code&gt; and &lt;code&gt;DelayedRequestor&lt;/code&gt; class , it has 61503 images.&lt;ul&gt;
&lt;li&gt;Issue: &lt;a href=&quot;https://github.com/creativecommons/cccatalog/issues/348&quot;&gt;Brooklyn Museum ticket&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Related PRs: &lt;a href=&quot;https://github.com/creativecommons/cccatalog/pull/355&quot;&gt;Brooklyn Museum implementation&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Iconfinder is a provider of icons that could not be integrated as the current strategy of ingestion is very slow and we need a better strategy.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Issue : &lt;a href=&quot;https://github.com/creativecommons/cccatalog/issues/396&quot;&gt;Iconfinder ticket&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;europeana-reingestion-strategy&quot;&gt;Europeana reingestion strategy&lt;/h2&gt;&lt;p&gt;Data collected from europeana was collected on a daily basis and there was a need to refresh it. The idea is that new data should be refreshed more frequently and as the data gets old, refreshing should become less frequent. While developing the strategy the API key limit and maximum collection expected is to be kept in mind. Considering these factors, a workflow was set up such that each day it crawls 59 days of data. 
The 59 days were split up into layers. The DAG crawls daily up to 1 week old data then it crawls monthly for data more than 1 week old and less than a year old data, anything older than a year is crawled every 3 months.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Issue: &lt;a href=&quot;https://github.com/creativecommons/cccatalog/issues/412&quot;&gt;Europeana reingestion ticket&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Related PR: &lt;a href=&quot;https://github.com/creativecommons/cccatalog/pull/473&quot;&gt;Europeana reingestion strategy&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;More details regarding the math of reingestion: &lt;a href=&quot;https://opensource.creativecommons.org/blog/entries/date-partitioned-data-reingestion/&quot;&gt;Data reingestion&lt;/a&gt;&lt;/p&gt;
&lt;div style=&quot;text-align:center;&quot;&gt;
    &lt;img src=&quot;dag_image_1.png&quot; width=&quot;1000px&quot;/&gt;
    &lt;img src=&quot;dag_image_2.png&quot; width=&quot;1000px&quot;/&gt;
    &lt;img src=&quot;dag_image_3.png&quot; width=&quot;1000px&quot;/&gt;
    &lt;p&gt;Europeana reingestion workflow&lt;/p&gt;
&lt;/div&gt;&lt;h2 id=&quot;merging-common-crawl-tags&quot;&gt;Merging Common Crawl tags&lt;/h2&gt;&lt;p&gt;When a provider is shifted from Common Crawl to API based crawl, the new data from API doesn‚Äôt have tags and metadata that were generated using clarifai and hence there is need to associate the new data with the tags corresponding to that image from the Common Crawl data. A direct url match is not possible as the Common Crawl urls and API image url are different, so we try to match it on the number or identifier that is associated with the url.&lt;/p&gt;
&lt;p&gt;Currently the merging logic is applied to Science Museum, Museums Victoria and Met Museum .&lt;/p&gt;
&lt;p&gt;In Science Museum, API url in image table is like &lt;a href=&quot;https://coimages.sciencemuseumgroup.org.uk/images/240/862/large_BAB_S_1_02_0017.jpg&quot;&gt;https://coimages.sciencemuseumgroup.org.uk/images/240/862/large_BAB_S_1_02_0017.jpg&lt;/a&gt; and CC url is like &lt;a href=&quot;https://s3-eu-west-1.amazonaws.com/smgco-images/images/369/541/medium_SMG00096855.jpg&quot;&gt;https://s3-eu-west-1.amazonaws.com/smgco-images/images/369/541/medium_SMG00096855.jpg&lt;/a&gt; . So the idea is to reduce the url to the last identifier like number , so after the modification of the url by modify_urls function it looks like &lt;code&gt;gpj.1700_20_1_S_BAB_&lt;/code&gt; (API url) and &lt;code&gt;gpj.55869000GMS_&lt;/code&gt; (CC url) .
Similar logic has been applied to met museum and museum victoria.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Issue: &lt;a href=&quot;https://github.com/creativecommons/cccatalog/issues/468&quot;&gt;https://github.com/creativecommons/cccatalog/issues/468&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Related PR: &lt;a href=&quot;https://github.com/creativecommons/cccatalog/pull/478&quot;&gt;https://github.com/creativecommons/cccatalog/pull/478&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;acknowledgement&quot;&gt;Acknowledgement&lt;/h2&gt;&lt;p&gt;I would like to thank my mentors Brent and Anna for their guidance throughout the internship.&lt;/p&gt;
</content>
  </entry>
  <entry xml:base="http://opensource.creativecommons.org/blog/entries/linked-commons-data-update/">
    <title type="text">Linked Commons: Data Update</title>
    <id>urn:uuid:bf2032b7-d1c2-320b-9cf1-92ad64320a02</id>
    <updated>2020-08-25T00:00:00Z</updated>
    <link href="http://opensource.creativecommons.org/blog/entries/linked-commons-data-update/" />
    <author>
      <name>subhamX</name>
    </author>
    <content type="html">&lt;p&gt;In this blog, I will be explaining the task we were working on for the last 3-4 weeks. It will take you on a journey of optimizations from million graph traversals in building the database to just a few traversals in the end. Also, we will be covering the new architecture for the upcoming version of the Linked Commons and the reason behind the change.&lt;/p&gt;
&lt;h2 id=&quot;where-does-it-fit?&quot;&gt;Where does it fit?&lt;/h2&gt;&lt;p&gt;So far the Linked Commons was using a tiny subset of the data available in the CC Catalog. One of the primary targets of our team was to update the data. If you observe closely all tasks so far starting from adding &quot;Graph Filtering Methods&quot; to &quot;Autocomplete Feature&quot;. These were actually bringing us closer towards this task. i.e. the much-awaited &lt;strong&gt;&quot;Scale the Data of Linked Commons&quot;&lt;/strong&gt;. We aim to add around &lt;strong&gt;235k nodes and 4.14 million links&lt;/strong&gt; into the Linked Commons project from around &lt;strong&gt;400 nodes and 500 links&lt;/strong&gt; in the current version. This drastic addition of new data is one of its kind, which makes this task very challenging and exciting.&lt;/p&gt;
&lt;h2 id=&quot;pilot&quot;&gt;Pilot&lt;/h2&gt;&lt;p&gt;The raw CC Catalog data cannot be used directly in the Linked Commons. Our first task involves processing it, which includes removing isolated nodes, etc. You can read more about it in the data processing series &lt;a href=&quot;https://opensource.creativecommons.org/blog/entries/cc-datacatalog-data-processing/&quot;&gt;blog&lt;/a&gt; written by my mentor Maria. After this, we need to build a database which stores the &lt;strong&gt;&quot;distance list&quot;&lt;/strong&gt; of all the nodes.&lt;/p&gt;
&lt;h3 id=&quot;what-is-distance-list-?&quot;&gt;What is &quot;distance list&quot;?&lt;/h3&gt;&lt;div style=&quot;text-align: center; width: 90%; margin-left: 5%;&quot;&gt;
    &lt;figure&gt;
        &lt;img src=&quot;distance-list.png&quot; alt=&quot;Distance List&quot; style=&quot;border: 1px solid black&quot;&gt;
        &lt;figcaption&gt;Distance list representation* of the node 'icij' part of a hypothetical graph&lt;/figcaption&gt;
    &lt;/figure&gt;
&lt;/div&gt;&lt;hr&gt;
&lt;p&gt;&lt;strong&gt;Distance List&lt;/strong&gt; is a method of graph representation. It is similar to &lt;a href=&quot;https://en.wikipedia.org/wiki/Adjacency_list&quot;&gt;Adjacency List&lt;/a&gt; representation of graphs but instead of storing data of just immediate neighbouring nodes, &quot;distance list&quot; groups all vertices based on their distance from the root node and stores this grouped data for every vertex in the graph. In short, &quot;distance list&quot; is a more general form of the Adjacency List representation.&lt;/p&gt;
&lt;p&gt;To build this &quot;distance list&quot;, we created a script for this, let‚Äôs name it &lt;strong&gt;build-dB-script.py&lt;/strong&gt;, which uses the &lt;a href=&quot;https://en.wikipedia.org/wiki/Breadth-first_search&quot;&gt;Breadth-First Search(BFS)&lt;/a&gt; algorithm on every node to traverse the graph and gradually build this distance list. The filtering nodes feature of our web page connects to the server, which uses the aforementioned database and serves a smaller chunk of data.&lt;/p&gt;
&lt;h2 id=&quot;problem&quot;&gt;Problem&lt;/h2&gt;&lt;p&gt;Now that we know where the &lt;em&gt;build-dB-script&lt;/em&gt; is used, let‚Äôs discuss the problems with it. The new graph data we are going to use is enormous and is in millions. A full traversal of a graph with million nodes, million times is very slow. Just to give some helpful numbers, the script was taking around 10 minutes to process a hundred nodes. Assuming the growth is linear(in the best case), it will take more than &lt;strong&gt;15 days&lt;/strong&gt; to complete the computations. &lt;strong&gt;It is scary, and thus, optimizations in the &lt;em&gt;build-dB-script&lt;/em&gt; are the need of the hour!!&lt;/strong&gt;&lt;/p&gt;
&lt;h2 id=&quot;optimizations&quot;&gt;Optimizations&lt;/h2&gt;&lt;p&gt;In this section, we will talk of the different versions of the build database script, starting from the brute force BFS method.&lt;/p&gt;
&lt;p&gt;The brute force BFS was the most simple and technically correct solution, but as the name suggests it was slow. In the next iteration, I stored the details of last n nodes, 10 to be precise and performed the same old BFS. It was faster but it had a logic error. Say, there is a link from a node to an already visited/traversed node. The script was not putting all the nodes which could have been explored from this path. After a few more leaps from Depth-first Search, to Breadth-first search, and other methods, eventually with the help of my mentors, we built a new approach - &lt;strong&gt;&quot;Sequential dB Build&quot;&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;To keep this blog short, I won‚Äôt be going too much into implementation details, but here are some of the critical points.&lt;/p&gt;
&lt;h3 id=&quot;key-points-of-the-sequential-db-build:&quot;&gt;Key points of the Sequential dB Build:&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;It was the fastest of all the predecessors and reduced the script timing significantly.&lt;/li&gt;
&lt;li&gt;In this approach, we aimed to build the all distance list of [1, 2, 3,... ., k-1] before building kth distance list.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Unfortunately, still, it was not enough for our current requirements. Just to give you some insights, the distance two list computation was taking around &lt;strong&gt;4 hours&lt;/strong&gt;, and &lt;strong&gt;distance three list&lt;/strong&gt; computation was taking &lt;strong&gt;20+ hours&lt;/strong&gt;. It shows that all these optimizations were not enough and were incapable of handling this big dataset.&lt;/p&gt;
&lt;h2 id=&quot;new-architecture&quot;&gt;New Architecture&lt;/h2&gt;&lt;p&gt;As the optimizations in &quot;build-dB-scripts&quot; weren‚Äôt enough, we started looking to simplify the current architecture. In the end, we want to have a viable product which is scalable to this massive data. Although we are still not dropping the multi-distance filtering, we will continue our research on it and hopefully will have it in &lt;strong&gt;Linked Commons 3.0&lt;/strong&gt;. üòé&lt;/p&gt;
&lt;p&gt;For any node, it is more likely that any person would wish to know the immediate neighbours who are linking to some arbitrary node. Nodes at a distance greater than one exhibits very less information on the reach and connectivity of the root node. It was because of this we decided to change our current logic of having the distance list up to 10; instead, we reduced it to 1 and also stored the immediate incomming nodes list (Nodes which are at distance 1 in the &lt;a href=&quot;https://en.wikipedia.org/wiki/Transpose_graph&quot;&gt;transpose graph&lt;/a&gt;).&lt;/p&gt;
&lt;p&gt;This small change in the design simplified a lot of things, and now the new graph build was taking around 2 minutes. By the time I am writing this blog we have upgraded our database from &lt;strong&gt;shelve to MongoDB&lt;/strong&gt; where the build time is further reduced. üî•üî•&lt;/p&gt;
&lt;div style=&quot;text-align: center; width: 90%; margin-left: 5%;&quot;&gt;
    &lt;figure&gt;
        &lt;img src=&quot;graph.png&quot; alt=&quot;Light Theme&quot; style=&quot;border: 1px solid black&quot;&gt;
        &lt;figcaption&gt;Graph showing neighbouring nodes. Incoming link are coloured with Turquoise and outgoing are coloured with Red.&lt;/figcaption&gt;
    &lt;/figure&gt;
&lt;/div&gt;&lt;h2 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h2&gt;&lt;p&gt;This task was really challenging and I learnt a lot. It was really mesmerizing to see the &lt;strong&gt;Linked Commons grow and evolve&lt;/strong&gt;. I hope you enjoyed reading this blog. You can follow the project development &lt;a href=&quot;https://github.com/creativecommons/cccatalog-dataviz/&quot;&gt;here&lt;/a&gt;, and access the stable version of linked commons &lt;a href=&quot;http://dataviz.creativecommons.engineering/&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Feel free to report bugs and suggest features. It will help us improve this project. If you wish to join the our team, consider joining our &lt;a href=&quot;https://creativecommons.slack.com/channels/cc-dev-cc-catalog-viz&quot;&gt;slack&lt;/a&gt; channel. Read more about our community teams &lt;a href=&quot;https://opensource.creativecommons.org/community/&quot;&gt;here&lt;/a&gt;. See you in my next blog! üöÄ&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;*&lt;em&gt;Linked Commons uses a more complex schema. The picture is just for illustration.&lt;/em&gt;&lt;/p&gt;
</content>
  </entry>
  <entry xml:base="http://opensource.creativecommons.org/blog/entries/2020-08-x5gon-cc-catalog-api/">
    <title type="text">X5GON Using CC Catalog API for Image Results</title>
    <id>urn:uuid:ffcc37e0-31ad-3231-b583-73749555ba0b</id>
    <updated>2020-08-24T00:00:00Z</updated>
    <link href="http://opensource.creativecommons.org/blog/entries/2020-08-x5gon-cc-catalog-api/" />
    <author>
      <name>annatuma</name>
    </author>
    <content type="html">&lt;p&gt;A few months ago, the Open Education team at Creative Commons made an introduction between the folks working on X5GON and CC Search.&lt;/p&gt;
&lt;p&gt;Throughout a few conversations, we quickly discovered that there are many parallels to how we're approaching our work, and some important differences that would allow each of us to benefit from cooperation.&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://www.x5gon.org/&quot;&gt;X5GON&lt;/a&gt; is building an AI-driven platform, focused on delivery of open education resources (OER). At its core, it is building a catalog of OER, upon which other &lt;a href=&quot;https://www.x5gon.org/platforms/services/&quot;&gt;services&lt;/a&gt; are based, such as analytics for personalized recommendations, and a discovery engine. By aggregating relevant content, curating it with the use of artificial intelligence and machine learning, and personalizing the experience to each learner, they're making OER more accessible and relevant.&lt;/p&gt;
&lt;p&gt;CC Search is not yet ready to ingest content types beyond images, but when we are able to do so, we plan to integrate via API with X5GON in order to serve OER that is made available in formats we will support in the future, starting with audio.&lt;/p&gt;
&lt;p&gt;The &lt;a href=&quot;https://discovery.x5gon.org/&quot;&gt;X5GON Discovery search engine&lt;/a&gt; allows users to find OER in video, audio, and text formats - and now, with the integration of results powered by the CC Catalog API, which also powers CC Search, users can also find openly licensed images for relevant educational queries. This is a great resource for educators and learners from all over the world.&lt;/p&gt;
&lt;p&gt;Try it for yourself, or look at these results for making &lt;a href=&quot;https://discovery.x5gon.org/search?q=geometry&amp;amp;type=Image&quot;&gt;geometry&lt;/a&gt; visual and fun!&lt;/p&gt;
</content>
  </entry>
  <entry xml:base="http://opensource.creativecommons.org/blog/entries/crawling-500-million/">
    <title type="text">How to politely crawl and analyze 500 million images</title>
    <id>urn:uuid:c4bde8a8-0a5d-324a-b450-571f43e3af02</id>
    <updated>2020-08-17T00:00:00Z</updated>
    <link href="http://opensource.creativecommons.org/blog/entries/crawling-500-million/" />
    <author>
      <name>aldenpage</name>
    </author>
    <content type="html">&lt;h4 id=&quot;background&quot;&gt;Background&lt;/h4&gt;&lt;p&gt;The goal of &lt;a href=&quot;https://search.creativecommons.org&quot;&gt;CC Search&lt;/a&gt; is to index all of the Creative Commons works on the internet, starting with images. We have indexed over 500 million images, which we believe is roughly 36% of all CC licensed content on the internet by &lt;a href=&quot;https://creativecommons.org/2018/05/08/state-of-the-commons-2017/&quot;&gt;our last count&lt;/a&gt;. To further enhance the usefulness of our search tool, we recently started crawling and analyzing images for improved search results. This article will discuss the process of taking a paper design for a large scale crawler, implementing it, and putting it in production, with a few idealized code snippets and diagrams along the way. The full source code can be viewed on &lt;a href=&quot;https://github.com/creativecommons/image-crawler&quot;&gt;GitHub&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Originally, when we discovered an image and inserted it into CC Search, we didn't even bother downloading it; we stuck the URL in our database and embedded the image in our search results. This approach has a lot of problems:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;We don't know the dimensions or compression quality of images, which is useful both for relevance purposes (de-ranking low  quality images) and for filtering. For example, some users are only interested in high resolution images and would like to exclude content below a certain size.&lt;/li&gt;
&lt;li&gt;We can't run any type of computer vision analysis on any of the images, which could be useful for enriching search metadata through object recognition.&lt;/li&gt;
&lt;li&gt;Embedding third party content is fraught with problems. What if the other party's server goes down, the images disappear due to link rot, or their TLS certificates expire? Each of these situations results in broken images appearing in the search results or browser alerts about degraded security.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;We solved (3) by setting up a &lt;a href=&quot;https://github.com/willnorris/imageproxy&quot;&gt;caching thumbnail proxy&lt;/a&gt; between images in the search results and their 3rd party origin, as well as some last-minute liveness checks to make sure that the image hasn't 404'd.&lt;/p&gt;
&lt;p&gt;(1) and (2), however, are not possible to solve without actually downloading the image and performing some analysis on the contents of the file. For us to reproduce the features that users take for granted in image search, we're going to need a fairly powerful crawling system.&lt;/p&gt;
&lt;p&gt;On the scale of several thousand images, it would be easy to cobble together a few scripts to spit out this information, but with half a billion images, there are a lot of hurdles to overcome.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;We want to crawl &lt;a href=&quot;https://en.wikipedia.org/wiki/Web_crawler#Politeness_policy&quot;&gt;politely&lt;/a&gt;; however, the concentration and quantity of images means that we have to hit some sources with a high crawl rate in order to have any hope of finishing the crawl in a reasonable period of time. Our data sources range from non-profit museums with a single staff IT person to tech companies with their own data centers and thousands of employees; the crawl rate has to be tailored to download quickly from the big players but not overwhelm small sources. At the same time, we need to be sure that we are not overestimating any source's capacity and watch for signs that our crawler is straining the server.&lt;/li&gt;
&lt;li&gt;We need to keep the time to process each image as low as possible to make it feasible to finish the crawling and analysis task in a reasonable period of time. This means that the crawling and analysis tasks need to be distributed to multiple machines in parallel.&lt;/li&gt;
&lt;li&gt;A lot of metadata will be produced by this crawler. The step of integrating it with our internal systems needs to not block resizing tasks. That suggests that a message bus will be necessary to buffer messages before they are written into our data layer, where writes can be expensive.&lt;/li&gt;
&lt;li&gt;We want to have a basic idea of how the crawl is progressing in the form of summaries of error counts, status codes, and crawl rates for each source.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;In summary, the challenge here isn't so much making a really fast crawler as much as it is tailoring the crawl speed to each source. At a minimum, we'll need to deal with concurrency and parallelism, provisioning and managing the life cycle of crawler infrastructure, pipelines for capturing output data, a way to monitor the progress of the crawl, a suite of tests to make sure the system behaves as expected, and a reliable way to enforce a &quot;politeness&quot; policy. That's not a trivial project, particularly for our tiny three person tech team (of which only one person is available to do all of the crawling work). Can't we just use an off-the-shelf open source crawler?&lt;/p&gt;
&lt;h4 id=&quot;what-about-existing-open-source-crawlers?&quot;&gt;What about existing open source crawlers?&lt;/h4&gt;&lt;p&gt;Any decent software engineer will consider existing options before diving into a project and reinventing the wheel. My assessment was that although there are a lot of open source crawling frameworks available, few of them focus on images, some are not actively maintained, and all would require extensive customization to meet the requirements of our crawl strategy. Further, many solutions are more complex than than our use case demands and would significantly expand our use of cloud infrastructure, resulting in higher expenses and more operational headaches. I experimented with Apache Nutch, Scrapy Cluster, and Frontera; none of the existing options looked quite right for our use case.&lt;/p&gt;
&lt;p&gt;As a reminder, we want to eventually crawl every single Creative Commons work on the internet. Effective crawling is central to the capabilities that our search engine is able to provide. In addition to being central to achieving high quality image search, crawling could also be useful for discovering new Creative Commons content of any type on any website. In my view, that's a strong argument for spending some time designing a custom crawling solution where we have complete end-to-end control of the process, as long as the feature set is limited in scope. In the next section, we'll assess the effort required to build a crawler from the ground up.&lt;/p&gt;
&lt;h4 id=&quot;designing-the-crawler&quot;&gt;Designing the crawler&lt;/h4&gt;&lt;p&gt;We know we're not going to be able to crawl 500 million images with one virtual machine and a single IP address, so it is obvious from the start that we are going to need a way to distribute the crawling and analysis tasks over multiple machines. A basic queue-worker architecture will do the job here; when we want to crawl an image, we can dispatch the URL to an inbound images queue, and a worker eventually pops that task out and processes it. Kafka will handle all of the hard work of partitioning and distributing the tasks between workers.&lt;/p&gt;
&lt;p&gt;The worker processes do the actual analysis of the images, which essentially entails downloading the image, extracting interesting properties, and sticking the resulting metadata back into a Kafka topic for later downstream processing. The worker will also have to include some instrumentation for conforming to rate limits and error reporting.&lt;/p&gt;
&lt;p&gt;We also know that we will need to share some information about crawl progress between worker processes, such as whether we've exceeded our prescribed rate limit for a website, the number of times we've seen a status code in the last minute, how many images we've processed so far, and so on. Since we're only interested in sharing application state and aggregate statistics, a lightweight key/value store like Redis seems like a good fit.&lt;/p&gt;
&lt;p&gt;Finally, we need a supervising process that centrally controls the crawl. This key governing process will be responsible for making sure our crawler workers are behaving properly by moderating crawl rates for each source, taking action in the face of errors, and reporting statistics to the operators of the crawler. We'll call this process the crawl monitor.&lt;/p&gt;
&lt;p&gt;Here's a rough sketch of how things will work:&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/blog/entries/crawling-500-million/image_crawler_simplified.png&quot; alt=&quot;Diagram&quot;&gt;&lt;/p&gt;
&lt;p&gt;At a high level, the problem of building a fast crawler seems solvable for our team, even on the scale of several hundred million images. If we can sustain a crawl and analysis rate of 200 images per second, we could crawl all 500 million images in about a month.&lt;/p&gt;
&lt;p&gt;In the next section, we'll examine some of the key components that make up the crawler.&lt;/p&gt;
&lt;h4 id=&quot;detailed-breakdown&quot;&gt;Detailed breakdown&lt;/h4&gt;&lt;h5 id=&quot;concurrency-with-asyncio&quot;&gt;Concurrency with &lt;code&gt;asyncio&lt;/code&gt;&lt;/h5&gt;&lt;p&gt;Crawling is a massively IO bound task. The workers need to maintain lots of simultaneous open connections with internal systems like Kafka and Redis as well as 3rd party websites holding the target images. Once we have the image in memory, performing our actual analysis task is easy and cheap. For these reasons, an asynchronous approach seems more attractive than using multiple threads of execution. Even if our image processing task grows in complexity and becomes CPU bound, we can get the best of both worlds by offloading heavyweight tasks to a process pool. See &quot;&lt;a href=&quot;https://docs.python.org/3/library/asyncio-dev.html#running-blocking-code&quot;&gt;Running Blocking Code&lt;/a&gt;&quot; in the &lt;code&gt;asyncio&lt;/code&gt; docs for more details.&lt;/p&gt;
&lt;p&gt;Another reason that an asynchronous approach may be desirable is that we have several interlocking components which need to react to events in real-time: our crawl monitoring process needs to simultaneously control the rate limiting process and also interrupt crawling if errors are detected, while our worker processes need to consume crawl events, process images, upload thumbnails, and produce events documenting the metadata of each image. Coordinating all of these components through inter-process communication could be difficult, but breaking up tasks into small pieces and yielding to the event loop is comparatively easy.&lt;/p&gt;
&lt;h5 id=&quot;the-resize-task&quot;&gt;The resize task&lt;/h5&gt;&lt;p&gt;This is the most vital part of our crawling system: the part that actually does the work of fetching and processing an image. As established previously, we need to execute this task concurrently, so everything needs to be defined with &lt;code&gt;async&lt;/code&gt;/&lt;code&gt;await&lt;/code&gt; syntax to allow the event loop to multitask. The actual task itself is otherwise straightforward.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Download the remote image and load it into memory.&lt;/li&gt;
&lt;li&gt;Extract the resolution and compression quality.&lt;/li&gt;
&lt;li&gt;Thumbnail the image for later computer vision analysis and upload it to S3.&lt;/li&gt;
&lt;li&gt;Write the information we've discovered to a Kafka topic.&lt;/li&gt;
&lt;li&gt;Report success/errors to Redis in aggregate.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;See &lt;a href=&quot;https://github.com/creativecommons/image-crawler/blob/master/worker/image.py&quot;&gt;image.py&lt;/a&gt; for the nitty-gritty details.&lt;/p&gt;
&lt;h4 id=&quot;rate-limiting-with-token-buckets-and-error-circuit-breakers&quot;&gt;Rate limiting with token buckets and error circuit breakers&lt;/h4&gt;&lt;h5 id=&quot;how-do-we-determine-the-rate-limit?&quot;&gt;How do we determine the rate limit?&lt;/h5&gt;&lt;p&gt;Often times, when designing highly concurrent software, the goal is to maximize the throughput and push servers to their absolute limit. The opposite is true with a web crawler, particularly when you are operating a non-profit organization completely reliant on the goodwill of others to exist. We want to be as certain as reasonably possible that we aren't going to knock a resource off of the internet with an accidental &lt;a href=&quot;https://en.wikipedia.org/wiki/Denial-of-service_attack&quot;&gt;DDoS&lt;/a&gt;. At the same time, we need to crawl as quickly as possible against sources with adequate resources to withstand a heavy crawl, or else we'll never finish. How can we match our crawl rate to a site's capabilities?&lt;/p&gt;
&lt;p&gt;Originally, my plan was to determine this through an adaptive rate limiting strategy, where we would start with a low rate limit and use a hill climbing algorithm to determine the optimal rate. We could track metrics like &lt;a href=&quot;https://en.wikipedia.org/wiki/Time_to_first_byte&quot;&gt;time to first byte&lt;/a&gt; (TTFB) and bandwidth speed to determine the exact moment that we have started to strain upstream servers. However, there are a lot of drawbacks here:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;It may not be correct to assume that performance will steadily degrade instead of failing all at once.&lt;/li&gt;
&lt;li&gt;We can't detect whether we are the cause of a performance issue or if the host is simply experiencing server trouble due to configuration errors or high traffic. We could get stuck at a suboptimal rate limit due to normal fluctuations in traffic.&lt;/li&gt;
&lt;li&gt;Recording TTFB in Python is difficult because it requires low level access to connection data. We might have to write an extension to &lt;code&gt;aiohttp&lt;/code&gt; to get it.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Eventually I decided that this is too much hassle. Can we get the job done with a simpler strategy?&lt;/p&gt;
&lt;p&gt;It turns out that the size of a website is typically correlated with infrastructure capabilities. The reasoning behind this is that if you are capable of hosting 450MM images, you are probably able to handle at least a couple hundred requests per second for serving traffic. In our case, we already know how many images a source has, so it's easy for us to peg our rate limit between a low minimum for small websites and a reasonable maximum for large websites, and then interpolate the rate limit for everything in between.&lt;/p&gt;
&lt;p&gt;Of course, it's important to note that this is only a rough heuristic that we use to make a reasonable guess about what a website can handle. We have to allow the possibility that we set our rate limit too aggressively in spite of our precautions.&lt;/p&gt;
&lt;h5 id=&quot;backing-off-with-circuit-breakers&quot;&gt;Backing off with circuit breakers&lt;/h5&gt;&lt;p&gt;If our heuristic fails to correctly approximate the bandwidth capabilities of a site, we are going to start encountering problems. For one, we might exceed the server-side rate limit, which means we will see &lt;code&gt;429 Rate Limit Exceeded&lt;/code&gt; and &lt;code&gt;403 Forbidden&lt;/code&gt; errors instead of the images we're trying to crawl. Worse yet, the upstream source might continue to happily serve requests while we suck up all of their traffic capacity, resulting in other users being unable to view the images. Clearly, in either scenario, we need to either reduce our crawl rate or even give up crawling the source entirely if it appears that we are impacting their uptime.&lt;/p&gt;
&lt;p&gt;To handle these situations, we have two tools in our toolbox: a sliding window recording the status code of every request made we've made to each domain in the last 60 seconds, and a list of the last 50 statuses for each website. If the number of errors in our one minute window exceed 10%, something is wrong; we should wait a minute before trying again. If we have encountered many errors in a row, however, that suggests that we're having trouble with a particular site, so we ought to give up crawling the source and raise an alert.&lt;/p&gt;
&lt;p&gt;Workers can keep track of this information in sorted sets in Redis. For the sliding error window, we'll sort each request by its timestamp, which will make it easy and cheap for us to expire status codes beyond the sliding window interval. Maintaining a list of the last N response codes is even easier; we just stick the status code in a list associated with the source.&lt;/p&gt;
&lt;div class=&quot;hll&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;StatsManager&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;fm&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;redis&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;redis&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;redis&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;known_sources&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;set&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;

    &lt;span class=&quot;nd&quot;&gt;@staticmethod&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;async&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;_record_window_samples&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pipe&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;source&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;status&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;sd&quot;&gt;&amp;quot;&amp;quot;&amp;quot; Insert a status into all sliding windows. &amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;now&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;time&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;monotonic&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
        &lt;span class=&quot;c1&quot;&gt;# Time-based sliding windows&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;stat_key&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;interval&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;WINDOW_PAIRS&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;key&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;stat_key&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;source&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;await&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pipe&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;zadd&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;key&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;now&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;status&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;time&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;monotonic&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
            &lt;span class=&quot;c1&quot;&gt;# Delete events from outside the window&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;await&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pipe&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;zremrangebyscore&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;key&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&amp;#39;-inf&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;now&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;interval&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;c1&quot;&gt;# &amp;quot;Last n requests&amp;quot; window&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;await&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pipe&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;rpush&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;LAST_50_REQUESTS&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;source&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;status&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;await&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pipe&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ltrim&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;LAST_50_REQUESTS&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;source&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;50&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;em&gt;&lt;center&gt;Collecting status codes in aggregate&lt;/center&gt;&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Meanwhile, the crawl monitor process can keep tabs on the contents of each error threshold.&lt;/p&gt;
&lt;p&gt;When more than 10% of the requests made to a source in the last minute are errors, we'll set a halt condition in Redis and stop replenishing rate limit tokens (more on that below).&lt;/p&gt;
&lt;div class=&quot;hll&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;now&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;time&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;monotonic&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;one_minute_window&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;await&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;redis&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;zrangebyscore&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;one_minute_window_key&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&amp;#39;-inf&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;now&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;60&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;errors&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;success&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;status&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;one_minute_window&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;status&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;not&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;EXPECTED_STATUSES&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;errors&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;successful&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;tolerance&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ERROR_TOLERANCE_PERCENT&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;100&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;not&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;successful&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;or&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;errors&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;successful&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tolerance&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;await&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;redis&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sadd&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;TEMP_HALTED_SET&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;source&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;em&gt;&lt;center&gt;Detecting elevated crawl errors for a source&lt;/center&gt;&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;For detecting &quot;serious&quot; errors, where we've seen 50 failed requests in a row, we'll set a permanent halt condition. Someone will have to manually troubleshoot the situation and switch the crawler back on for that source.&lt;/p&gt;
&lt;div class=&quot;hll&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;last_50_statuses_key&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;statuslast50req:&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;source&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;last_50_statuses&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;await&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;redis&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;lrange&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;last_50_statuses_key&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;last_50_statuses&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;50&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;and&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;_every_request_failed&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;last_50_statuses&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;await&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;redis&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sadd&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;HALTED_SET&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;source&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;em&gt;&lt;center&gt;Detecting persistent crawl errors&lt;/center&gt;&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;In practice, keeping a sliding window for tracking error thresholds and setting reasonable minimum and maximum crawl rates has worked well enough that the circuit breaker has never been tripped.&lt;/p&gt;
&lt;h5 id=&quot;enforcing-rate-limits-with-token-buckets&quot;&gt;Enforcing rate limits with token buckets&lt;/h5&gt;&lt;p&gt;It's one thing to set a policy for crawling; it's another thing entirely to actually enforce it. How can we coordinate our multiple crawling processes to prevent them from overstepping our rate limit?&lt;/p&gt;
&lt;p&gt;The answer is to implement a distributed token bucket system. The idea behind this is that each crawler has to obtain a token from Redis before making a request. Every second, the crawl monitor sets a variable containing the number of requests that can be made against a source. Each crawler process decrements the counter before making a request. If the decremented result is above zero, the worker is cleared to crawl. Otherwise, the rate limit has been reached and we should wait until a token has been obtained.&lt;/p&gt;
&lt;p&gt;The beauty of token buckets is their simplicity, performance, and resilience against failure. If our crawler monitor process dies, crawling halts completely; making a request is not possible without first acquiring a token. This is a much better alternative to the guard rails completely disappearing with the crawl monitor and allowing unbounded crawling. Further, since decrementing a counter and retrieving the result is an atomic operation in Redis, there's no risk of race conditions and therefore no need for locking. This is a huge boon for performance, as the overhead of coordinating and blocking on every single request would rapidly bog down our crawling system.&lt;/p&gt;
&lt;p&gt;To ensure that all crawling is performed at the correct speed, I wrapped &lt;code&gt;aiohttp.ClientSession&lt;/code&gt; with a rate limited version of the class.&lt;/p&gt;
&lt;div class=&quot;hll&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;RateLimitedClientSession&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;fm&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;aioclient&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;redis&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;client&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;aioclient&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;redis&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;redis&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;async&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;_get_token&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;source&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;token_key&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;CURRTOKEN_PREFIX&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;source&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;tokens&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;int&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;await&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;redis&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;decr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;token_key&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tokens&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;token_acquired&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;kc&quot;&gt;True&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;c1&quot;&gt;# Out of tokens&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;await&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;asyncio&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sleep&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;token_acquired&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;kc&quot;&gt;False&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;token_acquired&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;async&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;get&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;url&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;source&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;token_acquired&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;kc&quot;&gt;False&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;while&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;not&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;token_acquired&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;token_acquired&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;await&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;_get_token&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;source&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;await&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;client&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;get&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;url&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Meanwhile, the crawl monitor process is filling up each bucket every second.&lt;/p&gt;
&lt;h5 id=&quot;scheduling-tasks-somewhat-intelligently&quot;&gt;Scheduling tasks (somewhat) intelligently&lt;/h5&gt;&lt;p&gt;The final gotcha in the design of our crawler is that we want to crawl every single website at the same time at its prescribed rate limit. That sounds almost tautological, like something that we should be able to take for granted after implementing all of this logic for preventing our crawler from working too quickly, but it turns out our crawler's processing capacity itself is a limited and contentious resource. We can only schedule so many tasks simultaneously on each worker, and we need to ensure that tasks from a single website aren't starving other sources of crawl capacity.&lt;/p&gt;
&lt;p&gt;For instance, imagine that each worker is able to handle 5000 simultaneous crawling tasks, and every one of those tasks is tied to a tiny website with a very low rate limit. That means that our entire worker, which is capable of handling hundreds of crawl and analysis jobs per second, is stuck making one request per second until some faster tasks appear in the queue.&lt;/p&gt;
&lt;p&gt;In other words, we need to make sure that each worker process isn't jamming itself up with a single source. We have a &lt;a href=&quot;https://en.wikipedia.org/wiki/Scheduling_(computing%29&quot;&gt;scheduling problem&lt;/a&gt;. We've naively implemented first-come-first-serve and need to switch to a different scheduling strategy.&lt;/p&gt;
&lt;p&gt;There are innumerable ways to address scheduling problems. Since there are only a few dozen sources in our system, we can get away with using a stupid scheduling algorithm: give each source equal capacity in every worker. In other words, if there are 5000 tasks to distribute and 30 sources, we can allocate 166 simultaneous tasks to each source per worker. That's plenty for our purposes. There are obvious drawbacks of this approach in that eventually there will be so many sources that we start starving high rate limit sources of work. We'll cross that bridge when we come to it; it's better to use the simplest possible approach we can get away with instead of spending all of our time on solving hypothetical future problems.&lt;/p&gt;
&lt;div class=&quot;hll&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;    &lt;span class=&quot;k&quot;&gt;async&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;_schedule&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;task_schedule&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;raw_sources&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;await&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;redis&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;smembers&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;inbound_sources&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;sources&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&amp;#39;utf-8&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;raw_sources&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;num_sources&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sources&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;c1&quot;&gt;# A source never gets more than 1/4th of the worker&amp;#39;s capacity. This&lt;/span&gt;
        &lt;span class=&quot;c1&quot;&gt;# helps prevent starvation of lower rate limit requests and ensures&lt;/span&gt;
        &lt;span class=&quot;c1&quot;&gt;# that the first few sources to be discovered don&amp;#39;t get all of the&lt;/span&gt;
        &lt;span class=&quot;c1&quot;&gt;# initial task slots.&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;max_share&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;settings&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;MAX_TASKS&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;share&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;min&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;math&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;floor&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;settings&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;MAX_TASKS&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;num_sources&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;max_share&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;to_schedule&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{}&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;source&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sources&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;num_unfinished&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;_get_unfinished_tasks&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;task_schedule&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;source&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;num_to_schedule&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;share&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;num_unfinished&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;consumer&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;_get_consumer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;source&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;source_msgs&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;_consume_n&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;consumer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;num_to_schedule&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;to_schedule&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;source&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;source_msgs&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;to_schedule&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;em&gt;&lt;center&gt;Scheduling tasks for every source&lt;/center&gt;&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;The one implementation detail to deal with here is that our workers can't draw from a single inbound images queue anymore; we need to partition each source into its own queue so we can pull tasks from each source when we need it. This partitioning process can be handled transparently by the crawl monitor.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/blog/entries/crawling-500-million/image_crawler.png&quot; alt=&quot;A more complete diagram&quot;&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;&lt;center&gt;A more complete diagram showing the system with a queue for each source&lt;/center&gt;&lt;/em&gt;&lt;/p&gt;
&lt;h5 id=&quot;designing-for-testability&quot;&gt;Designing for testability&lt;/h5&gt;&lt;p&gt;It's quite difficult to test IO-heavy systems because of their need to interact with lots of external dependencies. Often times it is necessary to write complex integration tests or run manual tests to be certain that key functionality works as expected. This is no good because integration tests are much more expensive to maintain and take far longer to execute. We certainly wouldn't go to production without running a smoke test to verify correctness in real-world conditions, but it's still critical to have unit tests in place for catching bugs quickly during the development process.&lt;/p&gt;
&lt;p&gt;The solution to this problem is to use dependency injection, which is a fancy way of saying that we never do IO directly from within our application. Instead, we delegate IO to external objects that can be passed in at run-time. This makes it easy to pass in fake objects that approximate real world behavior without real world consequences.&lt;/p&gt;
&lt;p&gt;For example, the crawl monitor usually has to talk to our CC Search API (for assessing source size), Redis, and Kafka to do its job of regulating the crawl; instead of setting up a brittle and complicated integration test with all of those dependencies, we just instantiate some mock objects and pass them in. Now we can easily test individual components such as the error circuit breaker.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;&lt;center&gt;Testing our crawl monitor's circuit breaking functionality with mock dependencies&lt;/center&gt;&lt;/em&gt;&lt;/p&gt;
&lt;div class=&quot;hll&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;nd&quot;&gt;@pytest&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fixture&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;source_fixture&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;():&lt;/span&gt;
    &lt;span class=&quot;sd&quot;&gt;&amp;quot;&amp;quot;&amp;quot; Mocks the /v1/sources endpoint response. &amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;
        &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
            &lt;span class=&quot;s2&quot;&gt;&amp;quot;source_name&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&amp;quot;example&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
            &lt;span class=&quot;s2&quot;&gt;&amp;quot;image_count&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;5000000&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
            &lt;span class=&quot;s2&quot;&gt;&amp;quot;display_name&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&amp;quot;Example&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
            &lt;span class=&quot;s2&quot;&gt;&amp;quot;source_url&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&amp;quot;example.com&amp;quot;&lt;/span&gt;
        &lt;span class=&quot;p&quot;&gt;},&lt;/span&gt;
        &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
            &lt;span class=&quot;s2&quot;&gt;&amp;quot;source_name&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&amp;quot;another&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
            &lt;span class=&quot;s2&quot;&gt;&amp;quot;image_count&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1000000&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
            &lt;span class=&quot;s2&quot;&gt;&amp;quot;display_name&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&amp;quot;Another&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
            &lt;span class=&quot;s2&quot;&gt;&amp;quot;source_url&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&amp;quot;whatever&amp;quot;&lt;/span&gt;
        &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;


&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;create_mock_monitor&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sources&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;response&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;FakeAioResponse&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;status&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;200&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;body&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sources&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;session&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;FakeAioSession&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;response&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;response&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;redis&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;FakeRedis&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;regulator_task&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;asyncio&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;create_task&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;rate_limit_regulator&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;session&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;redis&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;redis&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;regulator_task&lt;/span&gt;


&lt;span class=&quot;nd&quot;&gt;@pytest&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mark&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;asyncio&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;async&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;test_error_circuit_breaker&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;source_fixture&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;sources&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;source_fixture&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;redis&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;monitor&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;create_mock_monitor&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sources&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;redis&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;store&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;statuslast50req:example&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;500&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;50&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;redis&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;store&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;statuslast50req:another&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;200&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;50&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;await&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;run_monitor&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;monitor_task&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;assert&lt;/span&gt; &lt;span class=&quot;sa&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;example&amp;#39;&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;redis&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;store&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;halted&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;assert&lt;/span&gt; &lt;span class=&quot;sa&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;another&amp;#39;&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;not&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;redis&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;store&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;halted&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;The main drawback of dependency injection is that initializing your objects will take some more ceremony. See the &lt;a href=&quot;https://github.com/creativecommons/image-crawler/blob/00b59aba9a15faccf203a53d73a98e8c06cb69e8/worker/scheduler.py#L162&quot;&gt;initialization of the crawl scheduler&lt;/a&gt; for an example of wiring up an object with a lot of dependencies. You might also find that constructors and other functions with a lot of dependencies will have a lot of arguments if care isn't taken to bundle external dependencies together. In my opinion, the price of a few extra lines of initialization code is well worth the benefits gained from testability and modularity.&lt;/p&gt;
&lt;h4 id=&quot;smoke-testing&quot;&gt;Smoke testing&lt;/h4&gt;&lt;p&gt;Even with our unit test coverage, we still need to do some basic small-scale manual tests to make sure our assumptions hold up in the real world. We'll need to write &lt;a href=&quot;https://www.terraform.io/&quot;&gt;Terraform&lt;/a&gt; modules that provision a working version of the real system. Sadly, our Terraform infrastructure repository is private for now, but here's a taste of what the infra code looks like.&lt;/p&gt;
&lt;div class=&quot;hll&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;kr&quot;&gt;module&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&amp;quot;image-crawler&amp;quot;&lt;/span&gt; &lt;span class=&quot; -Punctuation&quot;&gt;{&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;  source&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&amp;quot;../../modules/services/image-crawler&amp;quot;&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;  environment&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&amp;quot;prod&amp;quot;&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;  docker_tag&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&amp;quot;0.25.0&amp;quot;&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;  aws_access_key_id&lt;/span&gt;     &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&amp;quot;${var.aws_access_key_id}&amp;quot;&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;  aws_secret_access_key&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&amp;quot;${var.aws_secret_access_key}&amp;quot;&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;  zookeeper_endpoint&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&amp;quot;${module.kafka.zookeeper_brokers}&amp;quot;&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;  kafka_brokers&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&amp;quot;${module.kafka.kafka_brokers}&amp;quot;&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;  worker_instance_type&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&amp;quot;m5.large&amp;quot;&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;  worker_count&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;5&lt;/span&gt;
&lt;span class=&quot; -Punctuation&quot;&gt;}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;em&gt;&lt;center&gt;Initialization of crawler Terraform module in our production environment&lt;/center&gt;&lt;/em&gt;&lt;/p&gt;
&lt;div class=&quot;hll&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;kr&quot;&gt;resource&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&amp;quot;aws_instance&amp;quot; &amp;quot;crawler-workers&amp;quot;&lt;/span&gt; &lt;span class=&quot; -Punctuation&quot;&gt;{&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;  ami&lt;/span&gt;                     &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&amp;quot;${var.ami}&amp;quot;&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;  instance_type&lt;/span&gt;           &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&amp;quot;${var.worker_instance_type}&amp;quot;&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;  user_data&lt;/span&gt;               &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&amp;quot;${data.template_file.worker_init.rendered}&amp;quot;&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;  subnet_id&lt;/span&gt;               &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&amp;quot;${element(data.aws_subnet_ids.subnets.ids, 0)}&amp;quot;&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;  vpc_security_group_ids&lt;/span&gt;  &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;${aws_security_group.image-crawler-sg.id}&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;  count&lt;/span&gt;                   &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&amp;quot;${var.worker_count}&amp;quot;&lt;/span&gt;

  &lt;span class=&quot;kd&quot;&gt;tags&lt;/span&gt; &lt;span class=&quot; -Punctuation&quot;&gt;{&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;    Name&lt;/span&gt;             &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&amp;quot;image-crawler-worker-${var.environment}&amp;quot;&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;    environment&lt;/span&gt;      &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&amp;quot;${var.environment}&amp;quot;&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;    &amp;quot;cc:environment&amp;quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;na&quot;&gt; &amp;quot;${var.environment&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&amp;quot;dev&amp;quot; ? &amp;quot;staging&amp;quot; : &amp;quot;production&amp;quot;}&amp;quot;&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;    &amp;quot;cc:product&amp;quot;&lt;/span&gt;     &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&amp;quot;cccatalog-api&amp;quot;&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;    &amp;quot;cc:purpose&amp;quot;&lt;/span&gt;     &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&amp;quot;Image crawler worker&amp;quot;&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;    &amp;quot;cc:team&amp;quot;&lt;/span&gt;        &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&amp;quot;cc-search&amp;quot;&lt;/span&gt;
  &lt;span class=&quot; -Punctuation&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot; -Punctuation&quot;&gt;}&lt;/span&gt;

&lt;span class=&quot;kr&quot;&gt;resource&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&amp;quot;aws_instance&amp;quot; &amp;quot;crawler-monitor&amp;quot;&lt;/span&gt; &lt;span class=&quot; -Punctuation&quot;&gt;{&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;  ami&lt;/span&gt;                     &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&amp;quot;${var.ami}&amp;quot;&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;  instance_type&lt;/span&gt;           &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&amp;quot;c5.large&amp;quot;&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;  user_data&lt;/span&gt;               &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&amp;quot;${data.template_file.monitor_init.rendered}&amp;quot;&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;  subnet_id&lt;/span&gt;               &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&amp;quot;${element(data.aws_subnet_ids.subnets.ids, 0)}&amp;quot;&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;  vpc_security_group_ids&lt;/span&gt;  &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;${aws_security_group.image-crawler-sg.id}&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;

  &lt;span class=&quot;kd&quot;&gt;tags&lt;/span&gt; &lt;span class=&quot; -Punctuation&quot;&gt;{&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;    Name&lt;/span&gt;             &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&amp;quot;image-crawler-monitor-${var.environment}&amp;quot;&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;    environment&lt;/span&gt;      &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&amp;quot;${var.environment}&amp;quot;&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;    &amp;quot;cc:environment&amp;quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;na&quot;&gt; &amp;quot;${var.environment&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&amp;quot;dev&amp;quot; ? &amp;quot;staging&amp;quot; : &amp;quot;production&amp;quot;}&amp;quot;&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;    &amp;quot;cc:product&amp;quot;&lt;/span&gt;     &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&amp;quot;cccatalog-api&amp;quot;&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;    &amp;quot;cc:purpose&amp;quot;&lt;/span&gt;     &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&amp;quot;Image crawler monitor&amp;quot;&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;    &amp;quot;cc:team&amp;quot;&lt;/span&gt;        &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&amp;quot;cc-search&amp;quot;&lt;/span&gt;
  &lt;span class=&quot; -Punctuation&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot; -Punctuation&quot;&gt;}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;em&gt;&lt;center&gt;An excerpt of the crawler module definition&lt;/center&gt;&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;One &lt;code&gt;terraform plan&lt;/code&gt; and &lt;code&gt;terraform apply&lt;/code&gt; cycle later, we're ready to feed a few million test URLs to the inbound image queue and see what happens. By my recollection, this uncovered many glaring issues:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Basic network security configuration problems preventing communication between key components&lt;/li&gt;
&lt;li&gt;The need for our scheduling algorithm to be overhauled (already discussed)&lt;/li&gt;
&lt;li&gt;Workers exceeding Redis maximum connection limit&lt;/li&gt;
&lt;li&gt;Workers crashing due to hitting open file limit due to huge number of concurrent connections&lt;/li&gt;
&lt;li&gt;Probably a half dozen other problems&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;After fixing all of those issues and performing a larger smoke test, we're ready to start crawling on a large scale.&lt;/p&gt;
&lt;h5 id=&quot;monitoring-the-crawl&quot;&gt;Monitoring the crawl&lt;/h5&gt;&lt;p&gt;Unfortunately, we can't just kick back and relax while the crawler does its thing for a few weeks. We need some transparency about what the crawler is doing so we can be alerted when something breaks.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;How fast are we crawling each website? What's our target rate limit?&lt;/li&gt;
&lt;li&gt;How many errors have occurred? How many images have we successfully processed?&lt;/li&gt;
&lt;li&gt;Are we crawling right now, or are we finished?&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;It would be nice to build a reporting dashboard for this, but in the interest of time, we'll dump a giant JSON blob to &lt;code&gt;STDOUT&lt;/code&gt; every 5 seconds and call it a day. When we want to check on crawl progress, we &lt;code&gt;ssh&lt;/code&gt; into the crawl monitoring virtual machine and &lt;code&gt;tail&lt;/code&gt; the logs (we could also use our Graylog instance if we're feeling lazy). Fortunately, JSON is both trivially human and machine readable, so we can build a more sophisticated monitoring system later by parsing the logs.&lt;/p&gt;
&lt;p&gt;Here's an example log line from one of our smoke tests, indicating that we've crawled 13,224 images successfully and nothing else is happening.&lt;/p&gt;
&lt;div class=&quot;hll&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
   &lt;span class=&quot;nt&quot;&gt;&amp;quot;event&amp;quot;&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&amp;quot;monitoring_update&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
   &lt;span class=&quot;nt&quot;&gt;&amp;quot;time&amp;quot;&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&amp;quot;2020-04-17T20:22:56.837232&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
   &lt;span class=&quot;nt&quot;&gt;&amp;quot;general&amp;quot;&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
      &lt;span class=&quot;nt&quot;&gt;&amp;quot;global_max_rps&amp;quot;&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;193.418869804698&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
      &lt;span class=&quot;nt&quot;&gt;&amp;quot;error_rps&amp;quot;&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
      &lt;span class=&quot;nt&quot;&gt;&amp;quot;processing_rate&amp;quot;&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
      &lt;span class=&quot;nt&quot;&gt;&amp;quot;success_rps&amp;quot;&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
      &lt;span class=&quot;nt&quot;&gt;&amp;quot;circuit_breaker_tripped&amp;quot;&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[],&lt;/span&gt;
      &lt;span class=&quot;nt&quot;&gt;&amp;quot;num_resized&amp;quot;&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;13224&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
      &lt;span class=&quot;nt&quot;&gt;&amp;quot;resize_errors&amp;quot;&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
      &lt;span class=&quot;nt&quot;&gt;&amp;quot;split_rate&amp;quot;&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;
   &lt;span class=&quot;p&quot;&gt;},&lt;/span&gt;
   &lt;span class=&quot;nt&quot;&gt;&amp;quot;specific&amp;quot;&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
      &lt;span class=&quot;nt&quot;&gt;&amp;quot;flickr&amp;quot;&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
         &lt;span class=&quot;nt&quot;&gt;&amp;quot;successful&amp;quot;&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;13188&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
         &lt;span class=&quot;nt&quot;&gt;&amp;quot;last_50_statuses&amp;quot;&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
            &lt;span class=&quot;nt&quot;&gt;&amp;quot;200&amp;quot;&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;50&lt;/span&gt;
         &lt;span class=&quot;p&quot;&gt;},&lt;/span&gt;
         &lt;span class=&quot;nt&quot;&gt;&amp;quot;rate_limit&amp;quot;&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;178.375147633876&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
         &lt;span class=&quot;nt&quot;&gt;&amp;quot;error&amp;quot;&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;
      &lt;span class=&quot;p&quot;&gt;},&lt;/span&gt;
      &lt;span class=&quot;nt&quot;&gt;&amp;quot;animaldiversity&amp;quot;&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
         &lt;span class=&quot;nt&quot;&gt;&amp;quot;last_50_statuses&amp;quot;&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
            &lt;span class=&quot;nt&quot;&gt;&amp;quot;200&amp;quot;&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;18&lt;/span&gt;
         &lt;span class=&quot;p&quot;&gt;},&lt;/span&gt;
         &lt;span class=&quot;nt&quot;&gt;&amp;quot;successful&amp;quot;&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;18&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
         &lt;span class=&quot;nt&quot;&gt;&amp;quot;error&amp;quot;&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
         &lt;span class=&quot;nt&quot;&gt;&amp;quot;rate_limit&amp;quot;&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.206215440554406&lt;/span&gt;
      &lt;span class=&quot;p&quot;&gt;},&lt;/span&gt;
      &lt;span class=&quot;nt&quot;&gt;&amp;quot;phylopic&amp;quot;&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
         &lt;span class=&quot;nt&quot;&gt;&amp;quot;rate_limit&amp;quot;&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
         &lt;span class=&quot;nt&quot;&gt;&amp;quot;error&amp;quot;&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
         &lt;span class=&quot;nt&quot;&gt;&amp;quot;successful&amp;quot;&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;18&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
         &lt;span class=&quot;nt&quot;&gt;&amp;quot;last_50_statuses&amp;quot;&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
            &lt;span class=&quot;nt&quot;&gt;&amp;quot;200&amp;quot;&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;18&lt;/span&gt;
         &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
      &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
   &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Now that we can see what the crawler is up to, we can schedule the larger crawl and start collecting production quality data.&lt;/p&gt;
&lt;h4 id=&quot;takeaways&quot;&gt;Takeaways&lt;/h4&gt;&lt;p&gt;The result here is that we have a lightweight, modular, highly concurrent, and polite distributed image crawler with only a handful of lines of code.&lt;/p&gt;
&lt;div class=&quot;hll&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;alden:~/code/image_crawler$ cloc .
      &lt;span class=&quot;m&quot;&gt;48&lt;/span&gt; text files.
      &lt;span class=&quot;m&quot;&gt;43&lt;/span&gt; unique files.                              
      &lt;span class=&quot;m&quot;&gt;25&lt;/span&gt; files ignored.

github.com/AlDanial/cloc v &lt;span class=&quot;m&quot;&gt;1&lt;/span&gt;.81  &lt;span class=&quot;nv&quot;&gt;T&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;0&lt;/span&gt;.02 s &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;1667&lt;/span&gt;.4 files/s, &lt;span class=&quot;m&quot;&gt;130887&lt;/span&gt;.8 lines/s&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
------------------------------------------------------------------------------
Language                     files          blank        comment           code
------------------------------------------------------------------------------
Python                          &lt;span class=&quot;m&quot;&gt;16&lt;/span&gt;            &lt;span class=&quot;m&quot;&gt;244&lt;/span&gt;            &lt;span class=&quot;m&quot;&gt;242&lt;/span&gt;           &lt;span class=&quot;m&quot;&gt;1324&lt;/span&gt;
Markdown                         &lt;span class=&quot;m&quot;&gt;5&lt;/span&gt;             &lt;span class=&quot;m&quot;&gt;79&lt;/span&gt;              &lt;span class=&quot;m&quot;&gt;0&lt;/span&gt;            &lt;span class=&quot;m&quot;&gt;219&lt;/span&gt;
YAML                             &lt;span class=&quot;m&quot;&gt;3&lt;/span&gt;              &lt;span class=&quot;m&quot;&gt;2&lt;/span&gt;              &lt;span class=&quot;m&quot;&gt;4&lt;/span&gt;             &lt;span class=&quot;m&quot;&gt;61&lt;/span&gt;
XML                              &lt;span class=&quot;m&quot;&gt;3&lt;/span&gt;              &lt;span class=&quot;m&quot;&gt;0&lt;/span&gt;              &lt;span class=&quot;m&quot;&gt;0&lt;/span&gt;             &lt;span class=&quot;m&quot;&gt;18&lt;/span&gt;
Bourne Shell                     &lt;span class=&quot;m&quot;&gt;1&lt;/span&gt;              &lt;span class=&quot;m&quot;&gt;0&lt;/span&gt;              &lt;span class=&quot;m&quot;&gt;1&lt;/span&gt;              &lt;span class=&quot;m&quot;&gt;4&lt;/span&gt;
------------------------------------------------------------------------------
SUM:                            &lt;span class=&quot;m&quot;&gt;28&lt;/span&gt;            &lt;span class=&quot;m&quot;&gt;325&lt;/span&gt;            &lt;span class=&quot;m&quot;&gt;247&lt;/span&gt;           &lt;span class=&quot;m&quot;&gt;1626&lt;/span&gt;
------------------------------------------------------------------------------

alden:~/code/image_crawler$ tree .
.
‚îú‚îÄ‚îÄ architecture.png
‚îú‚îÄ‚îÄ CODE_OF_CONDUCT.md
‚îú‚îÄ‚îÄ CONTRIBUTING.md
‚îú‚îÄ‚îÄ crawl_monitor
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ monitor.py
‚îÇ   ‚îú‚îÄ‚îÄ rate_limit.py
‚îÇ   ‚îú‚îÄ‚îÄ README.md
‚îÇ   ‚îú‚îÄ‚îÄ settings.py
‚îÇ   ‚îú‚îÄ‚îÄ source_splitter.py
‚îÇ   ‚îú‚îÄ‚îÄ structured_logging.py
‚îÇ   ‚îî‚îÄ‚îÄ tsv_producer.py
‚îú‚îÄ‚îÄ docker-compose.yml
‚îú‚îÄ‚îÄ Dockerfile-monitor
‚îú‚îÄ‚îÄ Dockerfile-worker
‚îú‚îÄ‚îÄ __init__.py
‚îú‚îÄ‚îÄ LICENSE
‚îú‚îÄ‚îÄ Pipfile
‚îú‚îÄ‚îÄ Pipfile.lock
‚îú‚îÄ‚îÄ publish_release.sh
‚îú‚îÄ‚îÄ README.md
‚îú‚îÄ‚îÄ &lt;span class=&quot;nb&quot;&gt;test&lt;/span&gt;
‚îÇ   ‚îú‚îÄ‚îÄ corrupt.jpg
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ mocks.py
‚îÇ   ‚îú‚îÄ‚îÄ test_image.jpg
‚îÇ   ‚îú‚îÄ‚îÄ test_monitor.py
‚îÇ   ‚îî‚îÄ‚îÄ test_worker.py
‚îî‚îÄ‚îÄ worker
    ‚îú‚îÄ‚îÄ image.py
    ‚îú‚îÄ‚îÄ __init__.py
    ‚îú‚îÄ‚îÄ message.py
    ‚îú‚îÄ‚îÄ rate_limit.py
    ‚îú‚îÄ‚îÄ scheduler.py
    ‚îú‚îÄ‚îÄ settings.py
    ‚îú‚îÄ‚îÄ stats_reporting.py
    ‚îî‚îÄ‚îÄ util.py

&lt;span class=&quot;m&quot;&gt;3&lt;/span&gt; directories, &lt;span class=&quot;m&quot;&gt;34&lt;/span&gt; files
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;We now have a lot of useful information about images that we were lacking before. The next step is to take this metadata and integrate it into our search engine, as well as perform deeper analysis of images using computer vision.&lt;/p&gt;
</content>
  </entry>
  <entry xml:base="http://opensource.creativecommons.org/blog/entries/say_hello_to_ct/">
    <title type="text">Say Hello To Our Community Team</title>
    <id>urn:uuid:ddeb63da-7771-357d-8299-ad51defeaf4a</id>
    <updated>2020-08-14T00:00:00Z</updated>
    <link href="http://opensource.creativecommons.org/blog/entries/say_hello_to_ct/" />
    <author>
      <name>dhruvkb</name>
    </author>
    <content type="html">&lt;p&gt;Creative Commons is committed to open-source software. We have over two dozen
projects, spanning three times as many repositories on GitHub, each with its
small, but extremely enthusiastic, subcommunity. With only a few full-time
employees working on these projects, it is vital that we enable members from the
community to take increased responsibility in developing and maintaining them,
and growing the community of which they are a part.&lt;/p&gt;
&lt;p&gt;With that goal in mind, we've launched our Community Team initiative.&lt;/p&gt;
&lt;h3 id=&quot;what-is-the-community-team?&quot;&gt;What is the Community Team?&lt;/h3&gt;&lt;p&gt;Communities that grow organically around open source projects tend to be a bit
disorganised and the frequency of contributions and degree of involvement tends
to vary from member to member. Our goal is to identify contributors who are
actively involved within their communities and give them increased permissions
over the codebase and access to more information channels and tools in an effort
to empower them to participate more fully in the project.&lt;/p&gt;
&lt;p&gt;This is not restricted to code though. We're also looking for people who work
with the community on other aspects of the projects, such as design,
documentation, evangelism, and onboarding to name a few.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The Community Team establishes a framework for formalising the level of
involvement, which is a spectrum, into discrete level or 'roles'.&lt;/li&gt;
&lt;li&gt;Each role is mapped to a set of responsibilities that a member holding the
role is encouraged to take up.&lt;/li&gt;
&lt;li&gt;Each role also entrusts the members holding it to certain privileges, accesses
and permissions, to help them execute these responsibilities.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Roles also progressively include members in our roadmaps and planning meetings
to ensure that the community is aligned with our long-term goals.&lt;/p&gt;
&lt;h3 id=&quot;what-s-in-it-for-me?&quot;&gt;What's in it for me?&lt;/h3&gt;&lt;p&gt;The Community Team is not just a one-sided deal. Your membership in the
Community Team is just as beneficial for the you as it is for us. While there is
a &lt;a href=&quot;/community/community-team/#benefits-of-joining-the-community-team&quot;&gt;laundry list of benefits&lt;/a&gt; that you're entitled to, I'll just
mention some notable ones here.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;You gain real-world practical experience of working on open-source projects.&lt;/li&gt;
&lt;li&gt;You gain both soft-skills and technical-skills by interacting with other
developers from both the community as well as CC staff.&lt;/li&gt;
&lt;li&gt;Since we've already seen the quality of your work and involvement with the
community, you get priority in internship applications*.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Oh and, lest I forget, you'll receive CC swag!&lt;/p&gt;
&lt;p&gt;&lt;blockquote class=&quot;twitter-tweet&quot; data-align=&quot;center&quot;&gt;
  &lt;p lang=&quot;en&quot; dir=&quot;ltr&quot;&gt;
    Thanks for the goodies!!
    &lt;a href=&quot;https://twitter.com/creativecommons?ref_src=twsrc%5Etfw&quot;&gt;@creativecommons&lt;/a&gt;
    üòÄ
    &lt;a href=&quot;https://twitter.com/hashtag/OpenSource?src=hash&amp;amp;ref_src=twsrc%5Etfw&quot;&gt;#OpenSource&lt;/a&gt;
    &lt;a href=&quot;https://twitter.com/hashtag/creativecommons?src=hash&amp;amp;ref_src=twsrc%5Etfw&quot;&gt;#creativecommons&lt;/a&gt;
    &lt;a href=&quot;https://twitter.com/hashtag/GSoC?src=hash&amp;amp;ref_src=twsrc%5Etfw&quot;&gt;#GSoC&lt;/a&gt;
    &lt;a href=&quot;https://t.co/DFvpXCs8uu&quot;&gt;pic.twitter.com/DFvpXCs8uu&lt;/a&gt;
  &lt;/p&gt;
  &amp;mdash;
  Mayank Nader (@MayankNader)
  &lt;a href=&quot;https://twitter.com/MayankNader/status/1137995920866390016?ref_src=twsrc%5Etfw&quot;&gt;June 10, 2019&lt;/a&gt;
&lt;/blockquote&gt;&lt;/p&gt;
&lt;script async src=&quot;https://platform.twitter.com/widgets.js&quot; charset=&quot;utf-8&quot;&gt;&lt;/script&gt;&lt;h3 id=&quot;what-are-these-roles-?&quot;&gt;What are these 'roles'?&lt;/h3&gt;&lt;p&gt;If you've reached this point, I assume you see the potential of the Community
Team. Let's see where you'd fit in them.&lt;/p&gt;
&lt;p&gt;We have two kinds of roles, code-oriented &lt;a href=&quot;/community/community-team/project-roles/&quot;&gt;Project roles&lt;/a&gt;, that
give you responsibilities and permissions related to one CC project, and
non-code-oriented &lt;a href=&quot;/community/community-team/community-building-roles/&quot;&gt;Community Building roles&lt;/a&gt;, that give
you responsibilities and permissions related to improving the community of all
CC projects as a whole.&lt;/p&gt;
&lt;p&gt;Each type has a few levels but that I'll just link them for you to read on your
own. While your eligibility for any role depends on how involved you have been
in the past, the role you choose reflects how involved you would like to be in
the future.&lt;/p&gt;
&lt;p&gt;Start by asking yourself a simple question, &quot;Do I code?&quot;&lt;/p&gt;
&lt;h4 id=&quot;sure-i-can-code...&quot;&gt;&quot;Sure, I can code...&quot;&lt;/h4&gt;&lt;p&gt;&lt;em&gt;That's awesome!&lt;/em&gt; We have projects in a diverse array of languages, using myriad
tools and frameworks. Depending on the skills you have, or are planning to
acquire, you can pick a project and start contributing to it. Based on your
contributions and your familiarity with the codebase, you can then apply for the
role that matches your desired level of involvement.&lt;/p&gt;
&lt;p&gt;So if you want to be lightly involved with code-reviews and would like to know
about our plans in advance, you can start off as a Project Contributor. This is
a fantastic role to get started with and ensures that you get excellent
mentorship as you start your FOSS journey.&lt;/p&gt;
&lt;p&gt;As your familiarity with the codebase increases, you might want to triage
incoming issues or block certain PRs that you've reviewed. You could escalate
your role to Project Collaborator. Want to me more involved? You can apply to be
a Project Core Committer, or even a Project Maintainer.&lt;/p&gt;
&lt;h4 id=&quot;no-i-can-t-code...&quot;&gt;&quot;No, I can't code...&quot;&lt;/h4&gt;&lt;p&gt;&lt;em&gt;That's cool too!&lt;/em&gt; We realise that open source communities are never just about
the code. If you're passionate about growing the CC community by enabling new
contributors to get started or by spreading the word, you can apply for one of
the Community Building roles. Like the Project roles, there are a couple of
levels to choose from.&lt;/p&gt;
&lt;p&gt;Community builders have a whole different set of responsibilities and privileges
specifically catered to the unique task of cultivating a healthy community
around our many open source projects.&lt;/p&gt;
&lt;p&gt;So if you want to be lightly involved with onboarding new contributors to the
repositories and the workflows, you could start off as a Community Contributor.
This is a fantastic role to help new contributors get a headstart in their
journey with FOSS.&lt;/p&gt;
&lt;p&gt;As your familiarity with the community increases, you might want to suggest
tweets for our Twitter account, or pariticipate in long-term community building
tasks from Asana. You could escalate your role to Community Collaborator. Want
to me more involved? You can even apply to be a Community Maintainer.&lt;/p&gt;
&lt;h3 id=&quot;what-s-next?&quot;&gt;What's next?&lt;/h3&gt;&lt;p&gt;The Community Team is a fairly novel idea for us and we're still tweaking things
along the way. For example, we recently merged of two Project roles, namely
Project Member and Project Collaborator, when we realised they weren't so
different. As we internalise these roles more and more, we'll find more scope
for improvement and we'll continue to refine these roles over time.&lt;/p&gt;
&lt;p&gt;We're excited about the Community Team. If you're interested in joining us on
this ride, it's really easy to &lt;a href=&quot;/community/community-team/&quot;&gt;get started&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;small&gt;*We do not guarantee that you will be accepted if you apply for an
internship!&lt;/small&gt;&lt;/p&gt;
</content>
  </entry>
  <entry xml:base="http://opensource.creativecommons.org/blog/entries/legal-database-features/">
    <title type="text">CC Legal Database: Developing features</title>
    <id>urn:uuid:22d82fa8-ac33-3574-89ba-98937b7365f7</id>
    <updated>2020-08-07T00:00:00Z</updated>
    <link href="http://opensource.creativecommons.org/blog/entries/legal-database-features/" />
    <author>
      <name>krysal</name>
    </author>
    <content type="html">&lt;p&gt;In this post, I want to update the progress on Reimplementing the CC Legal Database site, my Outreachy project. There are several features added over the last month to date.&lt;/p&gt;
&lt;h3 id=&quot;submission-forms&quot;&gt;Submission forms&lt;/h3&gt;&lt;p&gt;The first thing I wanted to implement was the respective forms so that anyone can submit a case or article to the database. These forms were slightly modified in the redesign (discussed in the previous articles), so now it has fewer mandatory fields to lower the bar and facilitate the contribution of users.&lt;/p&gt;
&lt;figure style=&quot;text-align: center;&quot;&gt;
    &lt;img src=&quot;scholarship-form.png&quot; alt=&quot;Form to submit an article related to CC licenses&quot; style=&quot;border: 1px solid black; width: 60%;&quot;&gt;
    &lt;figcaption&gt;Scholarship form to submit an article.&lt;/figcaption&gt;
&lt;/figure&gt;&lt;p&gt;For the Scholarship form, for example, it is only needed to share your name, email and a link to propose an article related to any of the CC licenses, although the more information you can provide us the better, in any case, each contribution is reviewed by the staff before publishing.&lt;/p&gt;
&lt;h3 id=&quot;search&quot;&gt;Search&lt;/h3&gt;&lt;p&gt;The second important task was to allow searching in each of the listings. A basic function to start making use of the exposed information. In the &lt;a href=&quot;https://labs.creativecommons.org/caselaw/&quot;&gt;current site&lt;/a&gt;, this function is delegated to an external service, a certain famous search engine. Filtering is now performed in the backend based on the keywords entered by the user, thus returning the reduced list. Later this will be combined with filtering by tags or topics that are associated with each entry (case or scholarship).&lt;/p&gt;
&lt;h3 id=&quot;automated-tests&quot;&gt;Automated tests&lt;/h3&gt;&lt;p&gt;While developing the mentioned functionalities I was also in charge of adding automatic unit tests, to ensure that future changes to the code base do not damage already functional parts of the site. This, in addition to giving more confidence to future contributors, they provide value immediately, at the time of writing the tests you should think about possible edge cases, so they allowed me to notice a missing validation in a couple of routes and then correct it.&lt;/p&gt;
&lt;figure style=&quot;text-align: center;&quot;&gt;
    &lt;img src=&quot;404-page.png&quot; alt=&quot;404 page&quot; style=&quot;border:1px solid black; width:70%;&quot;&gt;
    &lt;figcaption&gt;Example of page obtained when requesting a case detail that is not published or doesn't exist.&lt;/figcaption&gt;
&lt;/figure&gt;&lt;p&gt;In this process of adding automated tests I wanted them to run on every pull request created, so I learned how to write a GitHub Action with a PostgreSQL service, the DBMS used in this case. Previously, I had already created a job for linting, so I needed to add another one to run in parallel to save time. This service provided by GitHub is pretty cool and useful, it opens up a world of possibilities, from running third party services like &lt;a href=&quot;https://github.com/GoogleChrome/lighthouse-ci&quot;&gt;Lighthouse test&lt;/a&gt; to even &lt;a href=&quot;https://github.com/gr2m/twitter-together&quot;&gt;send tweets&lt;/a&gt;! If you want to see the GitHub Action file configurated for this project, check it out: &lt;a href=&quot;https://github.com/creativecommons/caselaw/blob/31c3002a7860d78f3fdb464150c5c1b2f8bb86fc/.github/workflows/main.yml&quot;&gt;&lt;code&gt;.github/workflows/main.yml&lt;/code&gt;&lt;/a&gt;.&lt;/p&gt;
&lt;h3 id=&quot;accessibility&quot;&gt;Accessibility&lt;/h3&gt;&lt;p&gt;To check if the site had shortcomings I did the Lighthouse test on the homepage, discovering that there were indeed some issues to tackle. In principle the results were these:&lt;/p&gt;
&lt;figure style=&quot;text-align: center;&quot;&gt;
    &lt;img src=&quot;lighthouse-before.png&quot; alt=&quot;&quot; style=&quot;border:1px solid black; width:70%;&quot;&gt;
    &lt;figcaption&gt;Initial Lighthouse test measurements.&lt;/figcaption&gt;
&lt;/figure&gt;&lt;p&gt;The good thing about this test is that it throws up suggestions on how to fix the bugs found, so after adding certain missing attributes and labels, the following results were achieved.&lt;/p&gt;
&lt;figure style=&quot;text-align: center;&quot;&gt;
    &lt;img src=&quot;lighthouse-after.png&quot; alt=&quot;&quot; style=&quot;border:1px solid black; width:70%;&quot;&gt;
    &lt;figcaption&gt;Lighthouse test measurements after corrections.&lt;/figcaption&gt;
&lt;/figure&gt;&lt;p&gt;There is still room for improvement but at least we are within a quite acceptable green range.&lt;/p&gt;
&lt;h3 id=&quot;other-features-and-tweaks&quot;&gt;Other features and tweaks&lt;/h3&gt;&lt;p&gt;Some other features were implemented but only relevant to our registered users, that is, the Legal Staff. They consist of Django admin customization, such as filtering records by status, and a particular thing requested, the answers of frequently asked questions need to be displayed formatted, so they are now saved as Markdown text and transformed to HTML with style on the public site, showing lists, bold text, links, etc. The admin can also see a preview while editing.&lt;/p&gt;
&lt;h3 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h3&gt;&lt;p&gt;After reviewing all done this last month I see significant progress has been made, I have learned many things along the way: more of what Django and its ecosystem offers, about accessibility, continuous integration in Heroku and GitHub, and more. One of the things that makes me most happy is being able to be contributing and being part of an Open Source organization, knowing how it moves and works inside, something I never imagine before.&lt;/p&gt;
&lt;p&gt;Time flies and there are less than two weeks left to finish, so if you want to follow the project here is the repository to suggest improvements or report bugs, or if you prefer something less technical you can join us on the &lt;a href=&quot;https://creativecommons.slack.com/channels/cc-dev-legal-database&quot;&gt;slack channel&lt;/a&gt;.&lt;/p&gt;
</content>
  </entry>
  <entry xml:base="http://opensource.creativecommons.org/blog/entries/smithsonian-unit-code-update/">
    <title type="text">Smithsonian Unit Code Update</title>
    <id>urn:uuid:23985c56-007a-3707-9f9c-66bde8adae7e</id>
    <updated>2020-08-03T00:00:00Z</updated>
    <link href="http://opensource.creativecommons.org/blog/entries/smithsonian-unit-code-update/" />
    <author>
      <name>charini</name>
    </author>
    <content type="html">&lt;h2 id=&quot;introduction&quot;&gt;Introduction&lt;/h2&gt;&lt;p&gt;The Creative Commons (CC) Catalog project collects and stores CC licensed images scattered across the internet, such
that they can be made accessible to the general public via the &lt;a href=&quot;https://ccsearch.creativecommons.org/&quot;&gt;CC Search&lt;/a&gt; and &lt;a href=&quot;https://api.creativecommons.engineering/v1/&quot;&gt;CC Catalog API&lt;/a&gt;
tools. Numerous information associated with each image, which help in the image search and categorisation process are
stored via CC Catalog in the CC database.&lt;/p&gt;
&lt;p&gt;In my &lt;a href=&quot;/blog/entries/flickr-sub-provider-retrieval/&quot;&gt;previous blog post&lt;/a&gt; of this series entitled 'Flickr Sub-provider Retrieval', I discussed how
the images from a certain provider (such as Flickr) can be categorised based on the sub-provider values (which reflects
the underlying organisation or entity that published the images through the provider). We have similarly implemented
the sub-provider retrieval logic for Europeana and Smithsonian providers. Unlike in Flickr and Europeana, every single
image from Smithsonian is categorised under some sub-provider value where the sub-providers are identified based on a
unit code value as contained in the API response (for more information please refer to the pull request &lt;a href=&quot;https://github.com/creativecommons/cccatalog/pull/455&quot;&gt;#455&lt;/a&gt;).
The unit code values and the corresponding sub provider values are maintained in the dictionary
&lt;em&gt;SMITHSONIAN_SUB_PROVIDERS&lt;/em&gt;. However, there is the possibility of the &lt;em&gt;unit code&lt;/em&gt; values being updated at the
Smithsonian API level, and it is important that we have a mechanism of reflecting those updates in the
&lt;em&gt;SMITHSONIAN_SUB_PROVIDERS&lt;/em&gt; dictionary as well. In this blog post, we discuss how we learn the potential
changes to the &lt;em&gt;unit code&lt;/em&gt; values and keep the &lt;em&gt;SMITHSONIAN_SUB_PROVIDERS&lt;/em&gt; dictionary up-to-date.&lt;/p&gt;
&lt;h2 id=&quot;implementation&quot;&gt;Implementation&lt;/h2&gt;&lt;h3 id=&quot;retrieving-the-latest-unit-codes&quot;&gt;Retrieving the latest unit codes&lt;/h3&gt;&lt;p&gt;We are required to obtain the latest &lt;em&gt;unit codes&lt;/em&gt; supported by the Smithsonian API to achieve this task. Furthermore,
since we are only interested in image data, the &lt;em&gt;unit codes&lt;/em&gt; which are associated with images alone need to be
retrieved. The latest Smithsonian &lt;em&gt;unit codes&lt;/em&gt; corresponding to images can be retrieved by calling the end point
&lt;a href=&quot;https://api.si.edu/openaccess/api/v1.0/terms/unit_code?q=online_media_type:Images&amp;amp;api_key=REDACTED&quot;&gt;https://api.si.edu/openaccess/api/v1.0/terms/unit_code?q=online_media_type:Images&amp;amp;api_key=REDACTED&lt;/a&gt;&lt;/p&gt;
&lt;h3 id=&quot;check-for-unit-code-updates&quot;&gt;Check for unit code updates&lt;/h3&gt;&lt;p&gt;In order to identify whether changes have occurred to the collection of &lt;em&gt;unit codes&lt;/em&gt; supported by the Smithsonian API
(in the form of additions and/or deletions), we compare the values retrieved by calling the previously mentioned
endpoint, with the values contained in the &lt;em&gt;SMITHSONIAN_SUB_PROVIDERS&lt;/em&gt; dictionary. All changes are reflected in a table
named &lt;em&gt;smithsonian_new_unit_codes&lt;/em&gt; which contains the two fields, 'new_unit_code' and 'action'. If a new &lt;em&gt;unit code&lt;/em&gt; is
introduced at the API level, we store that &lt;em&gt;unit code&lt;/em&gt; value with the corresponding action value 'add' in the table.
This reflects that the given &lt;em&gt;unit code&lt;/em&gt; value needs to be added to the &lt;em&gt;SMITHSONIAN_SUB_PROVIDERS dictionary&lt;/em&gt;. If a
&lt;em&gt;unit code&lt;/em&gt; that appears in the &lt;em&gt;SMITHSONIAN_SUB_PROVIDERS&lt;/em&gt; dictionary does not appear at the API level, we store
the &lt;em&gt;unit code&lt;/em&gt; value with the corresponding action value 'delete' in the table, reflecting that it needs to be deleted
from the dictionary.&lt;/p&gt;
&lt;h3 id=&quot;triggering-the-unit-code-update-workflow&quot;&gt;Triggering the unit code update workflow&lt;/h3&gt;&lt;p&gt;A separate workflow named &lt;em&gt;check_new_smithsonian_unit_codes_workflow&lt;/em&gt; allows executing the logic we discussed via the
Airflow UI. For each execution, the table &lt;em&gt;smithsonian_new_unit_codes&lt;/em&gt; is completely cleared of previous data, and the
latest updates to reflect in the &lt;em&gt;SMITHSONIAN_SUB_PROVIDERS&lt;/em&gt; dictionary are stored. Note that the actual updates to
the dictionary (as reflected in the table) needs to be carried out by a person, since editing the dictionary is not
automated. Furthermore, this workflow is expected to be executed at-least once a week, preferably prior to running
the Smithsonian image retrieval script such that the Smithsonian sub-provider retrieval task can be run with no issue.&lt;/p&gt;
&lt;h2 id=&quot;acknowledgement&quot;&gt;Acknowledgement&lt;/h2&gt;&lt;p&gt;I express my gratitude to my GSoC supervisor Brent Moran for assisting me with this task.&lt;/p&gt;
</content>
  </entry>
  <entry xml:base="http://opensource.creativecommons.org/blog/entries/linked-commons-autocomplete-feature/">
    <title type="text">Linked Commons: Autocomplete Feature</title>
    <id>urn:uuid:0e278e85-748f-3d35-a640-24daab837875</id>
    <updated>2020-07-31T00:00:00Z</updated>
    <link href="http://opensource.creativecommons.org/blog/entries/linked-commons-autocomplete-feature/" />
    <author>
      <name>subhamX</name>
    </author>
    <content type="html">&lt;h2 id=&quot;introduction&quot;&gt;Introduction&lt;/h2&gt;&lt;p&gt;The following blog intends to explain the very recent feature integrated to the Linked Commons. Be it the giant Google Search or any small website having a form field, everyone wishes to predict what‚Äôs on the user‚Äôs mind. For every keystroke, a nice search bar always renders some possible options the user could be looking for. The core ideology behind having this feature is ‚Äî &lt;em&gt;do as much work as possible for the user!&lt;/em&gt;&lt;/p&gt;
&lt;div style=&quot;text-align: center; width: 100%;&quot;&gt;
    &lt;figure&gt;
        &lt;img src=&quot;autocomplete-feat-in-action.gif&quot; alt=&quot;autocomplete-feature&quot; style=&quot;border: 1px solid black&quot;&gt;
        &lt;figcaption style=&quot;font-weight: 500;&quot;&gt;Autocomplete feature in action&lt;/figcaption&gt;
    &lt;/figure&gt;
&lt;/div&gt;&lt;h2 id=&quot;motivation&quot;&gt;Motivation&lt;/h2&gt;&lt;p&gt;One of the newest features integrated last month into Linked Commons is Filtering by node name. Here a user can search for his/her favourite node and explore all its neighbours. Since the list is very big, it was self-evident for us to have a text box (and not a drop-down) where the user is supposed to type the node name.&lt;/p&gt;
&lt;p&gt;Some of the reasons why to have &quot;autocomplete feature&quot; in the filtering by node name -&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Some of the node names are very uncommon and lengthy. There is a high probability of misspelling it.&lt;/li&gt;
&lt;li&gt;Submitting the form and getting a response of ‚ÄúNode doesn‚Äôt exist‚Äù isn‚Äôt a very good user flow, and we want to minimise such incidents.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Also, on a side note giving a search bar to the user and giving no hints is ruthless. We all need recommendations and guess what linked commons got you covered! Now for every keystroke, we load a bunch of node names which you might be looking for. ;)&lt;/p&gt;
&lt;h2 id=&quot;problem&quot;&gt;Problem&lt;/h2&gt;&lt;p&gt;The autocomplete feature on a very basic level aims to predict the rest of a word the user is typing. A possible implementation is though the linear traversal of all the nodes in the list. It will be having a &lt;strong&gt;linear time complexity&lt;/strong&gt;. It‚Äôs not very good and it‚Äôs very obvious to look for a faster and more efficient way. Also, even if for once we neglect the &lt;strong&gt;time complexity&lt;/strong&gt;, looking for the best 10 nodes out of these millions on the client's machine is not at all a good idea; it will cause throttling and will result in performance drops. 
On the other hand, a &lt;strong&gt;trie based solution&lt;/strong&gt; is more efficient for sure but still, we cannot do this indexing on the client machine for the same reasons stated above.
So far, it is now apparent that we implement this feature on the server and also aim for at least something better than linear time complexity.&lt;/p&gt;
&lt;h2 id=&quot;a-non-conventional-solution&quot;&gt;A non-conventional solution&lt;/h2&gt;&lt;p&gt;We could have used Elastic Search, which is very powerful and has a ton of functionalities but since our needs are very small we wanted to look for other simple alternatives. Moreover, we didn't want to complicate our current architecture by adding an additional framework and libraries.&lt;/p&gt;
&lt;p&gt;Taking the above points into consideration we went ahead with the following solution. We store all nodes data into an SQL dB and search for all the nodes whose domain name pattern was matching to the query string. After slicing the query set and other randomization we sent the payload to the client. To make it more robust, we are caching the results in the frontend to avoid multiple calls for the same query. It will surely reduce the load from the server and also give a faster response.&lt;/p&gt;
&lt;h2 id=&quot;results&quot;&gt;Results&lt;/h2&gt;&lt;p&gt;To make sure our solution works well, we performed load tests, checking that any response time does not exceed 1000 ms. We used locust which is a user load testing tool. We simulated with &lt;strong&gt;1000 users&lt;/strong&gt; and &lt;strong&gt;10 as Hatch rate&lt;/strong&gt;. 
The following test is performed on the local machine to ensure that the server location isn‚Äôt affecting the results.&lt;/p&gt;
&lt;p&gt;Here are some aggregated result statistics.&lt;/p&gt;
&lt;table class=&quot;table table-striped&quot;&gt;
&lt;thead class=&quot;thead-dark&quot;&gt;&lt;tr&gt;
&lt;th&gt;Field Name&lt;/th&gt;
&lt;th&gt;Value&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Request Count&lt;/td&gt;
&lt;td&gt;&lt;strong&gt; 23323     &lt;/strong&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Failure Count&lt;/td&gt;
&lt;td&gt;&lt;strong&gt;  0        &lt;/strong&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Median Response Time&lt;/td&gt;
&lt;td&gt;&lt;strong&gt; 360 ms    &lt;/strong&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Average Response Time&lt;/td&gt;
&lt;td&gt;&lt;strong&gt; 586.289 ms&lt;/strong&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Min Response Time&lt;/td&gt;
&lt;td&gt;&lt;strong&gt; 4.03094 ms&lt;/strong&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Max Response Time&lt;/td&gt;
&lt;td&gt;&lt;strong&gt; 4216 ms   &lt;/strong&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Average Content Size&lt;/td&gt;
&lt;td&gt;&lt;strong&gt; 528.667 ms&lt;/strong&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Requests/s&lt;/td&gt;
&lt;td&gt;&lt;strong&gt; 171.754   &lt;/strong&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Max Requests/s&lt;/td&gt;
&lt;td&gt;&lt;strong&gt; 214       &lt;/strong&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Failures/s&lt;/td&gt;
&lt;td&gt;&lt;strong&gt; 0         &lt;/strong&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h2 id=&quot;next-steps&quot;&gt;Next steps&lt;/h2&gt;&lt;p&gt;In the next blog, we will be covering the long awaited data update and the new architecture.&lt;/p&gt;
&lt;h2 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h2&gt;&lt;p&gt;Overall, I enjoyed working on this feature and it was a great learning experience. This feature has been successfully integrated to the development version, do check it out. Now that you have read this blog till the end, I hope that you enjoyed it. For more information please visit our &lt;a href=&quot;https://github.com/creativecommons/cccatalog-dataviz/&quot;&gt;Github repo&lt;/a&gt;. We are looking forward to hearing from you on linked commons. Our &lt;a href=&quot;https://creativecommons.slack.com/channels/cc-dev-cc-catalog-viz&quot;&gt;slack&lt;/a&gt; doors are always open to you, see you there. :)&lt;/p&gt;
</content>
  </entry>
  <entry xml:base="http://opensource.creativecommons.org/blog/entries/cc-search-accessibility-week7-8/">
    <title type="text">CC Search, Initial Accessibility Improvements</title>
    <id>urn:uuid:b523aa13-3429-3303-b7cb-3c66beeed723</id>
    <updated>2020-07-25T00:00:00Z</updated>
    <link href="http://opensource.creativecommons.org/blog/entries/cc-search-accessibility-week7-8/" />
    <author>
      <name>AyanChoudhary</name>
    </author>
    <content type="html">&lt;p&gt;These are the seventh and eighth weeks of my internship with CC. I am working on improving the accessibility of cc-search and internationalizing it as well.
This post contains details of my work done to make initial accessibility improvements to homepage and the other static pages.&lt;/p&gt;
&lt;p&gt;With the internationalization work complete, our next target were the accessiblity improvements. So I decided to tackle the homepage and the static pages first.
The aforementioned pages had the following accessiblity issues:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;No aria-label on links&lt;/li&gt;
&lt;li&gt;Improper landmarks&lt;/li&gt;
&lt;li&gt;Improper aria-control nestings&lt;/li&gt;
&lt;li&gt;Some elements not being read by the screen-reader&lt;/li&gt;
&lt;li&gt;Color contrast Issues(to be covered later)&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;But before working I ran another set of audit tests to exactly pin-point these issues. I used &lt;a href=&quot;https://www.nvaccess.org/&quot;&gt;NVDA&lt;/a&gt; for running these audits.
Lets go through the fixes one at a time.&lt;/p&gt;
&lt;p&gt;The first issue of no aria-label was pre-dominantly found in the footer. we had some links such as:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;&amp;lt;a
    href=&quot;https://www.instagram.com/creativecommons&quot;
    class=&quot;social has-text-white&quot;
    target=&quot;_blank&quot;
    rel=&quot;noopener&quot;
&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;These links did not contain any aria-label and were read as &lt;strong&gt;cc link&lt;/strong&gt;. So the aria-labels had to be added &lt;code&gt;aria-label=&quot;instagram link&quot;&lt;/code&gt; in this case which fixed this problem.&lt;/p&gt;
&lt;p&gt;The next issue was of improper landmarks. Most of the pages had no &lt;strong&gt;main&lt;/strong&gt; landmark and some had no &lt;strong&gt;complimentary&lt;/strong&gt; or &lt;strong&gt;region&lt;/strong&gt; landmarks even though they were required in those pages.
These landmarks had to be added after the carefully scrutinising the pages in the audits.&lt;/p&gt;
&lt;p&gt;The next issue was of improper aria-control nestings. This is interesting as it involves having some deeper understanding of the roles involved. So I will explain this in a little depth.
The area where we had this issue was in feedback page. The code involved was:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;&amp;lt;ul&amp;gt;
    &amp;lt;li :class=&quot;tabClass(0, 'tab')&quot;&amp;gt;
        &amp;lt;a
            href=&quot;#panel0&quot;
            :aria-selected=&quot;activeTab == 0&quot;
            @click.prevent=&quot;setActiveTab(0)&quot;
        &amp;gt;
        Help us Improve
        &amp;lt;/a&amp;gt;
    &amp;lt;/li&amp;gt;
    &amp;lt;li :class=&quot;tabClass(1, 'tab')&quot;&amp;gt;
        &amp;lt;a
            href=&quot;#panel1&quot;
            :aria-selected=&quot;activeTab == 1&quot;
            @click.prevent=&quot;setActiveTab(1)&quot;
        &amp;gt;
        Report a Bug
        &amp;lt;/a&amp;gt;
    &amp;lt;/li&amp;gt;
&amp;lt;/ul&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The reason why this is an error is because of the &lt;code&gt;aria-selected&lt;/code&gt; attribute can only be applied to an element having the role &lt;strong&gt;tab&lt;/strong&gt; nested inside a &lt;strong&gt;tablist&lt;/strong&gt; element.
For reference, in the above example the &lt;code&gt;&amp;lt;ul&amp;gt;&lt;/code&gt; should have the role &lt;strong&gt;tablist&lt;/strong&gt; and each &lt;code&gt;&amp;lt;li&amp;gt;&lt;/code&gt; element should have the role &lt;strong&gt;tab&lt;/strong&gt;. And so the &lt;code&gt;aria-selected&lt;/code&gt; attribute should be in the &lt;code&gt;&amp;lt;li&amp;gt;&lt;/code&gt; element instead of the &lt;code&gt;&amp;lt;a&amp;gt;&lt;/code&gt; tag.&lt;/p&gt;
&lt;p&gt;The corrected code is:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;&amp;lt;ul role=&quot;tablist&quot;&amp;gt;
    &amp;lt;li role=&quot;tab&quot; :class=&quot;tabClass(0, 'tab')&quot; :aria-selected=&quot;activeTab == 0&quot;&amp;gt;
        &amp;lt;a 
            aria-label=&quot;help us improve form&quot; 
            href=&quot;#panel0&quot;
            @click.prevent=&quot;setActiveTab(0)&quot;
        &amp;gt;
        {{ $t('feedback.improve') }}
        &amp;lt;/a&amp;gt;
    &amp;lt;/li&amp;gt;
    &amp;lt;li role=&quot;tab&quot; :class=&quot;tabClass(1, 'tab')&quot; :aria-selected=&quot;activeTab == 1&quot;&amp;gt;
        &amp;lt;a 
            aria-label=&quot;report a bug form&quot;
            href=&quot;#panel1&quot;
            @click.prevent=&quot;setActiveTab(1)&quot;
        &amp;gt;
        {{ $t('feedback.bug') }}
        &amp;lt;/a&amp;gt;
    &amp;lt;/li&amp;gt;
&amp;lt;/ul&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Another interesting finding involved the screen readers not reading particular special characters such as &lt;code&gt;~&lt;/code&gt; and &lt;code&gt;|&lt;/code&gt;.
This issue was quite pronounced in the search guide page where these symbols were used in plenty in both links as well as texts.
So I had to phonetically write these out in the aria-labels of the links to make the screen reader read them out loud.
The corresponding changes are:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;&amp;lt;a
    aria-label=&quot;dog vertical bar cat&quot;
    href=&quot;https://search.creativecommons.org/search?q=dog%7Ccat&quot;
&amp;gt;
    &amp;lt;em&amp;gt;dog|cat&amp;lt;/em&amp;gt;
&amp;lt;/a&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;After all these changes we had some increase in the accessibility scores(computed from lighthouse):&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;About Page: 78 -&amp;gt; 97 | +19&lt;/li&gt;
&lt;li&gt;Search-Guide Page: 76 -&amp;gt; 97 | +23&lt;/li&gt;
&lt;li&gt;Feedback Page: 75 -&amp;gt; 97 | +22&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Whoosh!! That was quite a lot. We are done with these two weeks for now. Hope to see you in the next post as well.&lt;/p&gt;
&lt;p&gt;You can track the work done for these weeks through these PRs:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a href=&quot;https://github.com/creativecommons/cccatalog-frontend/pull/1068&quot;&gt;Accessibility&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://github.com/creativecommons/cccatalog-frontend/pull/1072&quot;&gt;Accessibility Improvements&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;The progress of the project can be tracked on &lt;a href=&quot;https://github.com/creativecommons/cccatalog-frontend&quot;&gt;cc-search&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;CC Search Accessiblity is my GSoC 2020 project under the guidance of &lt;a href=&quot;https://creativecommons.org/author/zackcreativecommons-org/&quot;&gt;Zack Krida&lt;/a&gt; and &lt;a href=&quot;https://opensource.creativecommons.org/blog/authors/akmadian/&quot;&gt;Ari Madian&lt;/a&gt;, who is the primary mentor for this project, &lt;a href=&quot;https://creativecommons.org/author/annacreativecommons-org/&quot;&gt;Anna Tumad√≥ttir&lt;/a&gt; for helping all along and engineering director &lt;a href=&quot;https://creativecommons.org/author/kriticreativecommons-org/&quot;&gt;Kriti
Godey&lt;/a&gt;, have been very supportive.&lt;/p&gt;
</content>
  </entry>
  <entry xml:base="http://opensource.creativecommons.org/blog/entries/data-flow-API-to-DB/">
    <title type="text">Data flow: from API to DB</title>
    <id>urn:uuid:44db39c0-d562-3a62-b5c5-ac4babcbbe40</id>
    <updated>2020-07-22T00:00:00Z</updated>
    <link href="http://opensource.creativecommons.org/blog/entries/data-flow-API-to-DB/" />
    <author>
      <name>srinidhi</name>
    </author>
    <content type="html">&lt;h2 id=&quot;introduction&quot;&gt;Introduction&lt;/h2&gt;&lt;p&gt;The CC Catalog project  handles the flow of image metadata from the source or
provider and loads it to the database, which is then surfaced to the &lt;a href=&quot;https://ccsearch.creativecommons.org/about&quot;&gt;CC
search&lt;/a&gt; tool. The workflows are set up for each provider to gather
metadata about CC licensed images. These workflows are handled with the help of
Apache Airflow. Airflow is an open source tool that helps us to schedule and
monitor workflows.&lt;/p&gt;
&lt;h2 id=&quot;airflow-intro&quot;&gt;Airflow intro&lt;/h2&gt;&lt;p&gt;Apache Airflow is an open source tool that helps us to schedule tasks and
monitor workflows . It provides an easy to use UI that makes managing tasks
easy.  In Airflow, the tasks we want to schedule are organised in DAGs
(Directed Acyclic Graphs). DAGs consist of a collection of tasks, and a
relationship defined among these tasks, so that they run in an organised
manner. DAGs files are standard python files that are loaded from  the defined
&lt;code&gt;DAG_FOLDER&lt;/code&gt; on a host. Airflow selects all the python files in the
&lt;code&gt;DAG_FOLDER&lt;/code&gt; that have a DAG instance defined globally, and executes them to
create the DAG objects.&lt;/p&gt;
&lt;h2 id=&quot;cc-catalog-workflow&quot;&gt;CC Catalog Workflow&lt;/h2&gt;&lt;p&gt;In the CC catalog, Airflow is set up inside a docker container along with other
services . The loader and provider workflows are inside the &lt;code&gt;dags&lt;/code&gt; directory in
the repo &lt;a href=&quot;https://github.com/creativecommons/cccatalog/tree/dacb48d24c6ae9b532ff108589b9326bde0d37a3/src/cc_catalog_airflow/dags&quot;&gt;dag folder&lt;/a&gt;. Provider workflows are set up to pull metadata
about CC licensed images from the respective providers , the data pulled is
structured into a standardised format and written into a TSV (Tab Separated
Values) file locally. These TSV files are then loaded into S3 and then finally
to PostgreSQL DB by the loader workflow.&lt;/p&gt;
&lt;h2 id=&quot;provider-api-workflow&quot;&gt;Provider API workflow&lt;/h2&gt;&lt;p&gt;The provider workflows are usually scheduled in one of two time frequencies,
daily or monthly.&lt;/p&gt;
&lt;p&gt;Providers such as Flickr or Wikimedia Commons that are filtered using the date
parameter are usually scheduled for daily jobs. These providers have a large
volume of continuously changing data, and so daily updates are required to keep
the data in sync.&lt;/p&gt;
&lt;p&gt;Providers that are scheduled for monthly ingestion are ones with a relativley
low volume of data, or for which filtering by date is not possible. This means
we need to ingest the entire collection at once. Examples are museum providers
like the &lt;a href=&quot;https://collection.sciencemuseumgroup.org.uk/&quot;&gt;Science museum UK&lt;/a&gt; or &lt;a href=&quot;https://www.smk.dk/&quot;&gt;Statens Museum for
Kunst&lt;/a&gt;. We don‚Äôt expect museum providers to change data on a daily basis.&lt;/p&gt;
&lt;p&gt;The scheduling of the DAGs by the scheduler daemons depends on a few
parameters.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;start_date&lt;/code&gt; - it denotes the starting date from which the
task should begin running. &lt;/li&gt;
&lt;li&gt;&lt;code&gt;schedule_interval&lt;/code&gt; - it denotes the interval between subsequent runs, it
can be specified with airflow keyword strings like ‚Äú@daily‚Äù, ‚Äú@weekly‚Äù,
‚Äú@monthly‚Äù, ‚Äú@yearly‚Äù other than these we can also schedule the interval using
cron expression.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Example: Cleveland museum is currently scheduled for a monthly crawl with a
starting date as &lt;code&gt;2020-01-15&lt;/code&gt;. &lt;a href=&quot;https://github.com/creativecommons/cccatalog/blob/dacb48d24c6ae9b532ff108589b9326bde0d37a3/src/cc_catalog_airflow/dags/cleveland_museum_workflow.py&quot;&gt;cleveland_museum_workflow&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&quot;loader-workflow&quot;&gt;Loader workflow&lt;/h2&gt;&lt;p&gt;The data from the provider scripts are not directly loaded into S3. Instead,
they are stored in a TSV file on the local disk, and the tsv_postgres workflow
handles loading of data to S3, and eventually PostgreSQL. The DAG starts by
calling the task to stage the oldest tsv file from the output directory of the
provider scripts to the staging directory. Next, two tasks run in parallel, one
loads the tsv file in the staging directory to S3 , while the other creates the
loading table in the PostgreSQL database. Once the data is loaded to S3 and the
loading table has been created, the data from S3 is loaded to the intermediate
loading table and then finally inserted into the image table. If loading from
S3 fails the data is loaded to PostgreSQL from the locally stored tsv file.
When the data has been successfully transferred to the image table, the
intermediate loading table is dropped and the tsv files in the staging
directory are deleted. If the copying the tsv files to S3 fails or then those
files are moved to the failure directory for future inspection.&lt;/p&gt;
&lt;div style=&quot;text-align:center;&quot;&gt;
    &lt;img src=&quot;loader_workflow.png&quot; width=&quot;1000px&quot;/&gt;
    &lt;p&gt; Loader workflow &lt;/p&gt;
&lt;/div&gt;&lt;h2 id=&quot;acknowledgement&quot;&gt;Acknowledgement&lt;/h2&gt;&lt;p&gt;I would like to thank Brent Moran for helping me write this blog post.&lt;/p&gt;
</content>
  </entry>
  <entry xml:base="http://opensource.creativecommons.org/blog/entries/what-is-up-ccos/">
    <title type="text">What is up? - CCOS Revamp</title>
    <id>urn:uuid:db2b95cd-c221-3f56-9ffb-8b165676fdbe</id>
    <updated>2020-07-20T00:00:00Z</updated>
    <link href="http://opensource.creativecommons.org/blog/entries/what-is-up-ccos/" />
    <author>
      <name>dhruvi16</name>
    </author>
    <content type="html">&lt;p&gt;In my previous blog, I demonstrated what my Outreachy project was about. Here I will talk about my progress in the past 7 weeks.&lt;/p&gt;
&lt;h3 id=&quot;the-set-up&quot;&gt;The Set-Up -&lt;/h3&gt;&lt;p&gt;The &lt;a href=&quot;https://opensource.creativecommons.org/&quot;&gt;Creative Commons Open Source&lt;/a&gt; website is built using &lt;a href=&quot;https://www.getlektor.com/&quot;&gt;Lektor&lt;/a&gt;. I was not very familiar with it, so I started by going through the documentation and the official website code. I learned how awesome it is and can also be used by non-coders. I got familiar with the &lt;a href=&quot;https://palletsprojects.com/p/jinja/&quot;&gt;jinja templates&lt;/a&gt; and working of themes in a Lektor app. For integrating new styles from Vocabulary, I replaced &lt;code&gt;templates/&lt;/code&gt; folder with a &lt;code&gt;theme/&lt;/code&gt; folder. Here is the link to how &lt;a href=&quot;https://www.getlektor.com/docs/templates/&quot;&gt;templates&lt;/a&gt; work in Lektor.&lt;/p&gt;
&lt;p&gt;As the revamping process is gradual, there was a need of setting up a staging environment where we could test the website. Deploying the branch that consists of the ongoing changes was pretty easy, I just followed the official &lt;a href=&quot;https://www.netlify.com/blog/2016/05/25/lektor-on-netlify-a-step-by-step-guide/&quot;&gt;documentation&lt;/a&gt; provided by Netlify and deployed it.&lt;/p&gt;
&lt;h3 id=&quot;adding-new-components-to-vocabulary&quot;&gt;Adding New Components to Vocabulary -&lt;/h3&gt;&lt;p&gt;The &lt;a href=&quot;https://www.figma.com/file/mttcugI1UxvCJRKE5sdpbO/Mockups&quot;&gt;mock-ups&lt;/a&gt; for the new CCOS website extensively use Vocabulary components, styles, and patterns, and it had components that were not available in Vocabulary. So, I worked on building them from scratch. I enjoyed this part a bit too much. And also this was a part of the project, I did not think would take up like 2 weeks but it did. I enjoyed questioning the scope, the design, the experience of the components, and getting satisfactory answers. Maintaining the practices, focusing on details were fun things to do. It felt like I own those components. You can check them out &lt;a href=&quot;https://cc-vocabulary.netlify.app/?path=/docs/vocabulary-introduction--page&quot;&gt;here&lt;/a&gt; and also use them wherever needed.&lt;/p&gt;
&lt;h3 id=&quot;updating-templates-of-the-theme&quot;&gt;Updating Templates of the Theme -&lt;/h3&gt;&lt;p&gt;I started by updating the home page template. I try to make the code cleaner and more readable. Going through the &lt;a href=&quot;https://www.getlektor.com/&quot;&gt;Lektor&lt;/a&gt; documentation, I came across different ways to do so. One of them was &lt;a href=&quot;/blog/entries/what-is-up-ccos/(https://www.getlektor.com/&quot;&gt;flow blocks&lt;/a&gt;), I like how it makes a template more modular and readable so I implemented the home page using flow blocks. This one after one, I started updating every template. For now, I have updated 10 templates and I plan to update the remaining in upcoming weeks.&lt;/p&gt;
&lt;h3 id=&quot;my-experience-so-far&quot;&gt;My Experience so far -&lt;/h3&gt;&lt;p&gt;This has been one heck of a journey for me. I have never collaborated with such a huge open-source organization and so that was something new for me. I have learned a lot of things both technical and non-technical so far. I have become more alert about the code I write, this journey has helped me improve the questions I ask to myself while writing code or thinking about the solution, I got to learn about new technologies such as &lt;a href=&quot;https://www.getlektor.com/&quot;&gt;Lektor&lt;/a&gt;, &lt;a href=&quot;https://webpack.js.org/&quot;&gt;Webpack&lt;/a&gt;, &lt;a href=&quot;https://sass-lang.com/documentation/syntax&quot;&gt;SCSS&lt;/a&gt; and many more. I am just very glad to be a part of this.&lt;/p&gt;
</content>
  </entry>
  <entry xml:base="http://opensource.creativecommons.org/blog/entries/linked-commons-whats-new/">
    <title type="text">Linked Commons: What's new?</title>
    <id>urn:uuid:cf56c986-4df1-344a-a15e-e852c66f895d</id>
    <updated>2020-07-16T00:00:00Z</updated>
    <link href="http://opensource.creativecommons.org/blog/entries/linked-commons-whats-new/" />
    <author>
      <name>subhamX</name>
    </author>
    <content type="html">&lt;h2 id=&quot;introduction&quot;&gt;Introduction&lt;/h2&gt;&lt;p&gt;&lt;strong&gt;Linked Commons&lt;/strong&gt; is a visualization project which aims to showcase and establish a relationship between millions of data points of licensed content metadata using graphs. Since it is the first blog of this new series, let‚Äôs discuss the core ideology of having this project and then about new features. Development of all components mentioned in this blog is complete and has been successfully integrated, so do check out the development version. Happy Reading!&lt;/p&gt;
&lt;h2 id=&quot;motivation-and-why-does-visualization-matter?&quot;&gt;Motivation and why does visualization matter?&lt;/h2&gt;&lt;p&gt;The number of websites using creative commons licensed content is very huge and growing very rapidly. The CC catalog hosts these millions of data points and each node contains information about the URL of the websites and the licenses used. One can surely do rigorous data analysis, but this would only be interpretable by a few people with a technical background.  On the other hand,  by visualizing data, it becomes incredibly easier to identify patterns and trends. As an old saying, a picture is worth a thousand words. That‚Äôs the core ideology of the Linked Commons, i.e. to show the millions of licensed content metadata and how these nodes are connected in a visually appealing form on the HTML canvas like a picture.&lt;/p&gt;
&lt;h2 id=&quot;task-1:-code-refactoring&quot;&gt;Task 1: Code Refactoring&lt;/h2&gt;&lt;p&gt;My first task was to refactor the code and migrate it to react. The existing codebase had all core functionalities, but we wanted to make it more modular, improve the design, code readability, and reduce complexity. This will help us maintain this project in the long run. Also, it will be easier for the community to contribute and understand the logic.&lt;/p&gt;
&lt;h2 id=&quot;task-2:-graph-filtering&quot;&gt;Task 2: Graph Filtering&lt;/h2&gt;&lt;h3 id=&quot;need-for-filtering-methods&quot;&gt;Need for Filtering Methods&lt;/h3&gt;&lt;div style=&quot;text-align: center; width: 90%; margin-left: 5%;&quot;&gt;
    &lt;figure&gt;
        &lt;img src=&quot;big-graph.png&quot; alt=&quot;Large Graph&quot; style=&quot;border: 1px solid black&quot;&gt;
        &lt;figcaption style=&quot;font-weight: 500;&quot;&gt;Pic showing clustors of a Graph with 9982 nodes 5000 links&lt;/figcaption&gt;
    &lt;/figure&gt;
&lt;/div&gt;&lt;p&gt;The aggregate data that cc catalog has is in hundreds of millions. Rendering a graph with these many nodes will be a nightmare for the browser‚Äôs rendering and JavaScript engine. Just like we divide any standard textbook into chapters, we thought about adding filtering options that enable the user to retrieve precise information according to certain criteria selected by them. Hence,¬† we need to have a way in which we can filter the aggregate data into smaller chunks.&lt;/p&gt;
&lt;h3 id=&quot;what-filtering-methods?&quot;&gt;What filtering methods?&lt;/h3&gt;&lt;p&gt;After brainstorming for a while, we converged and agreed to have &lt;strong&gt;filtering based on node name and distance&lt;/strong&gt;. The primary reason behind this was, it is kind of basic that a person would like to look for his/her favourite node and its neighbours. This is not the end for sure, and many more filtering methods will be added, maybe with the support of chaining one after another. This is just a baby step!&lt;/p&gt;
&lt;h3 id=&quot;server-side-filtering-vs-client-side-filtering?&quot;&gt;Server-side Filtering vs Client-Side Filtering?&lt;/h3&gt;&lt;p&gt;Now that we know on what query params the filter should work, we need to decide where to do the filtering. Should we do it on the client machine or do it on our server and pass the processed and filtered data to the client? In any filtering method, we need to traverse the whole graph. The JS engine in the browser is doing rendering stuff, complex calculation, etc. With all these processes, doing a full traversal of the dataset having more than a million nodes is going to take a lot of time and memory. The above claim assumes that we have a moderately dense graph. On the other hand, another strategy to accomplish graph filtering could be to delegate that load to a server, and the client‚Äôs browser can ask for a fresh copy of the filtered data whenever needed. As mentioned above the client-side filtering has serious shortcomings and user experience won‚Äôt be very good with browser freezing and frame drops. So, that's why we decided to go with the latter option i.e server-side filtering.&lt;/p&gt;
&lt;div style=&quot;text-align: center;&quot;&gt;
    &lt;figure&gt;
        &lt;img src=&quot;filtering-in-action.gif&quot; alt=&quot;Filtering In Action&quot; style=&quot;border: 1px solid black&quot;&gt;
        &lt;figcaption&gt;Filtering In Action&lt;/figcaption&gt;
    &lt;/figure&gt;
&lt;/div&gt;&lt;h2 id=&quot;task-3:-new-design&quot;&gt;Task 3: New Design&lt;/h2&gt;&lt;p&gt;My third task was to upgrade the front-end design of the project. It now has a very clean and refreshing look along with the support for both light and dark theme. Check out our webpage in dark mode and do let us know if it saves your PC energy consumption (As claimed by some websites). Now you all can visit the Linked Commons webpage at mid-night too, no strain to the eyes. ;)&lt;/p&gt;
&lt;div style=&quot;text-align: center; width: 90%; margin-left: 5%;&quot;&gt;
    &lt;figure&gt;
        &lt;img src=&quot;new-design-light.png&quot; alt=&quot;Light Theme&quot; style=&quot;border: 1px solid black&quot;&gt;
        &lt;figcaption&gt;Linked Commons - Light Theme&lt;/figcaption&gt;
    &lt;/figure&gt;
&lt;/div&gt;&lt;h2 id=&quot;next-steps&quot;&gt;Next steps&lt;/h2&gt;&lt;p&gt;In the next two weeks, I will be working on the following features.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Implement suggestions API on the server and integrate it with the frontend&lt;/li&gt;
&lt;li&gt;Update the visualization with a more recent and bigger dataset&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h2&gt;&lt;p&gt;Overall, it was fantastic and rejuvenating experience working on these tasks. Now that you have read this blog till the end, I hope that you enjoyed it. For more information visit our &lt;a href=&quot;https://github.com/creativecommons/cccatalog-dataviz/&quot;&gt;Github repo&lt;/a&gt;. We are looking forward to hearing from you on linked commons. Our &lt;a href=&quot;https://creativecommons.slack.com/channels/cc-dev-cc-catalog-viz&quot;&gt;slack&lt;/a&gt; doors are always open to you, see you there. :)&lt;/p&gt;
</content>
  </entry>
  <entry xml:base="http://opensource.creativecommons.org/blog/entries/cc-search-accessibility-week5-6/">
    <title type="text">Internationalization continued: Modifying tests</title>
    <id>urn:uuid:91d205ed-b94e-3d2a-9c30-5af7f04506ac</id>
    <updated>2020-07-10T00:00:00Z</updated>
    <link href="http://opensource.creativecommons.org/blog/entries/cc-search-accessibility-week5-6/" />
    <author>
      <name>AyanChoudhary</name>
    </author>
    <content type="html">&lt;p&gt;These are the fifth and sixth weeks of my internship with CC. I am working on improving the accessibility of cc-search and internationalizing it as well.
This post contains yet another important aspect to be taken care of while internationalizing the Vue components, i.e. modifying tests to include the changes.&lt;/p&gt;
&lt;p&gt;The components which were left are the two pages displaying the most content:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a href=&quot;https://github.com/creativecommons/cccatalog-frontend/blob/develop/src/pages/BrowsePage.vue&quot;&gt;Browse page&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://github.com/creativecommons/cccatalog-frontend/blob/develop/src/pages/PhotoDetailPage.vue&quot;&gt;ImageDetail page&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;The above two pages too were handled similar to the remaining pages, special care had to be taken in case of ImageDetail page since there are too many components in different files.
By this point we also have our json structure figured out, mostly and are ready to push the json for fetching further translations.&lt;/p&gt;
&lt;p&gt;Now let's look at the modifications required in the tests. We generally use &lt;code&gt;$t&lt;/code&gt; to access strings from the locales json, but this method/custom-component is not present in the testing vue instance, so we had to inject this method usin localVue and a custom i18n instance.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;const localVue = createLocalVue();
localVue.use(Vuex);
localVue.use(VueI18n);
const messages = require('@/locales/en.json');

const i18n = new VueI18n({
  locale: 'en',
  fallbackLocale: 'en',
  messages,
});
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now we inject this 18n component into our vue instance and we have access to our &lt;code&gt;$t&lt;/code&gt;, but there is still one more step left.
We still need to mock its functionality in the tests. So we create a mock &lt;code&gt;$t&lt;/code&gt; instance to mock in our component. The final code is given below:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;const $t = (key) =&amp;gt; i18n.messages[key];

options = {
    mocks: {
        $t,
    },
};
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now we are ready to render our component using these custom options with mocks for testing.&lt;/p&gt;
&lt;p&gt;And &lt;em&gt;drum rolls&lt;/em&gt; we have successfully completed Internationalization of the complete cc search. Below are the images for some of the completed pages:&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/blog/entries/cc-search-accessibility-week5-6/final.png&quot; alt=&quot;final.png&quot;&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/blog/entries/cc-search-accessibility-week5-6/finalAbout.png&quot; alt=&quot;finalAbout.png&quot;&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/blog/entries/cc-search-accessibility-week5-6/finalImageDetail.png&quot; alt=&quot;finalImageDetail.png&quot;&gt;&lt;/p&gt;
&lt;p&gt;The issues closed with the completion of Internationalization are:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a href=&quot;https://github.com/creativecommons/cccatalog-frontend/issues/487&quot;&gt;[META] Internationalisation (i18n) Setup&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://github.com/creativecommons/cccatalog-frontend/issues/941&quot;&gt;Set up vue-i18n infrastructure&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://github.com/creativecommons/cccatalog-frontend/issues/942&quot;&gt;Create locale messages format JSON structure&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://github.com/creativecommons/cccatalog-frontend/issues/943&quot;&gt;Allow users to change locale on the client&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;You can track the work done for these weeks through this PR:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a href=&quot;https://github.com/creativecommons/cccatalog-frontend/pull/1040&quot;&gt;Localize browsepage and single-result page&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;The progress of the project can be tracked on &lt;a href=&quot;https://github.com/creativecommons/cccatalog-frontend&quot;&gt;cc-search&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;CC Search Accessiblity is my GSoC 2020 project under the guidance of &lt;a href=&quot;https://creativecommons.org/author/zackcreativecommons-org/&quot;&gt;Zack Krida&lt;/a&gt; and &lt;a href=&quot;https://opensource.creativecommons.org/blog/authors/akmadian/&quot;&gt;Ari Madian&lt;/a&gt;, who is the primary mentor for this project, &lt;a href=&quot;https://creativecommons.org/author/annacreativecommons-org/&quot;&gt;Anna Tumad√≥ttir&lt;/a&gt; for helping all along and engineering director &lt;a href=&quot;https://creativecommons.org/author/kriticreativecommons-org/&quot;&gt;Kriti
Godey&lt;/a&gt;, have been very supportive.&lt;/p&gt;
</content>
  </entry>
  <entry xml:base="http://opensource.creativecommons.org/blog/entries/legal-database-coding-mid-term/">
    <title type="text">CC Legal Database: Coding and Mid-term status</title>
    <id>urn:uuid:0283bfb3-3e0e-3c6a-a70b-02df13f31235</id>
    <updated>2020-07-08T00:00:00Z</updated>
    <link href="http://opensource.creativecommons.org/blog/entries/legal-database-coding-mid-term/" />
    <author>
      <name>krysal</name>
    </author>
    <content type="html">&lt;p&gt;We are already in the second half of the time stipulated for the project and it is time to pause for review the initial plan, celebrate the objectives achieved and think about what remains to be done.&lt;/p&gt;
&lt;h2 id=&quot;initial-plan&quot;&gt;Initial plan&lt;/h2&gt;&lt;p&gt;Initially, two weeks were allocated to do the redesign for the new site. I thought there would be plenty of time here, &lt;em&gt;is just design&lt;/em&gt; I said to myself, despite not having done any serious project in Figma before beyond a few sketches. Later we will see I was wrong here. This included creating new Vocabulary components if necessary. Between the second and third weeks, I would create the data models (for Django and therefore for the database as well) and from the fourth week onwards it would start to implement all this in code: make the Homepage, listing, details pages and the others.&lt;/p&gt;
&lt;h2 id=&quot;issues-in-the-way&quot;&gt;Issues in the way&lt;/h2&gt;&lt;p&gt;One task that took longer than expected was to finish the designs, a key point because the other tasks depended on this. Though the initial scheme was ready on time, as it was discussed with the stakeholders new requirements became evident, so more modifications had to be made. For example, on the &lt;a href=&quot;https://labs.creativecommons.org/caselaw/&quot;&gt;current site&lt;/a&gt;, the way to explore cases and scholarship is by country, and in principle, this would stay the same way and I designed with that in mind, but talking to our internal user (which acts as a &lt;em&gt;product owner&lt;/em&gt; here) was better to change this scheme to one for labels or categories that are more related with both entities. Highlighting the case of the Scholarship model, in which the attribute of the country was eliminated because it is not so relevant, and although it seemed somewhat a small thing, this also caused changes in the design of the home page, the listings and how the content of the database will be explored in general. Design for a good user experience is not so easy as a non-designer may think. There were times when there was a lack of ideas but the important thing is to make decisions and move forward, in later iterations it will be improved.&lt;/p&gt;
&lt;p&gt;As in all software development, unexpected things happen and errors will appear no matter how much you plan ahead, for the fourth week I had planned to build a continuous integration system to have a server where anyone can see the progress of my changes, however, there were a few inconveniences that had me googling for a couple of days, publishing a Django project in Heroku can be tricky, specially regarding static files (assets like style sheets and scripts) if they are generated by Heroku at some point in the deployment pipeline, depending on the phase in which it is carried out, they can be lost in the ephemeral file system of Heroku, a process that I will not delve into here but that seems important to me to highlight if anyone else  has similar problems.&lt;/p&gt;
&lt;h2 id=&quot;progress-so-far&quot;&gt;Progress so far&lt;/h2&gt;&lt;p&gt;I have managed to finish the main tasks and I would say that even the initially expected result has been improved. So I can list the following achievements:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Redesigned the entire website using the Figma Design Library&lt;/li&gt;
&lt;li&gt;Built first pages: Home, listing and details pages for both Cases and Scholarship, and one for the FAQs.&lt;/li&gt;
&lt;li&gt;Create a GitHub Action to lint every PR and check if it follows the project's code style&lt;/li&gt;
&lt;li&gt;Deployment of the Django project on Heroku with a CI process linked to a GitHub repository, see the live development site &lt;a href=&quot;https://cc-caselaw.herokuapp.com/&quot;&gt;here&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;It is said quickly but each task carries its considerable workload. It's been a good result so far, I've learned a lot of things along the way, like basic use of Figma, use of Storybook (related to Vocabulary components), good code security practices, some accessibility details, and more.&lt;/p&gt;
&lt;h2 id=&quot;plan-for-the-second-half-of-the-timeline&quot;&gt;Plan for the second half of the timeline&lt;/h2&gt;&lt;p&gt;There are some tasks due from past weeks, such as build forms for Case and Scholarship submissions, but I am confident that now that the project has reached a stable state I can do it quickly in the next days. Other tasks were moved for later: searching records and filtering by tags moved after forms are created, so I can finish the visual parts of the site first and focus on functional work without shifting between types of tasks.&lt;/p&gt;
&lt;p&gt;The tasks and they order have changed, like I mentioned earlier, requirements were modified (a bit) so some tasks I planned for last weeks are not necessary anymore or are done already out-of-box with Django admin (benefits of choosing a batteries included framework!). In general, I don't think the initial plan was wrong, we just went through the natural evolution of a product software. Mentors have also been very helpful in keeping a reasonable scope and adjusting priorities.&lt;/p&gt;
&lt;p&gt;After main functionalities are done we can start making improvements, as we already identified some nice to have features but not so important at the moment. Stay tuned for more to come.&lt;/p&gt;
</content>
  </entry>
  <entry xml:base="http://opensource.creativecommons.org/blog/entries/integration-vocabulary-ccos/">
    <title type="text">Integration of Vocabulary with CCOS.</title>
    <id>urn:uuid:220be94d-1b9f-3d0a-8f65-fe0449aa3848</id>
    <updated>2020-07-08T00:00:00Z</updated>
    <link href="http://opensource.creativecommons.org/blog/entries/integration-vocabulary-ccos/" />
    <author>
      <name>dhruvi16</name>
    </author>
    <content type="html">&lt;p&gt;This blog demonstrates the project I am working on during the course of my Outreachy internship. My project involves redesigning and reimplementing one of the web products of the CC network using our new cohesive design library ‚Äî &lt;a href=&quot;https://cc-vocabulary.netlify.app/?path=/docs/vocabulary-introduction--page&quot;&gt;Vocabulary&lt;/a&gt;. After my internship is completed, the &lt;a href=&quot;https://opensource.creativecommons.org/&quot;&gt;Creative Commons Open Source&lt;/a&gt; website will have a complete revamped interface that will extensively use Vocabulary components.&lt;/p&gt;
&lt;h2 id=&quot;the-problem&quot;&gt;The Problem -&lt;/h2&gt;&lt;p&gt;There exists a large variety of web products across the Creative Commons network. These products serve different purposes for the network and so do they vary in the way of presenting the existing content. So, to conquer the inconsistency across the different products we have our coherent design system called Vocabulary.&lt;/p&gt;
&lt;p&gt;If we come to the current CC Open Source website, it is quite off-track considering our new design system Vocabulary. The styles and components of the website are not well aligned with the components of the Vocabulary. And thus it lacks harmony and consistency concerning the brand.&lt;/p&gt;
&lt;p&gt;The purpose of a design system gets dissolved if it is not well incorporated with the products and we do have this problem with the CC Open Source website. Hence, there was a need for a redesign of CCOS as per the new Design Library. This project aims to rectify the problems and inconsistencies of the CCOS website and build a completely new website (as per Vocabulary).&lt;/p&gt;
&lt;h2 id=&quot;the-solution&quot;&gt;The Solution -&lt;/h2&gt;&lt;p&gt;I started with trying out different mock-ups for the new website in Figma. You can see what I tried to make &lt;a href=&quot;https://www.figma.com/file/ka3zs1iYnqJvyLnvAV3cW7/Home-proposals&quot;&gt;here&lt;/a&gt;. And then with the help of our UX designer Francisco, we created all the mock-ups and finalized how the website will look in a couple of weeks, here is the &lt;a href=&quot;https://www.figma.com/file/mttcugI1UxvCJRKE5sdpbO/Mockups?node-id=759%3A516&quot;&gt;link&lt;/a&gt; for that.&lt;/p&gt;
&lt;p&gt;I started my internship with going through the website‚Äôs tech stack, the website is made using &lt;a href=&quot;https://www.getlektor.com/&quot;&gt;Lektor&lt;/a&gt;, with which I was not very familiar. I read the official docs, went through projects, tried making demo projects, and took help from mentors wherever I got stuck.&lt;/p&gt;
&lt;p&gt;To keep the project clean I added a theme that only has templates for the project and alters no content (as per aim). While updating templates, some components were not available in the Vocabulary yet, so I worked on adding those components to the library. And then used them in my new templates.&lt;/p&gt;
&lt;p&gt;I have thoroughly enjoyed contributing to this project as I got to learn so much. And I am excited for what‚Äôs next to come in the upcoming weeks.&lt;/p&gt;
</content>
  </entry>
  <entry xml:base="http://opensource.creativecommons.org/blog/entries/cc-search-accessibility-week3-4/">
    <title type="text">Internationalization Continued: Handling strings in the store</title>
    <id>urn:uuid:147fc2ec-5c3d-314b-9cf0-4baa4a84a202</id>
    <updated>2020-06-26T00:00:00Z</updated>
    <link href="http://opensource.creativecommons.org/blog/entries/cc-search-accessibility-week3-4/" />
    <author>
      <name>AyanChoudhary</name>
    </author>
    <content type="html">&lt;p&gt;These are the second two weeks of my internship with CC. I am working on improving the accessibility of cc-search and internationalizing it as well.
The internationalization work from the previous post is continued here and we also solve an interesting issue of translating strings from the Vuex store.&lt;/p&gt;
&lt;p&gt;During this period I removed all the hardcoded strings from the static pages which include:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;About Page&lt;/li&gt;
&lt;li&gt;Collections Page&lt;/li&gt;
&lt;li&gt;Search Guide Page&lt;/li&gt;
&lt;li&gt;Feedback Page &lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;All of the above pages were then internationalized following the same procedure as detailed in the previous post.
While internationalizing the homepage we ran into an interesting problem:&lt;/p&gt;
&lt;p&gt;The licenses strings were being accessed from the store and those too had to be internationalized.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;licenseTypes: [
    { code: 'commercial', name: 'Use commercially', checked: false },
    { code: 'modification', name: 'Modify or adapt', checked: false },
]
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The code was used to store the licenses in the store in the ordered format. The challenge was to extract the name strings from each license while keeping the changes and dependencies to a minimum.
The code which we were using in the templates to load these strings was:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;&amp;lt;label
        class=&quot;checkbox margin-right-big&quot;
        :for=&quot;licenseType.code&quot;
        :key=&quot;index&quot;
      &amp;gt;
        &amp;lt;input
          :id=&quot;licenseType.code&quot;
          type=&quot;checkbox&quot;
          :checked=&quot;licenseType.checked&quot;
          name=&quot;lt&quot;
          :value=&quot;licenseType.code&quot;
          @input=&quot;onFilterChanged(licenseType.code)&quot;
        /&amp;gt;
&amp;lt;/ label&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;So after some discussion and a great insight by @brenoferreira we came up with the idea to change to name field from the store to point to our extracted internationalization strings.
This proved to be very helpful as we managed to keep changes to a minimum without using any extra dependencies.
The code after implementing the changes is:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;licenseTypes: [
    { code: 'commercial', name: 'filters.license-types.commercial', checked: false, },
    { code: 'modification', name: 'filters.license-types.modification', checked: false,},
]
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;&amp;lt;label
        class=&quot;checkbox margin-right-big&quot;
        :for=&quot;licenseType.code&quot;
        :key=&quot;index&quot;
      &amp;gt;
        &amp;lt;input
          :id=&quot;licenseType.code&quot;
          type=&quot;checkbox&quot;
          :checked=&quot;licenseType.checked&quot;
          name=&quot;lt&quot;
          :value=&quot;licenseType.code&quot;
          @input=&quot;onFilterChanged(licenseType.code)&quot;
        /&amp;gt;
        {{ $t(licenseType.name) }}
&amp;lt;/label&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The rest of the internationalization stuff was string extractions and template modifications to accomodate the the translated strings.
And we are done with these two weeks, we be back with another post after two weeks.&lt;/p&gt;
&lt;p&gt;You can track the work done for these weeks through these PRs:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a href=&quot;https://github.com/creativecommons/cccatalog-frontend/pull/1024&quot;&gt;Internationalize About Page and Search Guide Page&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://github.com/creativecommons/cccatalog-frontend/pull/1031&quot;&gt;Internationalize feedback page, collections page and not found page&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;The progress of the project can be tracked on &lt;a href=&quot;https://github.com/creativecommons/cccatalog-frontend&quot;&gt;cc-search&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;CC Search Accessiblity is my GSoC 2020 project under the guidance of &lt;a href=&quot;https://creativecommons.org/author/zackcreativecommons-org/&quot;&gt;Zack Krida&lt;/a&gt; and &lt;a href=&quot;https://opensource.creativecommons.org/blog/authors/akmadian/&quot;&gt;Ari Madian&lt;/a&gt;, who is the primary mentor for this project, &lt;a href=&quot;https://creativecommons.org/author/annacreativecommons-org/&quot;&gt;Anna Tumad√≥ttir&lt;/a&gt; for helping all along and engineering director &lt;a href=&quot;https://creativecommons.org/author/kriticreativecommons-org/&quot;&gt;Kriti
Godey&lt;/a&gt;, have been very supportive.&lt;/p&gt;
</content>
  </entry>
  <entry xml:base="http://opensource.creativecommons.org/blog/entries/flickr-sub-provider-retrieval/">
    <title type="text">Flickr Sub-provider Retrieval</title>
    <id>urn:uuid:1fcfc052-0144-3623-9d5f-f16949e32ae1</id>
    <updated>2020-06-24T00:00:00Z</updated>
    <link href="http://opensource.creativecommons.org/blog/entries/flickr-sub-provider-retrieval/" />
    <author>
      <name>charini</name>
    </author>
    <content type="html">&lt;h2 id=&quot;introduction&quot;&gt;Introduction&lt;/h2&gt;&lt;p&gt;The Creative Commons (CC) licensed images made available via CC Search and CC Catalog API tools are retrieved from
numerous sources (which we refer to as providers) such as Flickr and different museum collections. While the existing
implementation of the CC Catalog tools enables filtering images in various manners such as based on image tags, the
provider, and the license type, it does not facilitate searching for images from particularly valuable internal sources
(referred to as sub-providers). For example, images related to 'NASA' have significant value in the Flickr collection,
since 'NASA' related pictures are extensively used by a large audience especially for educational purposes. The aim of
my first task in the GSoC project is to implement required changes in the API script level and in the existing data in
the database, such that filtering by certain important sub-providers is made possible.&lt;/p&gt;
&lt;p&gt;While there are several providers such as Flickr, Europeana, and Smithsonian from which we require to extract
sub-providers, the consensus was to initially focus on Flickr due to that currently being in production, and since a
substantial amount of images made available via CC Search come from Flickr. Thus, in this initial blog post, I will
discuss how I addressed the requirement of sub-provider retrieval in Flickr by making the necessary changes in the
&lt;a href=&quot;https://github.com/creativecommons/cccatalog&quot;&gt;Creative Commons Catalog&lt;/a&gt; repository.&lt;/p&gt;
&lt;h2 id=&quot;research&quot;&gt;Research&lt;/h2&gt;&lt;p&gt;The primary research involved in the Flickr sub-provider retrieval task was defining which entities to identify as
sub-providers, and identifying how those sub-providers can be retrieved based on the image related information we
retain.&lt;/p&gt;
&lt;h3 id=&quot;definition-of-a-sub-provider&quot;&gt;Definition of a sub-provider&lt;/h3&gt;&lt;p&gt;It was decided that a sub-provider should be a collection of user accounts in Flickr, where this collection corresponded
to a common entity, and the common entity would reflect the sub-provider. For example, since both Flickr user accounts
&lt;em&gt;NASA HQ PHOTO&lt;/em&gt; and &lt;em&gt;NASA Johnson&lt;/em&gt; provide images related to NASA, we would represent the NASA sub-provider by those
two (and other related) user accounts.&lt;/p&gt;
&lt;p&gt;The next challenge was to determine how to identify which collections of user accounts were important to a wider
audience. The number of views per user account was an intuitive measure to rely on for this requirement. My supervisor
Brent Moran executed a query on the existing CC database to obtain the 50 most popular user accounts in Flickr. A
snippet of the query response is as follows:&lt;/p&gt;
&lt;table class=&quot;table table-striped&quot;&gt;
&lt;thead class=&quot;thead-dark&quot;&gt;&lt;tr&gt;
&lt;th&gt;user_account_name&lt;/th&gt;
&lt;th&gt;total_views&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Apollo Image Gallery&lt;/td&gt;
&lt;td&gt;1216297208&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;BioDivLibrary&lt;/td&gt;
&lt;td&gt;625528813&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;manhhai&lt;/td&gt;
&lt;td&gt;445714729&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Thomas Hawk&lt;/td&gt;
&lt;td&gt;300554527&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Sangudo&lt;/td&gt;
&lt;td&gt;258177509&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;NASA Goddard Photo and Video&lt;/td&gt;
&lt;td&gt;225143949&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Despite having a significant number of views, some of these user accounts did not appear to be worth being identified
as belonging to a sub-provider due to their lack of educational importance. Thus, we manually curated this list to
retain what we believed to be important to a wider audience.&lt;/p&gt;
&lt;h3 id=&quot;sub-provider-identification&quot;&gt;Sub-provider identification&lt;/h3&gt;&lt;p&gt;In order to identify the sub-provider each image from Flickr belonged to, it was necessary to determine which field in
the stored image data referred to the user account. Among the various information contained in an API response, only a
selected set of fields is stored on the CC end, and it was important to use such stored data for the identification of
sub-providers. We initially decided to rely on the user account name which was reflected by the &lt;em&gt;ownername&lt;/em&gt; field in
the JSON response and stored as the &lt;em&gt;creator&lt;/em&gt; in the CC database. However, we later realised that the names of accounts
could potentially change over time, and therefore was not a reliable field for extracting the sub-provider. Another
field from the JSON response that helped to uniquely identify a user account was the &lt;em&gt;owner&lt;/em&gt; field, which acted like a
unique user ID. Even though the &lt;em&gt;owner&lt;/em&gt; value was not directly stored in the CC database, it was stored as part of the
&lt;em&gt;creator URL&lt;/em&gt; field, and fortunately, all creator URLs from Flickr consisted of a common prefix plus the &lt;em&gt;owner&lt;/em&gt; value
(the user id). Thus, we decided to use the &lt;em&gt;creator URL&lt;/em&gt; value retained in the CC database for identifying sub-providers
in Flickr.&lt;/p&gt;
&lt;h2 id=&quot;implementation&quot;&gt;Implementation&lt;/h2&gt;&lt;p&gt;There are two levels at which sub-provider retrieval needs to be supported, where the first concerns the API scripts
from which we initially pull the data from different providers to keep the CC collections uptodate. The second is the
CC database level where the existing data needs to be updated to ensure that those reflect the sub-providers similar to
the newly added image information.&lt;/p&gt;
&lt;p&gt;The following sections explain how we represented the sub-provider information in the implementation, the changes made
at Flickr API script level and the database update logic to support sub-provider retrieval.&lt;/p&gt;
&lt;h3 id=&quot;representing-the-sub-provider-information&quot;&gt;Representing the sub-provider information&lt;/h3&gt;&lt;p&gt;As previously explained, we define a sub-provider as a collection of user accounts, and it was identified that the
unique user ID returned in the Flickr JSON response (referred to as the &lt;em&gt;owner&lt;/em&gt;) was a reliable field for uniquely
identifying each user account. For the time being, we focused on sub-providers NASA, SpaceX, and the Biodiversity
Heritage Library (BioDivLibrary) based on their considerable importance to the community. Using the top six NASA related
user accounts, the 'Official SpaceX Photos' user account, and the 'BioDivLibrary' user account as filtered by Brent's
query, we identified the corresponding user IDs (content of the &lt;em&gt;owner&lt;/em&gt; field) using the
&lt;strong&gt;flickr.people.findByUsername&lt;/strong&gt; method made available in the Flickr API. The mapping between the sub-provider and the
corresponding user IDs was stored in a dictionary as follows.&lt;/p&gt;
&lt;div class=&quot;hll&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;FLICKR_SUB_PROVIDERS&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;s1&quot;&gt;&amp;#39;nasa&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;s1&quot;&gt;&amp;#39;24662369@N07&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# NASA Goddard Photo and Video&lt;/span&gt;
        &lt;span class=&quot;s1&quot;&gt;&amp;#39;35067687@N04&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# NASA HQ PHOTO&lt;/span&gt;
        &lt;span class=&quot;s1&quot;&gt;&amp;#39;29988733@N04&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# NASA Johnson&lt;/span&gt;
        &lt;span class=&quot;s1&quot;&gt;&amp;#39;28634332@N05&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# NASA&amp;#39;s Marshall Space Flight Center&lt;/span&gt;
        &lt;span class=&quot;s1&quot;&gt;&amp;#39;108488366@N07&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# NASAKennedy&lt;/span&gt;
        &lt;span class=&quot;s1&quot;&gt;&amp;#39;136485307@N06&amp;#39;&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# Apollo Image Gallery&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;},&lt;/span&gt;
    &lt;span class=&quot;s1&quot;&gt;&amp;#39;bio_diversity&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;s1&quot;&gt;&amp;#39;61021753@N02&amp;#39;&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# BioDivLibrary&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;},&lt;/span&gt;
    &lt;span class=&quot;s1&quot;&gt;&amp;#39;spacex&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;s1&quot;&gt;&amp;#39;130608600@N05&amp;#39;&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# Official SpaceX Photos&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Since this information was required both at the API script level and the database level to retrieve sub-providers, we
stored it in a common file accessible from both levels.&lt;/p&gt;
&lt;p&gt;The next challenge was to identify how to reflect the sub-provider of each image using the existing database schema.
There are two different fields in the database as &lt;em&gt;provider&lt;/em&gt; and the &lt;em&gt;source&lt;/em&gt;. The &lt;em&gt;provider&lt;/em&gt; reflects the main source
from which the images are retrieved, which happens to be 'Flickr' in this scenario. The &lt;em&gt;source&lt;/em&gt; field reflects an
organisation or entity that has published the photos using 'Flickr' in this instance (or some other site that we
recognise as a &lt;em&gt;provider&lt;/em&gt;).The &lt;em&gt;source&lt;/em&gt; field was previously not utilised and was simply set to the value of the
&lt;em&gt;provider&lt;/em&gt; in the Flickr API script. Based on internal discussions, it was decided that the &lt;em&gt;source&lt;/em&gt; field was to be
used for reflecting the sub-provider, if the corresponding image belonged to any of the user accounts contained in our
dictionary &lt;em&gt;FLICKR_SUB_PROVIDERS&lt;/em&gt;. Otherwise the &lt;em&gt;source&lt;/em&gt; was set to the default &lt;em&gt;provider&lt;/em&gt; value 'Flickr'.&lt;/p&gt;
&lt;h3 id=&quot;sub-provider-retrieval-at-api-script-level&quot;&gt;Sub-provider retrieval at API script level&lt;/h3&gt;&lt;p&gt;Retrieving the sub-provider from the Flickr API script was fairly straightforward. Since the complete JSON response was
available at the API script level, we did not have to worry about retrieving the user ID (&lt;em&gt;owner&lt;/em&gt; value) from the
&lt;em&gt;creator URL&lt;/em&gt; field in our data. Rather, we simply get the owner value from the API response, and try to search for it
in the &lt;em&gt;FLICKR_SUB_PROVIDERS&lt;/em&gt; dictionary as follows.&lt;/p&gt;
&lt;div class=&quot;hll&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;owner&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;image_data&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;get&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;owner&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;strip&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;source&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;next&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;s&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;s&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;FLICKR_SUB_PROVIDERS&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;owner&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;FLICKR_SUB_PROVIDERS&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;s&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]),&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&amp;#39;Flickr&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Since the collection of user IDs corresponding to each sub-provider is represented as a set, the time complexity for
each sub-provider is O(1) and therefore the total time complexity is linear in the number of sub-providers (that is O(n)
for n sub-providers). Due to the number of sub-providers of interest being minimal (currently it is 3), this search
logic is quite efficient.&lt;/p&gt;
&lt;p&gt;Once we determine whether the &lt;em&gt;source&lt;/em&gt; field should be set to a sub-provider value or the default ‚ÄòFlickr‚Äô value with
the given logic, we set the &lt;em&gt;source&lt;/em&gt; value in the image store likewise.&lt;/p&gt;
&lt;h3 id=&quot;sub-provider-update-at-the-database-level&quot;&gt;Sub-provider update at the database level&lt;/h3&gt;&lt;p&gt;When updating sub-providers at the database level, we need to rely on the creator URL field to obtain the user ID of
each image. The creator URL is of the following form.&lt;/p&gt;
&lt;p&gt;'&lt;a href=&quot;https://www.flickr.com/photos/&quot;&gt;https://www.flickr.com/photos/&lt;/a&gt;' + &lt;em&gt;User ID&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;For the purpose of automating the process of updating the database to reflect sub-providers, I added the necessary SQL
queries and made it accessible via the Apache Airflow UI. The database update logic is as follows.&lt;/p&gt;
&lt;p&gt;As the first step, I create a temporary table and populate it with the sub-provider values and the corresponding
creator URLs. This is done by iterating through the sub-provider, user ID value pairs in the &lt;em&gt;FLICKR_SUB_PROVIDERS&lt;/em&gt;
dictionary, and concatenating the user ID with the prefix '&lt;a href=&quot;https://www.flickr.com/photos/&quot;&gt;https://www.flickr.com/photos/&lt;/a&gt;' to obtain the creator URL.&lt;/p&gt;
&lt;p&gt;The initial plan was to then perform a join on the CC image table (where all the image related information is stored)
with the temporary table on the condition that the creator URL from the image table matches that of the temporary table.
This query which filters all the rows in the image table where we need to update the sub-provider values, looks as
follows.&lt;/p&gt;
&lt;div class=&quot;hll&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;UPDATE&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;image_table&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;SET&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;col&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;SOURCE&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;public&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;temp_table&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;col&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;SUB_PROVIDER&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;public&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;temp_table&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;WHERE&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;image_table&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;col&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;CREATOR_URL&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;public&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;temp_table&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;col&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;CREATOR_URL&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;};&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;However, a major concern with this query, as my supervisor Brent Moran pointed out, was that it locked all the rows
which matched the 'WHERE' clause at once. With respect to the magnitude of the Flickr data available in the CC image
table, this meant that the above query would lock millions of rows, thus hindering the execution of other queries on
the image table. To mitigate this issue, we decided to update the SQL query as follows, such that we perform a 'SELECT'
query on the rows to be updated by joining the previously created temporary table with the CC image table (a 'SELECT'
query does not lock the table), and iterate row by row over the query result to set the &lt;em&gt;source&lt;/em&gt; value in the image
table to the sub-provider value.&lt;/p&gt;
&lt;div class=&quot;hll&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;SELECT&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;col&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;FOREIGN_ID&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;foreign_id&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;public&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;temp_table&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;col&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;PROVIDER&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sub_provider&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;image_table&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;INNER&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;JOIN&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;public&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;temp_table&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;ON&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;image_table&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;col&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;CREATOR_URL&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;public&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;temp_table&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;col&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;CREATOR_URL&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;AND&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;image_table&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;col&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;PROVIDER&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&amp;#39;Flickr&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Let us refer to the result produced from the SELECT query as &amp;#39;selected_records&amp;#39;&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;foreign_id&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sub_provider&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;selected_records&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;UPDATE&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;image_table&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;SET&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;col&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;SOURCE&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&amp;#39;&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{sub_provider}&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;WHERE&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;image_table&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;col&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;PROVIDER&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&amp;#39;Flickr&amp;#39;&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;AND&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;MD5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;({&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;image_table&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;col&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;FOREIGN_ID&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;})&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;MD5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{foreign_id}&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;To make this functionality available from the Airflow UI, I have added the Airflow DAG
&lt;em&gt;flickr_sub_provider_update_workflow&lt;/em&gt;.
The changes in the source field after updating the image table in the database looks like follows.&lt;/p&gt;
&lt;table class=&quot;table table-striped&quot;&gt;
&lt;thead class=&quot;thead-dark&quot;&gt;&lt;tr&gt;
&lt;th style=&quot;text-align:center&quot;&gt;id&lt;/th&gt;
&lt;th style=&quot;text-align:center&quot;&gt;provider&lt;/th&gt;
&lt;th style=&quot;text-align:center&quot;&gt;source before the update&lt;/th&gt;
&lt;th style=&quot;text-align:center&quot;&gt;source after the update&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&quot;text-align:center&quot;&gt;14369&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;flickr&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;flickr&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;bio_diversity&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&quot;text-align:center&quot;&gt;14372&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;flickr&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;flickr&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;bio_diversity&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&quot;text-align:center&quot;&gt;14375&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;flickr&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;flickr&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;bio_diversity&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&quot;text-align:center&quot;&gt;14378&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;flickr&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;flickr&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;bio_diversity&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&quot;text-align:center&quot;&gt;14382&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;flickr&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;flickr&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;bio_diversity&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&quot;text-align:center&quot;&gt;40784&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;flickr&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;flickr&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;nasa&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&quot;text-align:center&quot;&gt;47237&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;flickr&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;flickr&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;nasa&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&quot;text-align:center&quot;&gt;47242&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;flickr&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;flickr&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;nasa&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&quot;text-align:center&quot;&gt;47244&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;flickr&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;flickr&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;nasa&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&quot;text-align:center&quot;&gt;47245&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;flickr&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;flickr&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;nasa&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;For more information regarding the implementation, please refer to the following PR:
&lt;a href=&quot;https://github.com/creativecommons/cccatalog/pull/420&quot;&gt;https://github.com/creativecommons/cccatalog/pull/420&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&quot;acknowledgement&quot;&gt;Acknowledgement&lt;/h2&gt;&lt;p&gt;I express my gratitude to Brent Moran and Anna Tumad√≥ttir for their assistance with my first task in GSoC 2020 by
helping me to filter the sub-providers of interest and conducting the necessary research.&lt;/p&gt;
</content>
  </entry>
  <entry xml:base="http://opensource.creativecommons.org/blog/entries/cc-search-accessibility-week1-2/">
    <title type="text">CC Search, Setting up vue-i18n and internationalizing homepage</title>
    <id>urn:uuid:b6330fc6-4ba0-3d32-96cf-057eec67072a</id>
    <updated>2020-06-10T00:00:00Z</updated>
    <link href="http://opensource.creativecommons.org/blog/entries/cc-search-accessibility-week1-2/" />
    <author>
      <name>AyanChoudhary</name>
    </author>
    <content type="html">&lt;p&gt;These are the first two weeks of my internship with CC. I am working on improving the accessibility of cc-search and internationalizing it as well.
We started with first compiling the accessibility reports from accessibility insights, lighthouse and pa11y into a single document and then opening up appropriate issues ont he repo to address them.&lt;/p&gt;
&lt;p&gt;The accessibility issues are listed here:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a href=&quot;https://github.com/creativecommons/cccatalog-frontend/issues/996&quot;&gt;Accessibility - Improve labels&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://github.com/creativecommons/cccatalog-frontend/issues/997&quot;&gt;Evaluate keyboard navigation effectiveness&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://github.com/creativecommons/cccatalog-frontend/issues/998&quot;&gt;Fix color contrast problems&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://github.com/creativecommons/cccatalog-frontend/issues/999&quot;&gt;Improve elements markup&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://github.com/creativecommons/cccatalog-frontend/issues/1000&quot;&gt;Evaluate any accessibility linter tools&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;The decision was made to audit the tab indices along with internationalizing the page.
The accessibility changes will be done after the completion of internationalization as the aria-labels will have to be internationalized as well.&lt;/p&gt;
&lt;p&gt;The first two weeks involved setting up vue-i18n, auditing the tab index for homepage and internationalizing it.
The tab index adit for homepage is displayed:&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/blog/entries/cc-search-accessibility-week1-2/audit.png&quot; alt=&quot;audit.png&quot;&gt;&lt;/p&gt;
&lt;p&gt;The internationalization part was pretty straightforward, we just had to export all the strings to the JSON files and load transaltions through the i18n module.
For complex elements of the type &lt;code&gt;string &amp;lt;tag&amp;gt;string&amp;lt;/tag&amp;gt; string&lt;/code&gt; I went for the templating method.
Here we use the v-slot attribute of the i18n functional component to convert the element into a template where the tag occupies a slot in the syntax.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;&amp;lt;i18n path=&quot;footer.caption.label&quot; tag=&quot;p&quot; class=&quot;caption&quot;&amp;gt;
    &amp;lt;template v-slot:noted&amp;gt;
        &amp;lt;a href=&quot;https://creativecommons.org/policies#license&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&amp;gt;{{$t('footer.caption.noted')}}&amp;lt;/a&amp;gt;
    &amp;lt;/template&amp;gt;
    &amp;lt;template v-slot:attribution&amp;gt;
        &amp;lt;a href=&quot;https://creativecommons.org/licenses/by/4.0/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&amp;gt;
        {{$t('footer.caption.attribution')}}
        &amp;lt;/a&amp;gt;
    &amp;lt;/template&amp;gt;
    &amp;lt;template v-slot:icons&amp;gt;
        &amp;lt;a href=&quot;https://fontawesome.com/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot; class=&quot;has-text-white&quot;&amp;gt;
        {{$t('footer.caption.icons')}}
        &amp;lt;/a&amp;gt;
    &amp;lt;/template&amp;gt;
&amp;lt;/i18n&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The final outcome looks pretty good:&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/blog/entries/cc-search-accessibility-week1-2/final.png&quot; alt=&quot;final.png&quot;&gt;&lt;/p&gt;
&lt;p&gt;And voila we are done with the first two weeks. I also internationalized the header and the footer along with the homepage.
You can track the work done for these weeks through these PRs:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a href=&quot;https://github.com/creativecommons/cccatalog-frontend/pull/1007&quot;&gt;setup internationalization plugin&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://github.com/creativecommons/cccatalog-frontend/pull/1013&quot;&gt;Internationalize homepage, header and footer&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;The progress of the project can be tracked on &lt;a href=&quot;https://github.com/creativecommons/cccatalog-frontend&quot;&gt;cc-search&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;CC Search Accessiblity is my GSoC 2020 project under the guidance of &lt;a href=&quot;https://opensource.creativecommons.org/blog/authors/akmadian/&quot;&gt;Ari Madian&lt;/a&gt;, who is the primary mentor for this project, &lt;a href=&quot;https://creativecommons.org/author/annacreativecommons-org/&quot;&gt;Anna Tumad√≥ttir&lt;/a&gt; for helping all along and engineering director &lt;a href=&quot;https://creativecommons.org/author/kriticreativecommons-org/&quot;&gt;Kriti
Godey&lt;/a&gt;, have been very supportive.&lt;/p&gt;
</content>
  </entry>
  <entry xml:base="http://opensource.creativecommons.org/blog/entries/science-museum-implementation/">
    <title type="text">Science Museum provider implementation</title>
    <id>urn:uuid:7960ba6c-0bbb-300e-86d8-4744b9b0ee25</id>
    <updated>2020-06-10T00:00:00Z</updated>
    <link href="http://opensource.creativecommons.org/blog/entries/science-museum-implementation/" />
    <author>
      <name>srinidhi</name>
    </author>
    <content type="html">&lt;h2 id=&quot;introduction&quot;&gt;Introduction&lt;/h2&gt;&lt;p&gt;CC catalog project is responsible for collecting CC licensed images available in the web,  CC licensed images are hosted by different
sources, these sources that provide the images and its metadata are called providers. Currently, images are collected from providers using two methods
Common Crawl and API based crawl. Common Crawl data is an open repository of web crawled data and we use that data to get the necessary image metadata 
for that provider &lt;a href=&quot;https://commoncrawl.org/the-data/get-started/&quot;&gt;more information&lt;/a&gt;. API crawl is implemented using the API endpoint maintained 
by the providers. The main problem with Common Crawl is that we don't have control over the data they crawl, and this sometimes results poor 
data quality whereas with API based crawl we have access to the information available. API based crawl is better when we need to update image
metadata and reqular intervals.&lt;/p&gt;
&lt;p&gt;As a part of the internship, I will be working on moving providers from Common Crawl to API based crawl as well as integrate new providers
to the API crawl. I will be starting with the Science Museum provider.&lt;/p&gt;
&lt;h2 id=&quot;science-museum&quot;&gt;Science Museum&lt;/h2&gt;&lt;p&gt;Science museum is a provider with around 80,000 CC licensed images, currently Science museum data is ingested from Common Crawl. 
Science museum is one such provider where our data is of poor quality and there is need to improve it. This is done by moving 
Science museum to an API based crawl.&lt;/p&gt;
&lt;h2 id=&quot;api-research&quot;&gt;API research&lt;/h2&gt;&lt;p&gt;We want to index metadata using their open API &lt;a href=&quot;https://collection.sciencemuseumgroup.org.uk/search/has_image/image_license&quot;&gt;endpoint&lt;/a&gt;. 
However, before the implementation we have to ensure that the API provides necessary content and there is a systematic way to get it.
The first step is to take an object from their collection and check certain criterias.&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://collection.sciencemuseumgroup.org.uk/api/objects/co8005638&quot;&gt;sample object&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;The criteria are:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;parameters available for the API&lt;/li&gt;
&lt;li&gt;Object landing url (frontend link of the object the image is associated with) &lt;/li&gt;
&lt;li&gt;Image url (the url link of the image)&lt;/li&gt;
&lt;li&gt;CC license associated with the image&lt;/li&gt;
&lt;li&gt;creator, title and other metadata info &lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Once the above checks have been made, we need to find a way to get all the objects, this could be by paging through the records 
or partition using the parameters, etc. Since their API parameter has &lt;code&gt;page[number]&lt;/code&gt; paging would be an appropriate choice with  max size 
as 100 it would require around 800 pages to get all the objects but then since they don't allow paging a large number of results, and 
the max number of pages for Science Museum is 50 pages.This would mean we would get only 5000 objects and around 17000 images.&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://collection.sciencemuseumgroup.org.uk/search/image_license?page[size]=100&amp;amp;page[number]=50&quot;&gt;API page-50&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://collection.sciencemuseumgroup.org.uk/search/image_license?page[size]=100&amp;amp;page[number]=51&quot;&gt;API page-51&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;So we need to find a way to divide the collection into subsets such that each subset has less than or equal to 5000 objects.
Luckily, the API had another set of parameters &lt;code&gt;date[from]&lt;/code&gt; and &lt;code&gt;date[to]&lt;/code&gt; which represents the time period of the object. 
Querying the API through different time period at the same time ensuring that records in that time period don't exceed 5000 solves the problem, starting
from year 0 to year 2020 by trial and error method suitable year range was chosen.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;                                            YEAR_RANGE = [
                                                (0, 1500),
                                                (1500, 1750),
                                                (1750, 1825),
                                                (1825, 1850),
                                                (1850, 1875),
                                                (1875, 1900),
                                                (1900, 1915),
                                                (1915, 1940),
                                                (1940, 1965),
                                                (1965, 1990),
                                                (1990, 2020)
                                            ]
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;With this we have a method to ingest the desired records, but before writing the script we need to know the different licenses 
provided by the API.  We need to figure out a consistent way to identify which license and version are attached to each object.&lt;br&gt;
To do this, we ran a test script to get counts of objects under different licenses.&lt;/p&gt;
&lt;p&gt;The results are:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;+-----------------+----------+
| license_version | count(1) |
+-----------------+----------+
| CC-BY-NC-ND 2.0 |      210 |
| CC-BY-NC-ND 4.0 |     2376 |
| CC-BY-NC-SA 2.0 |        1 |
| CC-BY-NC-SA 4.0 |    61694 |
+-----------------+----------+
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Since the licenses and their versions are confirmed, we can start the implementation.&lt;/p&gt;
&lt;h2 id=&quot;implementation&quot;&gt;Implementation&lt;/h2&gt;&lt;p&gt;The implementation is quite simple in nature: we loop the through the &lt;code&gt;YEAR_RANGE&lt;/code&gt; and get all the records for that period and 
pass it on to an object data handler method that extracts the necessary details from the record and store it in the &lt;code&gt;ImageStore&lt;/code&gt;
instance. ImageStore is a class that stores image information from the provider, it stores the information in a buffer and inserts to tsv
when the buffer reached threshold limit. Due to overlapping date ranges, the metadata for some objects is collected multiple times.
So, we keep track of the record/object's id in a global variable &lt;code&gt;RECORD_IDS = []&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;Within the object data handler method before collecting details we check if the &lt;code&gt;id&lt;/code&gt; already exists in &lt;code&gt;RECORD_IDS&lt;/code&gt;. 
If it exists we move on to the next record.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;                                            for obj_ in batch_data:
                                                id_ = obj_.get(&quot;id&quot;)
                                                if id_ in RECORD_IDS:
                                                    continue
                                                RECORD_IDS.append(id_)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;code&gt;id_&lt;/code&gt; is the object id and we cannnot use this value as foreign identifier, the reason behind it is that an object could
have multiple images with it and using object id we cannot determine the image uniquely, so we must use image id that is unique
for each image. Currently image id is taken from &lt;code&gt;multimedia&lt;/code&gt;, multimedia is a field in the json response that lists multiple 
images and their metadata, for each image data in multimedia, foreign id is in &lt;code&gt;admin.uid&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;The implementation can be found &lt;a href=&quot;https://github.com/creativecommons/cccatalog/blob/master/src/cc_catalog_airflow/dags/provider_api_scripts/science_museum.py&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;h3 id=&quot;results:&quot;&gt;Results:&lt;/h3&gt;&lt;p&gt;Running the scripts we get:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Number of records recieved : &lt;code&gt;35584&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Number of images collected : &lt;code&gt;62497&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The problem with current implementation is that records with no date would be missed.&lt;/p&gt;
&lt;p&gt;Science Museum provider is the first provider I worked on as a part of the internship and thank my mentor Brent Moran for the help.&lt;/p&gt;
&lt;h3 id=&quot;additional-details-:&quot;&gt;Additional Details :&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;https://github.com/creativecommons/cccatalog/issues/302&quot;&gt;research work&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://github.com/creativecommons/cccatalog/pull/400&quot;&gt;implementation&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</content>
  </entry>
  <entry xml:base="http://opensource.creativecommons.org/blog/entries/resource-gathering/">
    <title type="text">Resource Gathering</title>
    <id>urn:uuid:1b4acbcb-fbab-372c-854f-833a05aafa23</id>
    <updated>2020-06-09T00:00:00Z</updated>
    <link href="http://opensource.creativecommons.org/blog/entries/resource-gathering/" />
    <author>
      <name>dhruvi16</name>
    </author>
    <content type="html">&lt;p&gt;As an outreachy intern, I am handling the integration of &lt;a href=&quot;https://creativecommons.org/&quot;&gt;Creative Commons&lt;/a&gt; design library ‚Äî &lt;a href=&quot;https://cc-vocabulary.netlify.app/&quot;&gt;Vocabulary&lt;/a&gt; with one of our web products ‚Äî &lt;a href=&quot;https://opensource.creativecommons.org/&quot;&gt;CC OS&lt;/a&gt;. I have been working the design library for 3‚Äì4 months now and I have enjoyed the experience the library caters and I am trying to achieve the same experience in the Open source website. To understand UX in-depth, I have been reading different resources and document this knowledge through this series of blogs. This in-depth information will help me achieve the desired experience through the library.&lt;/p&gt;
&lt;p&gt;Using a Coursera course, &lt;a href=&quot;https://www.coursera.org/learn/user-experience-design/&quot;&gt;Introduction to user experience&lt;/a&gt;, I will be describing the UX design cycle with a series of articles and this article is about describing the first step of the design cycle which is Resource Gathering.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Basic definitions&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;User experience design includes designing interfaces through which a user accomplishes a task. Designing better interfaces which can help the user to perform tasks easily.&lt;/p&gt;
&lt;p&gt;The interface consists of an input and output through which the user interacts with the system. For instance, clicking a photo requires the user to press the button (input) and an image is the desired output. Creating an affordable and usable interface is the main goal of this process. Design is a data-driven process and resource gathering is all about gathering this data.&lt;/p&gt;
&lt;p&gt;The resource gathering process is about figuring out how the task is currently accomplished by the user. There are 4 ways to gather data and below I will describe them all in detail. There are two types of data ‚Äî Quantitative (numeric) and Qualitative (thematic) and designers prefer to use both types of data as per requirement.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Naturalistic observation&lt;/strong&gt; - This includes observing the user accomplishing the task in the field. This involves the least interaction with the user and the designer watches the user performing the task from distance. The designer notes down qualitative and quantitative information about this activity. This removes the effect of social desirability of the user on the information collected but also the designer‚Äôs perception can be reflected in the collected data.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Surveys&lt;/strong&gt; - A survey can be interchangeably used with a questionnaire. In a survey, the user answers a set of questions about how he/she performs the tasks currently. The questions can be closed-ended which can provide quantitative data and also open-ended which gives us the qualitative data. This involves some amount of interaction with the user. Surveys can be held in the field or lab.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Focus Groups&lt;/strong&gt; - Focus groups are about engaging with a group of 6‚Äì10 people and talk about how they perform a task currently. This involves a lot of interaction with the users. This can be performed in a safe environment (lab) where users can open up without hesitation. The design team includes a moderator who can ask relevant questions, a note-taker who can note down the on-going conversation and a media person (optional) who can record video or take photos of the session.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Interview&lt;/strong&gt; - The interview involves asking questions to the user one-to-one about how they perform the task currently. This involves the highest amount of interaction with the user. Interviews are held in labs. The designer talks to the user about the task and collects both quantitative and qualitative data. This is the most time-taking way of collecting data but it gives the most useful data among all the methods.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
</content>
  </entry>
  <entry xml:base="http://opensource.creativecommons.org/blog/entries/legal-database-design/">
    <title type="text">CC Legal Database: Design</title>
    <id>urn:uuid:b2a2a092-d722-34fb-bb65-9103c9b4ed48</id>
    <updated>2020-06-09T00:00:00Z</updated>
    <link href="http://opensource.creativecommons.org/blog/entries/legal-database-design/" />
    <author>
      <name>krysal</name>
    </author>
    <content type="html">&lt;p&gt;Finishing the third week since the project started (for context see this &lt;a href=&quot;/blog/entries/legal-database-a-new-beginning/&quot;&gt;first post&lt;/a&gt;), so the design phase is almost over and a new site look is out of the oven. The focus on these weeks was to draw the mockups for the user-facing parts of the site, integrating styles of CC Vocabulary and to get the data model for the database.&lt;/p&gt;
&lt;h3 id=&quot;visual-styles&quot;&gt;Visual Styles&lt;/h3&gt;&lt;p&gt;The intention was to keep the content that is already present but improve its distribution and access by users. For this, the main menu was changed to provide direct links to listing of Cases and Scholarships. The old &quot;Countries&quot; page was removed and replaced by a more granular division by legal resource, so this data will be shown separately.&lt;/p&gt;
&lt;p&gt;The final look for the home site is as follows.&lt;/p&gt;
&lt;div style=&quot;text-align: center;&quot;&gt;
    &lt;figure&gt;
        &lt;img src=&quot;cc-caselaw-home.png&quot; alt=&quot;New CC Caselaw Home Mockup&quot; style=&quot;border: 1px solid black&quot;&gt;
        &lt;figcaption&gt;New Home page design with Vocabulary.&lt;/figcaption&gt;
    &lt;/figure&gt;
&lt;/div&gt;&lt;p&gt;I made use of as many Vocabulary components as possible, like header, footer and table. This way is easier to keep consistency between CC products and to develop the frontend part of the site because those components are already built and tested, though some will require certain modifications (e.g. card link with a search input), and some others have to be created from scratch, like a pagination component that is actually now required for two sites.&lt;/p&gt;
&lt;h3 id=&quot;data-model&quot;&gt;Data Model&lt;/h3&gt;&lt;p&gt;The second main task I worked on was coding the models on Django, which is in charge of creating the database schema through migrations. For this, I had to review the sources of information (CSV files, sheets, forms) and how they are used. The key point here is to keep constant communication with staff who are more involved in the &lt;em&gt;business case&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;Several iterations were required for each task as well as some researching, and while the engineering and design work never seems to end, this makes good foundations to continue and advance.&lt;/p&gt;
</content>
  </entry>
  <entry xml:base="http://opensource.creativecommons.org/blog/entries/cc-browser-extension-upcoming-improvements/">
    <title type="text">Upcoming improvements/features in CC Search Extension</title>
    <id>urn:uuid:cdf59a68-68ac-36b4-85c8-a19bb2848f33</id>
    <updated>2020-06-01T00:00:00Z</updated>
    <link href="http://opensource.creativecommons.org/blog/entries/cc-browser-extension-upcoming-improvements/" />
    <author>
      <name>makkoncept</name>
    </author>
    <content type="html">&lt;p&gt;&lt;a href=&quot;https://opensource.creativecommons.org/ccsearch-browser-extension/&quot;&gt;CC Search Extension&lt;/a&gt; is a cross-browser extension, which lets you search for and filter content that is under Creative Commons licenses. It was developed as one of the CC projects during Google Summer of Code program of 2019.&lt;/p&gt;
&lt;h3 id=&quot;the-story-so-far&quot;&gt;The story so far&lt;/h3&gt;&lt;p&gt;It's release on the extension stores of &lt;a href=&quot;https://chrome.google.com/webstore/detail/cc-search-browser-extensi/agohkbfananbebiaphblgcfhcclklfnh&quot;&gt;Chrome&lt;/a&gt;, &lt;a href=&quot;https://addons.mozilla.org/en-US/firefox/addon/cc-search-extension/&quot;&gt;Firefox&lt;/a&gt;, and &lt;a href=&quot;https://addons.opera.com/en/extensions/details/cc-search/&quot;&gt;Opera&lt;/a&gt; was accompanied by several announcements on twitter, which were well received by the community and thus the number of weekly users (i.e the number of users that have used the extension at least once during last week) drastically increased. After several weeks, the extension reached 22,000+ weekly users. But, now this number fluctuates between 9,000 - 10,000. So, what happened? Well, the majority of initial influx were the &quot;curious&quot; folks who just wanted to check out this new tool and later thought that this was not something that they might find useful. But, there are also users that are looking for a similar tool and the lack of sufficient features and capabilities of the extension made them stop using it and look for better alternatives.&lt;/p&gt;
&lt;h3 id=&quot;what-s-the-plan&quot;&gt;What's the plan&lt;/h3&gt;&lt;p&gt;The plan is to transform the extension to become competent enough to contribute to the user's workflow and be an important part of their toolkit. This will be done by adding valuable new features in addition to other enhancements and improvements.&lt;/p&gt;
&lt;p&gt;In this section, I will list several improvements and features that will be added to the extension during the upcoming months.&lt;/p&gt;
&lt;h4 id=&quot;new-filters&quot;&gt;New Filters&lt;/h4&gt;&lt;p&gt;The extension, currently supports only 3 filters: &lt;code&gt;license&lt;/code&gt;, &lt;code&gt;sources&lt;/code&gt;, and &lt;code&gt;use case&lt;/code&gt;. The support for new filters like &lt;code&gt;image type&lt;/code&gt;, &lt;code&gt;file type&lt;/code&gt;, &lt;code&gt;aspect ratio&lt;/code&gt;,  and &lt;code&gt;image size&lt;/code&gt; will be added. This will give more options to the users and let them be more specific about the content they want.&lt;/p&gt;
&lt;h4 id=&quot;related-images-and-image-tags&quot;&gt;Related Images and Image tags&lt;/h4&gt;&lt;p&gt;Showing related Images will help users find a variety of images that fit their requirements and also explore the images that would not usally show up on the initial pages of the search result. Whereas, Image tags will let the users incrementally make their queries better and more specific.&lt;/p&gt;
&lt;h4 id=&quot;adding-browse-by-sources-section&quot;&gt;Adding &quot;Browse by Sources&quot; section&lt;/h4&gt;&lt;p&gt;Even though the users can see the number of sources supported by the extension from the drop-down filter, they might not be familiar with many of them and what kind of content they provide. Adding a &quot;Browse by Source&quot; section would make users appreciate the sources available for them to choose from.&lt;/p&gt;
&lt;h4 id=&quot;improving-the-bookmarks-section&quot;&gt;Improving the bookmarks section&lt;/h4&gt;&lt;p&gt;Significant improvements will be made to the bookmarks section. First of all, the bookmarks data will be cached so that unnecessary requests to the Catalog API can be avoided. The bookmarks will be organized by the dates and this will also facilitate adding some type of filter mechanism. In addition to this, pagination in the bookmarks section and support for named bookmark file exports will be added&lt;/p&gt;
&lt;h4 id=&quot;syncing-as-much-data-as-possible&quot;&gt;Syncing as much data as possible&lt;/h4&gt;&lt;p&gt;An effort will be made to sync as much extension data as possible between the user's system. Syncing the user's preference/settings will ensure a familiar experience across systems and syncing the bookmarks data and the previous session search results would make them feel like they are continuing from where they left.&lt;/p&gt;
&lt;h4 id=&quot;integrating-cc-vocabulary&quot;&gt;Integrating CC Vocabulary&lt;/h4&gt;&lt;p&gt;The extension uses a very outdated version of CC Vocabulary. It will be replaced by the latest version for a refreshing new look.&lt;/p&gt;
&lt;h4 id=&quot;adding-support-for-microsoft-edge&quot;&gt;Adding support for Microsoft Edge&lt;/h4&gt;&lt;p&gt;The new Microsoft Edge browser is based on chromium. This paves the way to add support for it thanks to the power and flexibility of the WebExtension API. This will then allow us to also officially release on the &lt;a href=&quot;https://microsoftedge.microsoft.com/addons/Microsoft-Edge-Extensions-Home&quot;&gt;Microsoft Edge Addon Store&lt;/a&gt;.&lt;/p&gt;
&lt;h3 id=&quot;join-the-discussion&quot;&gt;Join the discussion&lt;/h3&gt;&lt;p&gt;If you have any feedback/suggestions or just want to say hi,  please join the &lt;code&gt;#cc-dev-browser-extension&lt;/code&gt; channel on &lt;a href=&quot;https://opensource.creativecommons.org/community/#slack&quot;&gt;slack&lt;/a&gt;. You can also track the progress on the project's &lt;a href=&quot;https://github.com/creativecommons/ccsearch-browser-extension&quot;&gt;Github&lt;/a&gt; Repository.&lt;/p&gt;
</content>
  </entry>
  <entry xml:base="http://opensource.creativecommons.org/blog/entries/takeaways-from-my-FOSS-journey/">
    <title type="text">Takeaways from my FOSS¬†journey!</title>
    <id>urn:uuid:21536df2-1436-3e06-8262-8e5d2c91e01c</id>
    <updated>2020-05-22T00:00:00Z</updated>
    <link href="http://opensource.creativecommons.org/blog/entries/takeaways-from-my-FOSS-journey/" />
    <author>
      <name>dhruvi16</name>
    </author>
    <content type="html">&lt;div style=&quot;text-align: center;&quot;&gt;
  &lt;figure&gt;
    &lt;img src=&quot;cover.jpg&quot;/&gt;
    &lt;figcaption&gt;
      &lt;em&gt;
        &lt;a href=&quot;https://www.flickr.com/photos/60255995@N04/14774214687&quot;&gt;&quot;Sky at night&quot;&lt;/a&gt; by &lt;a href=&quot;https://www.flickr.com/photos/60255995@N04&quot;&gt;Rychu92&lt;/a&gt; is licensed under &lt;a href=&quot;https://creativecommons.org/licenses/by-sa/2.0/?ref=ccsearch&amp;atype=rich&quot;&gt;CC BY-SA 2.0&lt;/a&gt;
      &lt;/em&gt;
    &lt;/figcaption&gt;
  &lt;/figure&gt;
&lt;/div&gt;&lt;p&gt;First let me introduce myself because of course I am not a very famous blogger or writer.&lt;/p&gt;
&lt;p&gt;I am Dhruvi. I am a third-year undergrad student. I am a designer/developer and also a FOSS enthusiast. I started my opensource journey a year ago (that is around Feb ‚Äô19) and now here I am starting my Outreachy internship with this blog (not literally of course). I am consistent, curious, and creative, and below I will tell you how these three C‚Äôs have helped me through my journey.&lt;/p&gt;
&lt;p&gt;Below are the four things that I think might be the ‚Äòtakeaways‚Äô from my experience -&lt;/p&gt;
&lt;h3 id=&quot;now-is-the-time&quot;&gt;NOW is the time -&lt;/h3&gt;&lt;p&gt;There is no better time than now! Let‚Äôs accept the fact that most of the students wait for ‚Äúthe time‚Äù to start with opensource as most of us want to get into programs like GSoC, Outreachy, and many more. But I figured it is very necessary to know that whether you are interested in opensource or is it only the big internships attracting you. So, to get these answers, you need to explore, and to explore I suggest you start today. I am very fond of asking myself the question ‚ÄòWhy?‚Äô and to answer those questions I explore, I invest time. So start finding answers to your whys? today.&lt;/p&gt;
&lt;h3 id=&quot;start-slow&quot;&gt;Start SLOW -&lt;/h3&gt;&lt;p&gt;For me the start was a little overwhelming and that made me push it away. And to avoid that I tried starting small and slow. By small and slow, I mean try the easy things first, like getting aware of the logistics. Personally, general practices or set of rules calm me down when I try to get into some uncomfortable zones. And yes opensource was not a very comfortable zone for me in the beginning (I mean what is *wink). To keep myself motivated, I started with familiar things like contributing to familiar projects or familiar good first issues (the easy ones). Completing a task or two gave me a lot of confidence and made me stick around.&lt;/p&gt;
&lt;h3 id=&quot;choose-wisely&quot;&gt;Choose WISELY -&lt;/h3&gt;&lt;p&gt;After playing around for some time and getting familiar with the logistics, I went for a project hunt. I listed my areas of interest and areas which seemed exciting to me. Using those filters I found some amazing projects which were actively being worked on. I got my answers to why would I want to work on these projects? by working on them. I believe if you are interested the motivation will be natural. With some projects, I felt connected and I did not feel the need of pushing myself for contributing to them. My only advice for making a wise choice is that ‚ÄúDon‚Äôt push yourself too hard‚Äù!&lt;/p&gt;
&lt;h3 id=&quot;speak-through-your-work&quot;&gt;Speak through your WORK -&lt;/h3&gt;&lt;p&gt;When I was sure, I wanted to work on a particular project I started getting familiar with the community (the specifics). I got familiar with the ideas and agendas the community had behind the projects. And fortunately, I got to work with the most amazing and inspiring people who helped me when I was stuck and I plan to keep working with them. I kept doing a few things which I guess might be worth mentioning -&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Try to write the most appropriate and relevant code.&lt;/li&gt;
&lt;li&gt;Try to break the solution into small understandable parts.&lt;/li&gt;
&lt;li&gt;Try to take initiatives. Small initiatives like opening issues will also work (Yes! opening relevant and meaningful issues is an initiative.).&lt;/li&gt;
&lt;li&gt;Know when to ask for help from the community (I am still working on this).&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;I know this was not an article full of resources and tips to get into Outreachy or GSoC but I just wanted to communicate that students should see that opensource is a broader concept. I wanted to share a personal take and help the beginners with my own experience. Thanks for reading!&lt;/p&gt;
</content>
  </entry>
  <entry xml:base="http://opensource.creativecommons.org/blog/entries/cc-search-accessibility-and-internationalization/">
    <title type="text">CC Search, Proposal Drafting and Community Bonding</title>
    <id>urn:uuid:e9ce22b5-b66a-37f1-a59b-aa5419b7d5c5</id>
    <updated>2020-05-22T00:00:00Z</updated>
    <link href="http://opensource.creativecommons.org/blog/entries/cc-search-accessibility-and-internationalization/" />
    <author>
      <name>AyanChoudhary</name>
    </author>
    <content type="html">&lt;h3 id=&quot;proposal-drafting&quot;&gt;Proposal Drafting&lt;/h3&gt;&lt;p&gt;The majority of my time in March was spent on drafting the proposal for my project &lt;strong&gt;Improve CC Search Accessibility&lt;/strong&gt;.
While drafting my proposal I had two broad topic that I had to focus on: Accessibility and Internationalization.&lt;/p&gt;
&lt;p&gt;So the first thing which I did was go through the various resources available with me such as w3 guidelines for accessibility, dequeuniversity accessibility insights and MDN notes on accessibility.
After I made myself acquainted myself wih all of these, the next challenge was to sort out which of the metrics were relevant and important enough to be detailed in the proposal and also some of the others metrics which made notable appearances.
Finally by including all of these I had the accessibility part of my proposal complete. Next, I had to work out the part for internationalization. Since it was already decided upon that we will be using vue-i18n, I did some research as to how to we can leverage it to gain the best possible result.&lt;/p&gt;
&lt;p&gt;One of the important parts of internationalization happens to be deciding upon the JSON structure which was a highlighted section in my proposal.
The other notable sections included strategies for modification of templates while translating and also how the translations would be carried out without hindering any further development of the platform.&lt;/p&gt;
&lt;h3 id=&quot;community-bonding&quot;&gt;Community Bonding&lt;/h3&gt;&lt;p&gt;Community Bonding involved getting to the mentors and the people whom I will be working with during this internship. Also we decided upon running the audit tests for the cc-search website during this time as it would help identify the key issues we would be facing and also would provide a suitable foundation to start working upon.
The audits were done using Lighthouse, Accessibility Insights and pa11y and they provided useful insights on which parts of the website we should be focusing on such as the contrast issues and the aria-label fixes.&lt;/p&gt;
&lt;p&gt;Coming up next will be the progress on the first 2 weeks of the project.&lt;/p&gt;
</content>
  </entry>
  <entry xml:base="http://opensource.creativecommons.org/blog/entries/legal-database-a-new-beginning/">
    <title type="text">CC Legal Database: a new beginning</title>
    <id>urn:uuid:0ca867d0-f061-3202-9da4-7e89977781ce</id>
    <updated>2020-05-22T00:00:00Z</updated>
    <link href="http://opensource.creativecommons.org/blog/entries/legal-database-a-new-beginning/" />
    <author>
      <name>krysal</name>
    </author>
    <content type="html">&lt;p&gt;CC maintains a collection of case law and legal scholarship relevant to legal issues around Creative Commons licenses. The CC Legal Database system gathers and exposes this information for everybody, as anyone can submit information, this aims to help understanding how CC legal tools have been interpreted by courts, and how they operate the larger legal ecosystem.&lt;/p&gt;
&lt;p&gt;The current &lt;a href=&quot;https://labs.creativecommons.org/caselaw/&quot;&gt;site&lt;/a&gt; is a beta version built on Jekyll, a static site generator, using Google forms and spreadsheets as database. This system has served its purpose, but it's time to modernize it since there are several issues we want to fix, mainly related to the automation of review and publication process, as for the visual styles, CC is doing a major redesign of websites with &lt;a href=&quot;https://cc-vocabulary.netlify.com/&quot;&gt;Vocabulary&lt;/a&gt;, the new design system, to unify the user experience.&lt;/p&gt;
&lt;p&gt;The process for collecting the information is decoupled into loose spreadsheets, some Google forms, and its publication is a cumbersome manual process for two teams involved, the Legal Team that have to review the incoming data and edit it if necessary, and the Tech Team which is the one that actually publishes. This is prone to human errors (e.g. missing a column entry for one row) that can be easily avoided as well as save time to both CC teams.&lt;/p&gt;
&lt;p&gt;This project, Reimplement CC‚Äôs Legal Database using Django, aims to address all these main issues, automate the reviewing and publication process, empowering CC legal staff to manage all the workflow without the intervention of the tech team, and make use of Vocabulary components and guides to unify styles with the rest of Creative Commons products.&lt;/p&gt;
&lt;h3 id=&quot;design&quot;&gt;Design&lt;/h3&gt;&lt;p&gt;First task in the plan is to design the user-facing parts of the new website on Figma, this tool allows to easily draw on the browser (great for start quickly since no need to install a program in your PC) and even collaborate between peers to edit one document at the same time. CC keeps here the Vocabulary design library, so it facilitates a lot using the already existing components.&lt;/p&gt;
&lt;p&gt;You can find designs and follow the process in this Figma link: &lt;a href=&quot;https://www.figma.com/file/L2sACqzX61N2OMd5lmisop/New-CC-Caselaw-Mockups&quot;&gt;New CC Caselaw Mockups&lt;/a&gt;. A new logo was made by the UX designer Francisco, with this the project start feeling like a consistent product of CC.&lt;/p&gt;
&lt;div style=&quot;text-align: center; margin: 15px 0px&quot;&gt;
&lt;figure&gt;
    &lt;img src=&quot;legal_database.svg&quot; alt=&quot;New Creative Commons Legal Database logo&quot; width=&quot;350px&quot;/&gt;
&lt;/figure&gt;
&lt;/div&gt;&lt;!-- ![New Creative Commons Legal Database logo](legal_database.svg) --&gt;

&lt;h3 id=&quot;why-django?&quot;&gt;Why Django?&lt;/h3&gt;&lt;p&gt;Before I briefly mentioned the use of Django, a framework of Python, for the implementation, so I will state some reasons that led to this decision.&lt;/p&gt;
&lt;p&gt;Two options were given for the backend development: WordPress or Django. WordPress is a nice tool to build sites like blogs and e-commerce, it gives a lot of functionalities to end-users (usually not technical) out of the box and can be extended with a wide ecosystem of plugins, but I identified some cons for this particular case. It will bring many not necessary features to the system initially planned and will take considerable work to customize both, the frontend with Vocabulary and the database in the backend. Building a Wordpress theme with Vocabulary was already considered for another project apart, so that should be done first. As for the DB,  deal with Wordpress tables may not be the best developer experience and could be a real mess.&lt;/p&gt;
&lt;p&gt;Looking at Django with Python, we can start in a greenfield ready to customize, like Wordpress, is a mature technology with a large number of libraries to extend its functionalities. For maintenance, the engineering team will be responsible and since Django is already used to back the &lt;a href=&quot;https://search.creativecommons.org/&quot;&gt;CC Search&lt;/a&gt;, currently the most ambitious products of the organization, then there should be no problem with this point. Given all this it seemed obvious to me to choose Django for this project.&lt;/p&gt;
&lt;h3 id=&quot;next-steps&quot;&gt;Next steps&lt;/h3&gt;&lt;p&gt;It has only been a week so we're just starting, so next task to do sooner are:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Conduct interview with staff to iterate over designs&lt;/li&gt;
&lt;li&gt;Setup the Django project&lt;/li&gt;
&lt;li&gt;Model the legal database&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&quot;how-you-can-help&quot;&gt;How you can help&lt;/h3&gt;&lt;p&gt;We are still discussing the new image before start coding so these are some options if you want to get involved:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Suggest improvements to designs/UX or new features joining the discussion on the &lt;a href=&quot;https://creativecommons.slack.com/channels/cc-dev-legal-database&quot;&gt;&lt;code&gt;#cc-dev-legal-database&lt;/code&gt;&lt;/a&gt; Slack channel or on the &lt;a href=&quot;https://github.com/creativecommons/caselaw&quot;&gt;github&lt;/a&gt; project.&lt;/li&gt;
&lt;li&gt;Contribute directly to the CC's Vocabulary design system on &lt;a href=&quot;https://github.com/creativecommons/vocabulary&quot;&gt;github&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;Submit a case or a scholarship related to CC licenses on the &lt;a href=&quot;https://labs.creativecommons.org/caselaw/contribute/&quot;&gt;current site&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;CC Legal Database&lt;/strong&gt; is my Outreachy project for this summer, under the guidance of Director of Engineering &lt;a href=&quot;https://creativecommons.org/author/kriticreativecommons-org/&quot;&gt;Kriti Godey&lt;/a&gt; and Core Systems Manager &lt;a href=&quot;https://creativecommons.org/author/timidcreativecommons-org/&quot;&gt;Timid Robot Zehta&lt;/a&gt;, they are very supportive and the CC community is notable welcoming.&lt;/p&gt;
&lt;p&gt;This is the first post of a series so stay tuned if you're interested to know more.&lt;/p&gt;
</content>
  </entry>
  <entry xml:base="http://opensource.creativecommons.org/blog/entries/improving-cc-license-chooser-outcomes/">
    <title type="text">Improving CC License Chooser: Outcomes</title>
    <id>urn:uuid:bb5e2374-647f-389c-b535-0fb44d4a3608</id>
    <updated>2020-05-21T00:00:00Z</updated>
    <link href="http://opensource.creativecommons.org/blog/entries/improving-cc-license-chooser-outcomes/" />
    <author>
      <name>obulat</name>
    </author>
    <content type="html">&lt;p&gt;During the three months of my Outreachy internship, I worked on improving the new version of the chooser to make it ready for production. You can view the result at &lt;a href=&quot;https://chooser-beta.creativecommons.org/&quot;&gt;chooser-beta.creativecommons.org&lt;/a&gt;. (Don't forget to leave your feedback!). We've gone through iterations of design, implementation and user experience testing.&lt;/p&gt;
&lt;h3 id=&quot;technical-details&quot;&gt;Technical details&lt;/h3&gt;&lt;p&gt;I implemented a couple of versions of design in line with the insights we've got from UX testing. Francisco Vera created the final design, and I &lt;em&gt;converted  the Figma design into a VueJS app&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;I created custom components for the stepper, and used &lt;a href=&quot;https://buefy.org/&quot;&gt;Buefy&lt;/a&gt; components for more common elements, and &lt;a href=&quot;https://fortawesome.com/&quot;&gt;Fortawesome&lt;/a&gt; library for icons. The downsize of this convenience was a huge bundle size. I performed analysis with &lt;code&gt;webpack-bundle-analyzer&lt;/code&gt; and after several rounds of tree shaking, managed to &lt;strong&gt;reduce the size of the bundle almost by half&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;The license chooser has to keep data about the license properties that the user selects and display any changes on screen. Previously, all data for selected license was passed to components using props. So, when a user added, say,  a 'NonCommercial' clause to their license, or typed in the link to which the work should be attributed, the data was passed through props to the components that displayed the result. This created chains of props passing that were brittle. To make the process more robust, I &lt;strong&gt;added Vuex store&lt;/strong&gt; to keep the data that is necessary for more than one component.&lt;/p&gt;
&lt;p&gt;To make chooser accessible for all of our wide multilingual community, I &lt;strong&gt;integrated the vue-i18n plugin&lt;/strong&gt;, and made all of the text translatable.  Together with Kriti, we added &lt;strong&gt;Transifex integration&lt;/strong&gt; so that the text translation can be crowdsourced.&lt;/p&gt;
&lt;p&gt;I've also updated the code from using Vue webpack templates to &lt;strong&gt;Vue CLI&lt;/strong&gt;, and added &lt;strong&gt;Github hooks&lt;/strong&gt; to test the code before merging any new pull requests. &lt;strong&gt;Google analytics integration&lt;/strong&gt; will help us continue improving the chooser.&lt;/p&gt;
&lt;p&gt;After all of this work, I was really excited to be the person to deploy the new chooser to github pages. And redeploy it many more times after that :)&lt;/p&gt;
&lt;h3 id=&quot;working-remotely&quot;&gt;Working remotely&lt;/h3&gt;&lt;p&gt;It has been a great experience to work remotely, before the time of global coronavirus lockdowns when everyone has started to work from home.&lt;/p&gt;
&lt;p&gt;What helped me during this time is the weekly meetings we had with other members of CC team. This made me feel a part of the team, plan and implement the work I needed to do, and stay on track.&lt;/p&gt;
&lt;p&gt;Working remotely also let me have a flexible work schedule. While ensuring that I work at least 40 hours per week (the Outreachy internship requirement), I sometimes worked on weekends or early in the morning, when it was more convenient for me.&lt;/p&gt;
&lt;h3 id=&quot;working-together&quot;&gt;Working together&lt;/h3&gt;&lt;p&gt;It's been a pleasure to work with Creative Commons team. My mentors, &lt;a href=&quot;https://creativecommons.org/author/kriticreativecommons-org/&quot;&gt;Kriti&lt;/a&gt; and &lt;a href=&quot;https://opensource.creativecommons.org/blog/authors/akmadian/&quot;&gt;Ari&lt;/a&gt;, together with &lt;a href=&quot;https://creativecommons.org/author/annacreativecommons-org/&quot;&gt;Anna&lt;/a&gt;, Francisco Vera and &lt;a href=&quot;https://creativecommons.org/author/brenoferreira/&quot;&gt;Breno&lt;/a&gt;, were there for me all through the internship, help me feel a part of CC team.&lt;/p&gt;
&lt;p&gt;But the CC community is much wider than that! I've been amazed at the enthusiasm of the users who helped us with the UX testing, and at the speed with which they jumped on the task of translating the website as soon as we published the text on Transifex.&lt;/p&gt;
&lt;h3 id=&quot;what-s-next?&quot;&gt;What's next?&lt;/h3&gt;&lt;p&gt;My internship ended more than two months ago, but I continue to be a part of CC open source team. I also hope this experience will help me go on to a career as a developer.&lt;/p&gt;
</content>
  </entry>
  <entry xml:base="http://opensource.creativecommons.org/blog/entries/why-lektor/">
    <title type="text">Why Lektor?</title>
    <id>urn:uuid:2cec5ffc-29a4-3c29-ac42-e928118f3be7</id>
    <updated>2020-05-15T00:00:00Z</updated>
    <link href="http://opensource.creativecommons.org/blog/entries/why-lektor/" />
    <author>
      <name>dhruvi16</name>
    </author>
    <content type="html">&lt;div style=&quot;text-align: center;&quot;&gt;
  &lt;figure&gt;
    &lt;img src=&quot;cover.png&quot;/&gt;
    &lt;figcaption&gt;
      &lt;em&gt;
        why?why?why? &lt;a href=&quot;https://creativecommons.org/publicdomain/zero/1.0/&quot;&gt;(CC0 1.0)&lt;/a&gt;
      &lt;/em&gt;
    &lt;/figcaption&gt;
  &lt;/figure&gt;
&lt;/div&gt;&lt;p&gt;I wrote this article while prepping for my Outreachy internship. I was trying to find out why Lektor is being used for the project and found out really convincing reasons for the same.&lt;/p&gt;
&lt;p&gt;Let‚Äôs start with basic types of website -&lt;/p&gt;
&lt;p&gt;Static website: Here the webpages are pre-loaded to the server and when the request is made, these pages are served to the client as it is. These webpages can use HTML, CSS, and Javascript. By static, it does not mean that these webpages are devoid of user interactivity. These pages can be highly reactive (because of course JS) but yes they are not generated on the server and are static in that manner.&lt;/p&gt;
&lt;p&gt;Dynamic website: Here the webpages are generated by the server. It is connected to a database and all the data is fetched from there. It uses server-side scripting and also client-side scripting (if necessary). It is called dynamic because the webpages are processed by the server.&lt;/p&gt;
&lt;p&gt;So why go static? ‚Äî Because the vast, vast majority of websites will be read many more times than they will be updated. This is crucial because dynamic content does not come for free. It needs server resources and because program code is running there it needs to be kept up to date to ensure there are no security problems that are left unpatched. Also when a website gets a sudden spike of traffic a static website will stay up for longer on the same server than a dynamic one that needs to execute code.&lt;/p&gt;
&lt;p&gt;There are certain drawbacks of static websites we are going to focus on here and how Lektor helps us to combat those.&lt;/p&gt;
&lt;p&gt;Drawbacks -&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Multi-page websites are really hard to manage ‚Äî Updating the content can be a cumbersome task here.&lt;/li&gt;
&lt;li&gt;Lack of dynamic content.&lt;/li&gt;
&lt;li&gt;Unavailability of the admin side of the website ‚Äî This makes hard for non-technical people to edit the website.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Lektor helps to combat all the shortcomings listed above. It is built using Node.js and Python and is very easy to understand and use.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;The first drawback has a very common solution that is templates. Lektor has a file structure that consists of ‚Äî content, models, and templates. This structure helps us to manage multi-page websites without any cumbersome copy-pasting.&lt;/li&gt;
&lt;li&gt;This drawback can be overcome by using external services or in house micro-services. These services can easily be integrated into your Lektor project. This will save time and give efficient results.&lt;/li&gt;
&lt;li&gt;This is the most amazing thing that Lektor does. Combating this shortcoming makes Lektor stand out. Lektor takes from content management systems like WordPress and provides a flexible browser-based admin interface from which you can edit your website‚Äôs contents. Unlike traditional CMS solutions, however, it runs entirely on your computer. This means you can give a Lektor website to people that have no understanding of programming and they can still modify the content and update the website.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Due to such capabilities, I find this framework amazing and I am excited about using it. Though there are many points untouched in this blog I would try to write a more in-depth blog when I learn about it more during my internship.&lt;/p&gt;
&lt;p&gt;Credits ‚Äî This blog is inspired by &lt;a href=&quot;https://2016.ploneconf.org/talks/static-websites-with-lektor.html&quot;&gt;Static websites with Lektor&lt;/a&gt; and also for more details you can check out &lt;a href=&quot;https://www.getlektor.com/&quot;&gt;Lektorpython&lt;/a&gt;.&lt;/p&gt;
</content>
  </entry>
  <entry xml:base="http://opensource.creativecommons.org/blog/entries/date-partitioned-data-reingestion/">
    <title type="text">Date-Partitioned Data Reingestion</title>
    <id>urn:uuid:33f5a94f-2510-3c9f-95ad-460fe82c9b1f</id>
    <updated>2020-05-14T00:00:00Z</updated>
    <link href="http://opensource.creativecommons.org/blog/entries/date-partitioned-data-reingestion/" />
    <author>
      <name>mathemancer</name>
    </author>
    <content type="html">&lt;p&gt;CC Catalog is a project that gathers information about images from around the
internet, and stores the information so that these images can eventually be
indexed in &lt;a href=&quot;https://ccsearch.creativecommons.org/&quot;&gt;CC Search&lt;/a&gt;. A portion of the process is directed by
&lt;a href=&quot;https://airflow.apache.org/&quot;&gt;Apache Airflow&lt;/a&gt;, which is a tool commonly used to organize workflows
and data pipelines.&lt;/p&gt;
&lt;p&gt;In this blog post, we will explore the way in which we keep information we
gather about images up-to-date, using metadata pulled from the Flickr API as an
example case study.&lt;/p&gt;
&lt;h2 id=&quot;apache-airflow-and-the-execution_date-concept&quot;&gt;Apache Airflow, and the &lt;code&gt;execution_date&lt;/code&gt; concept&lt;/h2&gt;&lt;p&gt;Apache Airflow is open source software that loads Directed Acyclic Graphs (DAGs)
defined via python files. The DAG is what defines a given workflow. The nodes
are pieces of jobs that need to be accomplished, and the directed edges of the
graph define dependencies between the various pieces.&lt;/p&gt;
&lt;p&gt;A &lt;a href=&quot;https://airflow.apache.org/docs/1.10.9/concepts.html#dag-runs&quot;&gt;DAG Run&lt;/a&gt; is an 'execution' of the overall workflow defined by
the DAG, and is associated with an &lt;code&gt;execution_date&lt;/code&gt;.  Contrary to what one might
expect, &lt;code&gt;execution_date&lt;/code&gt; does &lt;em&gt;not&lt;/em&gt; mean the date when the workflow is executed,
but rather the date 'perspective' from which the workflow is executed.  This
means one can give a command that instructs Airflow to execute the workflow
defined by a DAG as if the date were 2019-01-01, regardless of the actual date.&lt;/p&gt;
&lt;h2 id=&quot;our-use-of-execution_date&quot;&gt;Our Use of &lt;code&gt;execution_date&lt;/code&gt;&lt;/h2&gt;&lt;p&gt;Much of the data contained in CC Catalog is pulled from various APIs on the
internet, and one strategy we use quite regularly is to make a request of the
form:&lt;/p&gt;
&lt;p&gt;&lt;em&gt;&quot;please give me all the metadata for photos uploaded to Flickr on 2019-01-01&quot;&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;Since we're often requesting metadata about user-sourced content on 3rd-party
sites, some sort of &lt;code&gt;date_uploaded&lt;/code&gt; parameter is often available for filtering
results in the API provided by the 3rd-party site.  This allows us to partition
large data-sets into more manageable pieces.  It also leads naturally to the
strategy of requesting metadata for yesterday's photos, each day:&lt;/p&gt;
&lt;p&gt;&lt;em&gt;&quot;please give me all the metadata for photos uploaded to Flickr &lt;strong&gt;yesterday&lt;/strong&gt;&quot;&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;Doing this each day lets us keep the metadata in our catalog synced with the
upstream source (i.e., the Flickr API). This is where the &lt;code&gt;execution_date&lt;/code&gt;
concept comes in. By default, a workflow which is scheduled to run daily uses
the previous day's date as its &lt;code&gt;execution_date&lt;/code&gt;, and so an execution that
happens on the actual date 2020-02-02 will have &lt;code&gt;execution_date&lt;/code&gt; 2020-02-01 by
default. This matches up naturally with the strategy above, so we have a number
of workflows that ingest (meta)data into CC Catalog using this default
&lt;code&gt;execution_date&lt;/code&gt; on a daily basis.&lt;/p&gt;
&lt;h2 id=&quot;challenge:-data-can-go-stale-over-time&quot;&gt;Challenge:  Data can go stale over time&lt;/h2&gt;&lt;p&gt;There are some problems with the strategy outlined above:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;What if a photo changes upstream?&lt;/li&gt;
&lt;li&gt;What if a photo is deleted upstream?&lt;/li&gt;
&lt;li&gt;What about metadata that changes over time (e.g., 'views')?&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Given we're only ingesting metadata about photos the day after they're uploaded,
we won't be able to capture the relevant data for any of these situations.  So,
we need to reingest the metadata for images on some schedule over time.&lt;/p&gt;
&lt;h2 id=&quot;reingestion-schedule&quot;&gt;Reingestion Schedule&lt;/h2&gt;&lt;p&gt;We would prefer to reingest the metadata for newer images more frequently, and
the metadata for older images less frequently. This is because we assume the
metadata for newer images will be updated at the source in more interesting ways
when the image is newer. For example, assume a picture is viewed 100 times per
month.&lt;/p&gt;
&lt;table class=&quot;table table-striped&quot;&gt;
&lt;thead class=&quot;thead-dark&quot;&gt;&lt;tr&gt;
&lt;th style=&quot;text-align:right&quot;&gt;month&lt;/th&gt;
&lt;th style=&quot;text-align:right&quot;&gt;total views&lt;/th&gt;
&lt;th style=&quot;text-align:right&quot;&gt;% increase&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&quot;text-align:right&quot;&gt;   1&lt;/td&gt;
&lt;td style=&quot;text-align:right&quot;&gt;100&lt;/td&gt;
&lt;td style=&quot;text-align:right&quot;&gt;infinite&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&quot;text-align:right&quot;&gt;   2&lt;/td&gt;
&lt;td style=&quot;text-align:right&quot;&gt;200&lt;/td&gt;
&lt;td style=&quot;text-align:right&quot;&gt;100% &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&quot;text-align:right&quot;&gt;   3&lt;/td&gt;
&lt;td style=&quot;text-align:right&quot;&gt;300&lt;/td&gt;
&lt;td style=&quot;text-align:right&quot;&gt;50% &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&quot;text-align:right&quot;&gt;   4&lt;/td&gt;
&lt;td style=&quot;text-align:right&quot;&gt;400&lt;/td&gt;
&lt;td style=&quot;text-align:right&quot;&gt;33% &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&quot;text-align:right&quot;&gt;   5&lt;/td&gt;
&lt;td style=&quot;text-align:right&quot;&gt;500&lt;/td&gt;
&lt;td style=&quot;text-align:right&quot;&gt;25% &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&quot;text-align:right&quot;&gt;   6&lt;/td&gt;
&lt;td style=&quot;text-align:right&quot;&gt;600&lt;/td&gt;
&lt;td style=&quot;text-align:right&quot;&gt;20% &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&quot;text-align:right&quot;&gt;   7&lt;/td&gt;
&lt;td style=&quot;text-align:right&quot;&gt;700&lt;/td&gt;
&lt;td style=&quot;text-align:right&quot;&gt;17% &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&quot;text-align:right&quot;&gt;   8&lt;/td&gt;
&lt;td style=&quot;text-align:right&quot;&gt;800&lt;/td&gt;
&lt;td style=&quot;text-align:right&quot;&gt;14% &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&quot;text-align:right&quot;&gt;   9&lt;/td&gt;
&lt;td style=&quot;text-align:right&quot;&gt;900&lt;/td&gt;
&lt;td style=&quot;text-align:right&quot;&gt;13% &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&quot;text-align:right&quot;&gt;  10&lt;/td&gt;
&lt;td style=&quot;text-align:right&quot;&gt;1000&lt;/td&gt;
&lt;td style=&quot;text-align:right&quot;&gt;11% &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&quot;text-align:right&quot;&gt;  11&lt;/td&gt;
&lt;td style=&quot;text-align:right&quot;&gt;1100&lt;/td&gt;
&lt;td style=&quot;text-align:right&quot;&gt;10% &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&quot;text-align:right&quot;&gt;  12&lt;/td&gt;
&lt;td style=&quot;text-align:right&quot;&gt;1200&lt;/td&gt;
&lt;td style=&quot;text-align:right&quot;&gt;9% &lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;As we see, given consistent monthly views, the 'percent increase' of the total
views metric drops off as the picture ages (In reality, it appears that in most
cases, pictures are mostly viewed when they are new).&lt;/p&gt;
&lt;p&gt;Thus, it makes sense to focus more on keeping the information up-to-date for the
most recently uploaded images.&lt;/p&gt;
&lt;h3 id=&quot;real-numbers-for-flickr&quot;&gt;Real numbers for Flickr&lt;/h3&gt;&lt;p&gt;For Flickr, in the worst case, we can ingest about 100 dates' worth of uploaded
image metadata per day. This was calculated using the year 2016 as an example.
Because 2016 was around the peak for the number of images uploaded to Flickr per
day, the actual number if dates' worth of metadata we can ingest per day is
quite a bit higher, perhaps 150.&lt;/p&gt;
&lt;p&gt;We'll need to choose around 150 dates for each daily run, and reingest the
metadata for all images uploaded on each of those dates.  We want to choose
those dates preferring newer images (for the reasons outlined above), and choose
them so that if we follow the same date-choosing algorithm each daily run, we'll
eventually reingest the metadata for &lt;em&gt;all&lt;/em&gt; images on some predictable schedule.&lt;/p&gt;
&lt;h3 id=&quot;strategy-to-choose-which-dates-to-reingest&quot;&gt;Strategy to choose which dates to reingest&lt;/h3&gt;&lt;p&gt;Assume we'll reingest metadata from some number &lt;code&gt;n&lt;/code&gt; of dates on each daily run.
We set some maximum number of days &lt;code&gt;D&lt;/code&gt; we're willing to wait between reingestion
of the data for a given image, subject to the constraint that we need to have
&lt;code&gt;n * D &amp;gt; T&lt;/code&gt;, where &lt;code&gt;T&lt;/code&gt; is the total number of dates for which data exists. For
Flickr, there's (at the time of this writing) about 6,000 days for which image
metadata was uploaded. If we set&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;n = 150&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;D = 180&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;then we have &lt;code&gt;n * D = 150 * 180 = 27,000 &amp;gt; 6,000&lt;/code&gt;, as desired.  In fact, there
is quite a bit of slack in this calculation. Keep in mind, however, that we add
one date's worth of metadata as each day passes in real time.  Thus, we want to
keep some slack here. One option would be to reingest the metadata for each
image every 90 days, rather than every 180. This would still leave some slack,
and we'd have generally fresher data.  This means that on each day, we'd ingest
metadata for photos uploaded on that date, as well as metadata for photos
uploaded&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;90, 180, 270, 360, ..., 13320, or 13410 days prior to the current date.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;This is better, but 90 days is still quite a long time to wait to reingest
metadata for a recently-uploaded photo. So, it'd be better to use the slack
available to reingest metadata for recently-uploaded photos more often, and back
off smoothly to reingest metadata for the oldest photos only once every 180
days. We ended up using a schedule where we ingest metadata for photos uploaded
on the current &lt;code&gt;execution_date&lt;/code&gt;, as well as metadata for photos uploaded&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;1, 2, ..., 6, or 7 days prior;&lt;/li&gt;
&lt;li&gt;14, 21, ..., 84, or 91 days prior;&lt;/li&gt;
&lt;li&gt;106, 121, ..., 376, or 391 days prior;&lt;/li&gt;
&lt;li&gt;421, 451, ..., 1081, or 1111 days prior;&lt;/li&gt;
&lt;li&gt;1201, 1291, ..., 3181, or 3271 days prior; and&lt;/li&gt;
&lt;li&gt;3451, 3631, ..., 10291, or 10471 days prior.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;These lists can be generated using the following snippet:&lt;/p&gt;
&lt;div class=&quot;hll&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;get_reingestion_day_list_list&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;args&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;
        &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;args&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;][&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;j&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;arg&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;arg&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;arg&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;args&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[:&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;j&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;args&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;][&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
        &lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;args&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;get_reingestion_day_list_list&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;7&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;7&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;12&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;15&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;20&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;30&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;24&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;90&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;24&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;180&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;40&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;This function creates a list of lists of integers based on input pairs
describing which prior dates to ingest. An approximate interpretation of the
input pairs in this example would be&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Ingest data which is at most a week old daily.&lt;/li&gt;
&lt;li&gt;Ingest data which is between a week and three months old weekly.&lt;/li&gt;
&lt;li&gt;Ingest data which is between three months and a year old biweekly.&lt;/li&gt;
&lt;li&gt;Ingest data which is between one and three years old monthly.&lt;/li&gt;
&lt;li&gt;Ingest data which is between three and nine years old every three
months.&lt;/li&gt;
&lt;li&gt;Ingest data which is between nine and twenty-eight years old every six months.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The astute reader will notice that these lists only define 128 dates (including
the current date) for which metadata should be reingested.  We prefer to be a
bit conservative on the total amount we plan to ingest per day, since things can
happen that put the ingestion workflow DAG out of service for some time on
occasion.&lt;/p&gt;
&lt;p&gt;So, using this strategy, we ensure that all metadata is updated at least every 6
months, with a preference towards metadata about images uploaded recently.
Because this schedule covers about 28.7 years back in time, this strategy should
suffice to reingest all relevant Flickr data for the next 12 years or so (the
current date is 2020).&lt;/p&gt;
&lt;p&gt;For more context around what we've shown here, please take a look at
&lt;a href=&quot;https://github.com/creativecommons/cccatalog/&quot;&gt;the CC Catalog repo&lt;/a&gt;.&lt;/p&gt;
</content>
  </entry>
  <entry xml:base="http://opensource.creativecommons.org/blog/entries/2020-04-03-nvmee-on-debian-on-aws/">
    <title type="text">NVMEe on Debian on AWS</title>
    <id>urn:uuid:cd3e9db2-b141-3ea1-8cd9-61cd146ec9cd</id>
    <updated>2020-04-03T00:00:00Z</updated>
    <link href="http://opensource.creativecommons.org/blog/entries/2020-04-03-nvmee-on-debian-on-aws/" />
    <author>
      <name>TimidRobot</name>
    </author>
    <content type="html">&lt;h2 id=&quot;problem&quot;&gt;Problem&lt;/h2&gt;&lt;p&gt;The current Creative Commons infrastructure buildouts use Debian GNU/Linux AWS
EC2 instances with EBS volumes. Depending on chance (or race conditions), the
mapping of block devices can be different from one host to another or between
reboots.&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;em&gt;Occasionally, devices can respond to discovery in a different order in
subsequent instance starts, which causes the device name to change.&lt;/em&gt;
(&lt;a href=&quot;https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/nvme-ebs-volumes.html&quot; title=&quot;Amazon EBS and NVMe on Linux Instances - Amazon Elastic Compute Cloud&quot;&gt;Amazon EBS and NVMe on Linux Instances - Amazon Elastic Compute
Cloud&lt;/a&gt;)&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&quot;our-solution&quot;&gt;Our Solution&lt;/h2&gt;&lt;p&gt;Modern Amazon Linux AMIs resolve this by providing a &lt;code&gt;udev&lt;/code&gt; rule, but Debian
GNU/Linux does not yet do this. To ensure our systems are configured correctly,
At Creative Commons, we use the device specified during provisioning (ex.
&lt;code&gt;/dev/xvdf&lt;/code&gt;) to identify the correct NVMEe device. We then format it with a
label that can be used mounting during subsequent reboots.&lt;/p&gt;
&lt;p&gt;Thankfully, AWS documents the the device specified during provisioning (ex. &lt;code&gt;/dev/xvdf&lt;/code&gt;):&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;em&gt;For Nitro-based instances, the block device mappings that are specified in
the Amazon EC2 console when you are attaching an EBS volume or during
AttachVolume or RunInstances API calls are captured in the vendor-specific
data field of the NVMe controller identification.&lt;/em&gt;
(&lt;a href=&quot;https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/nvme-ebs-volumes.html&quot; title=&quot;Amazon EBS and NVMe on Linux Instances - Amazon Elastic Compute Cloud&quot;&gt;Amazon EBS and NVMe on Linux Instances - Amazon Elastic Compute
Cloud&lt;/a&gt;)&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;We use SaltStack (&lt;a href=&quot;https://github.com/creativecommons/sre-salt-prime&quot; title=&quot;creativecommons/sre-salt-prime: Site Reliability Engineering / DevOps SaltStack configuration files&quot;&gt;&lt;code&gt;creativecommons/sre-salt-prime&lt;/code&gt;&lt;/a&gt;) to:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Install the &lt;code&gt;nvme-cli&lt;/code&gt; package&lt;/li&gt;
&lt;li&gt;Use the &lt;code&gt;nvme&lt;/code&gt; command to detect which &lt;code&gt;/dev/nvme?n?&lt;/code&gt; contains &lt;em&gt;spec&lt;/em&gt; (ex.
&lt;code&gt;xvdf&lt;/code&gt;) in the NVMe vendor specific data&lt;/li&gt;
&lt;li&gt;Create a symlink (ex. &lt;code&gt;/dev/xvdf -&amp;gt; /dev/nvme1n1&lt;/code&gt;) so that SaltStack can use
&lt;code&gt;/dev/xvdf&lt;/code&gt; for the initial setup&lt;/li&gt;
&lt;li&gt;Perform the intial setup&lt;/li&gt;
&lt;li&gt;Delete the symlink since:&lt;ol&gt;
&lt;li&gt;The initial setup formatted the volume with a label that is used to mount
the filesystem&lt;/li&gt;
&lt;li&gt;There is no guarantee the symlink will be accurate on subsequent reboots
and it might cause confusion&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;The &lt;a href=&quot;https://github.com/creativecommons/sre-salt-prime/blob/master/states/mount/init.sls&quot;&gt;&lt;code&gt;states/mount/init.sls&lt;/code&gt;&lt;/a&gt; state includes a complex shell
command (with Jinja2 variables) that loops through the NVMe devices and finds
the correct one:&lt;/p&gt;
&lt;div class=&quot;hll&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; n in /dev/nvme?n?
&lt;span class=&quot;k&quot;&gt;do&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; nvme id-ctrl -v &lt;span class=&quot;si&quot;&gt;${&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;|&lt;/span&gt; grep -q &lt;span class=&quot;s1&quot;&gt;&amp;#39;^0000:.*{{ spec_short }}&amp;#39;&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;then&lt;/span&gt;
        ln -s &lt;span class=&quot;si&quot;&gt;${&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{{&lt;/span&gt; spec_long &lt;span class=&quot;o&quot;&gt;}}&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;fi&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;done&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Example variable values:&lt;/p&gt;
&lt;table class=&quot;table table-striped&quot;&gt;
&lt;thead class=&quot;thead-dark&quot;&gt;&lt;tr&gt;
&lt;th&gt;Jinja2 Variable&lt;/th&gt;
&lt;th&gt;Example Value&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;{{ spec_short }}&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;&lt;code&gt;xvdf&lt;/code&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;{{ spec_long }}&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;&lt;code&gt;/dev/xvdf&lt;/code&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h3 id=&quot;related-links&quot;&gt;Related Links&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;https://wiki.debian.org/Cloud/AmazonEC2Image/Buster&quot; title=&quot;Cloud/AmazonEC2Image/Buster - Debian Wiki&quot;&gt;Cloud/AmazonEC2Image/Buster - Debian Wiki&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://packages.debian.org/buster/nvme-cli&quot; title=&quot;Debian -- Details of package nvme-cli in buster&quot;&gt;&lt;code&gt;nvme-cli&lt;/code&gt; package details in Debian buster&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Debian buster ‚Äî Debian Manpages&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;https://manpages.debian.org/buster/nvme-cli/nvme.1.en.html&quot;&gt;nvme(1) ‚Äî nvme-cli&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;https://manpages.debian.org/buster/nvme-cli/nvme-id-ctrl.1.en.html&quot;&gt;nvme-id-ctrl(1) ‚Äî nvme-cli&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;other-solutions&quot;&gt;Other Solutions&lt;/h2&gt;&lt;p&gt;While doing additional research for this blog post, I found additional
solutions to the same problem. They're all good, but I apprecite the simplicity
of a temporary symlink for setup versus maintaining custom udev rules (maybe I
can help contribute a udev based solution to Debian or Debian's EC2 image). I
can also easily imagine a more complex solution being a better fit if/when our
infrastructure provisioining become more complex.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;https://github.com/oogali/ebs-automatic-nvme-mapping&quot; title=&quot;oogali/ebs-automatic-nvme-mapping: Automatic mapping of EBS volumes via NVMe block devices to standard block device paths&quot;&gt;oogali/ebs-automatic-nvme-mapping&lt;/a&gt;: Automatic mapping of EBS volumes via NVMe block devices to standard block device paths&lt;ul&gt;
&lt;li&gt;udev rule that invokes a Bash script to create symlinks&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;CoreOS&lt;ul&gt;
&lt;li&gt;udev rules that invokes a Bash script to create symlinks&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;https://github.com/coreos/init/blob/master/udev/rules.d/90-cloud-storage.rules&quot;&gt;&lt;code&gt;udev/rules.d/90-cloud-storage.rules&lt;/code&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://github.com/coreos/init/blob/master/udev/bin/cloud_aws_ebs_nvme_id&quot;&gt;&lt;code&gt;udev/bin/cloud_aws_ebs_nvme_id&lt;/code&gt;&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://gist.github.com/jalaziz/c22c8464cb602bc2b8d0a339b013a9c4&quot;&gt;AWS EBS NVMe udev rules&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;udev rule that invokes a Pyton script to create symlinks&lt;/li&gt;
&lt;li&gt;this is a copy as Amazon only provides access to the source of Amazon Linux
from within an Amazon Linux AMI: &lt;em&gt;The yumdownloader --source command line
tool provided in the Amazon Linux AMI enables viewing of source code inside
of an Amazon EC2.&lt;/em&gt; (&lt;a href=&quot;https://aws.amazon.com/amazon-linux-ami/faqs/&quot; title=&quot;Amazon Linux AMI FAQs&quot;&gt;Amazon Linux AMI FAQs&lt;/a&gt;)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
</content>
  </entry>
  <entry xml:base="http://opensource.creativecommons.org/blog/entries/cc-vocabulary-week9-13/">
    <title type="text">CC Vocabulary - My Internship Ended</title>
    <id>urn:uuid:85900455-54f0-35dd-b689-57e5a399b7e5</id>
    <updated>2020-04-02T00:00:00Z</updated>
    <link href="http://opensource.creativecommons.org/blog/entries/cc-vocabulary-week9-13/" />
    <author>
      <name>conye</name>
    </author>
    <content type="html">&lt;p&gt;This will be my last blog as an Outreachy intern. My watch as an intern has come to an end.  I am glad I chose the Creative Commons community or rather am glad Creative Commons chose me (am not the chosen one). I have gained a lot of valuable knowledge, skills and I am more confident in my abilities.&lt;/p&gt;
&lt;h2 id=&quot;summary-of-my-internship-with-vocabulary&quot;&gt;Summary of  My Internship with Vocabulary&lt;/h2&gt;&lt;p&gt;I have been more involved with the Vocabulary project during my internship and am happy with the work that has been done so far. I made 24 pull requests with 17 merged. My last contribution was adding a &lt;a href=&quot;https://github.com/creativecommons/vocabulary/pull/145&quot;&gt;header component&lt;/a&gt; to the revamped Vocabulary. Here is a summary of my time with Vocabulary.&lt;/p&gt;
&lt;h3 id=&quot;when-i-started-my-internship-vocabulary-comprised-of:&quot;&gt;When I started my Internship, Vocabulary comprised of:&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;UI components built with Vue &lt;/li&gt;
&lt;li&gt;Styling was written with Stylus&lt;/li&gt;
&lt;li&gt;live style guide built with Styleguidist&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&quot;currently:&quot;&gt;Currently:&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;UI components built with extending Bulma library components. &lt;/li&gt;
&lt;li&gt;Styling extended with SASS.&lt;/li&gt;
&lt;li&gt;An interactive playground experience built with Storybook that provides a live style guide and documentation.&lt;/li&gt;
&lt;li&gt;A subset Vue-Vocabulary with the same styling but to support platforms built with Vue&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;To use the Vocabulary components, check out its &lt;a href=&quot;https://github.com/creativecommons/vocabulary&quot;&gt;Github repository&lt;/a&gt;. You can also have a playground experience on &lt;a href=&quot;https://cc-vocabulary.netlify.com&quot;&gt;storybook&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&quot;my-progress&quot;&gt;My Progress&lt;/h2&gt;&lt;p&gt;Before this internship, I had just switched careers from Network engineering to Software development and this experience came at the time needed.&lt;/p&gt;
&lt;h3 id=&quot;where-i-was-before-the-internship&quot;&gt;Where I was before the Internship&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;No experience working on open source project (or any free open source project)&lt;/li&gt;
&lt;li&gt;My technical skills were basically on the front end (HTML, CSSS and JavaScript with little React) &lt;/li&gt;
&lt;li&gt;No experience working remotely as a Software developer&lt;/li&gt;
&lt;li&gt;Had only written one blog post on medium&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&quot;where-i-am-now&quot;&gt;Where I am now&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;4 months experience working on open source project &lt;/li&gt;
&lt;li&gt;Improved on my previous technical skills, adding new ones (added Vue, Storybook, Webpack, Docker)&lt;/li&gt;
&lt;li&gt;4 months of experience working with a team remotely as a Software developer&lt;/li&gt;
&lt;li&gt;Written additional 6 more blog post; 3 here and 3 for Outreachy&lt;/li&gt;
&lt;li&gt;Improved communication skills &lt;/li&gt;
&lt;li&gt;Improved time management&lt;/li&gt;
&lt;li&gt;Still working to improve where I am now &lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;whats-next?&quot;&gt;Whats next?&lt;/h2&gt;&lt;p&gt;I will continue to contribute to CC open source projects especially to the Vocabulary project that I have become a part of. I would love to see the application of Vocabulary to the development of other CC platforms and applications.  I also want to apply the skills that I have acquired to get a full-time software developer position.&lt;/p&gt;
&lt;p&gt;My special appreciation to Outreachy for this opportunity, the entire CC team especially those I worked with, My mentors &lt;a href=&quot;/blog/authors/hugosolar/&quot;&gt;Hugo Solar&lt;/a&gt; and &lt;a href=&quot;/blog/authors/dhruvkb/&quot;&gt;Dhruv Bhanushali&lt;/a&gt; for their guidance, direction, and help whenever I got stuck, also to the Director of Engineering &lt;a href=&quot;/blog/authors/kgodey/&quot;&gt;Kriti Godey&lt;/a&gt; for always checking up on me ensuring I had a wonderful internship experience.&lt;/p&gt;
</content>
  </entry>
  <entry xml:base="http://opensource.creativecommons.org/blog/entries/2020-03-05-participe-gsoc/">
    <title type="text">Participe do Google Summer of Code / Outreachy</title>
    <id>urn:uuid:e5616ac8-3b6a-3afa-85f5-eddcd822577e</id>
    <updated>2020-03-05T00:00:00Z</updated>
    <link href="http://opensource.creativecommons.org/blog/entries/2020-03-05-participe-gsoc/" />
    <author>
      <name>brenoferreira</name>
    </author>
    <content type="html">&lt;p&gt;O Google Summer of Code (GSoC) √© uma iniciativa global do Google com o objetivo de incentivar a participa√ß√£o de estudantes com interesse em tecnologia a contribu√≠rem com projetos de software de c√≥digo aberto. Programa que existe desde 2005, que incentivou mais de 15.000 estudantes de mais de 118 pa√≠ses a se envolverem com v√°rias organiza√ß√µes que defendem o c√≥digo aberto.&lt;/p&gt;
&lt;p&gt;O Outreachy promove est√°gios para pessoas em organiza√ß√µes que trabalham com c√≥digo aberto. O foco da participa√ß√£o no programa est√° nas comunidades com pouca representa√ß√£o, vi√©s sist√™mico ou discrimina√ß√£o na √°rea de tecnologia.&lt;/p&gt;
&lt;p&gt;Os estudantes trabalham com uma organiza√ß√£o respons√°vel por algum projeto e durante um per√≠odo de est√°gio de 3 meses, e estar√£o sob tutoria de um(a) mentor(a) que ser√° respons√°vel por ajudar o estudante e gui√°-lo(a) a encontrar a melhor maneira de concluir o projeto.&lt;/p&gt;
&lt;p&gt;Em 2020 a Creative Commons est√° novamente participando do GSoC e Outreachy, e estagi√°rios participando conosco ter√£o a oportunidade de trabalhar em projetos relacionados √† cultura de acesso livre de impacto global, dentre eles o nosso principal produto de tecnologia, o CC Search, que √© um site de busca de conte√∫do livre licenciados com as licen√ßas da CC ou sob dom√≠nio p√∫blico.&lt;/p&gt;
&lt;p&gt;A Creative Commons √© uma organiza√ß√£o n√£o governamental sem fins lucrativos que criou licen√ßas que permitem a c√≥pia e compartilhamento com menos restri√ß√µes que o tradicional todos direitos reservados (copyright), as chamadas &lt;a href=&quot;https://creativecommons.org/licenses/?lang=pt_BR&quot;&gt;Licen√ßas Creative Commons&lt;/a&gt;, como CC-BY, CC-BY-SA, etc..&lt;/p&gt;
&lt;p&gt;Muitas das organiza√ß√µes que participam do programa do Google e Outreachy trabalham em projetos de c√≥digo livre utilizados globalmente em diversas aplica√ß√µes. √â uma oportunidade √∫nica de contribuir com um projeto que gera um impacto positivo na comunidade internacional de tecnologia. Al√©m disso, os estudantes ter√£o um mentor exclusivo para ajudar no desenvolvimento do projeto. N√£o √© um daqueles est√°gios onde os estudantes ficam desamparados nos momentos de dificuldade.&lt;/p&gt;
&lt;p&gt;O est√°gio √© remunerado naturalmente. Os valores pagos aos estagi√°rios pelo Google variam com a localiza√ß√£o onde o estudante mora e mais informa√ß√µes podem ser encontradas no &lt;a href=&quot;https://developers.google.com/open-source/gsoc/help/student-stipends&quot;&gt;site do programa&lt;/a&gt;. No caso do Outreachy, os valores est√£o tamb√©m na &lt;a href=&quot;https://www.outreachy.org&quot;&gt;p√°gina do programa&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Caso voce se interesse em participar do GSoC ou Outreachy esse ano, seguem algumas dicas que poder√£o te ajudar no seu processo de aplica√ß√£o e submiss√£o de projeto:&lt;/p&gt;
&lt;p&gt;Leia o conte√∫do dispon√≠vel online sobre como o programa funciona. &lt;a href=&quot;https://summerofcode.withgoogle.com/how-it-works] e [Outreachy](https://www.outreachy.org/docs/applicant/&quot;&gt;Google Summer of Code&lt;/a&gt;. Assim voce ir√° poder entender a proposta do programa, sua estrutura e tirar suas d√∫vidas; &lt;a href=&quot;https://opensource.creativecommons.org/internships/project-ideas/all/&quot;&gt;nossa lista de projetos&lt;/a&gt; que estamos sugerindo esse ano para os estudantes trabalhar e ver qual projeto est√° melhor alinhado com seus interesses e habilidades; e &lt;a href=&quot;https://opensource.creativecommons.org/internships/applicant-guide/&quot;&gt;nosso guia para candidatos&lt;/a&gt; para entender o passo a passo de como n√≥s iremos trabalhar com candidatos e estudantes selecionados para participar do programa. Esse conte√∫do est√° todo em ingl√™s.&lt;/p&gt;
&lt;p&gt;Sobre ingl√™s, para ser selecionado para trabalhar conosco, √© necess√°rio que voce consiga se comunicar razoavelmente bem em ingl√™s. A Creative Commons √© uma organiza√ß√£o internacional e voce precisar√° se comunicar com pessoas da organiza√ß√£o e da comunidade que n√£o falam portugu√™s. Eu, Breno Ferreira, autor desse post, falo portugues ent√£o caso voce se interesse pelo &lt;a href=&quot;https://opensource.creativecommons.org/internships/project-ideas/all/#cc-search-accessibility&quot;&gt;projeto que serei respons√°vel&lt;/a&gt;, eu poderei me comunicar em privado em portugues, mas toda comunica√ß√£o dos estudantes em canais p√∫blicos dever√° ser em ingl√™s. Voce n√£o precisa ser 100% fluente, mas precisa conseguir entender e se fazer entender no idioma.&lt;/p&gt;
&lt;p&gt;O GSoC √© um programa focado em contribui√ß√µes de c√≥digo, afinal, chama-se Google Summer of Code. Ent√£o, voce precisa ter alguns conhecimentos b√°sicos de algumas ferramentas para uma boa participa√ß√£o no programa.&lt;/p&gt;
&lt;p&gt;Voce precisar√° saber usar Git e Github. Todos os projetos da Creative Commons est√£o no Github e o conhecimento b√°sico dessas ferramentas √© fundamental. A &lt;a href=&quot;https://help.github.com/pt&quot;&gt;documenta√ß√£o do Github&lt;/a&gt; pode ajudar, principalmente a parte sobre &lt;a href=&quot;https://help.github.com/pt/github/collaborating-with-issues-and-pull-requests/about-pull-requests&quot;&gt;como funcionam os Pull Requests&lt;/a&gt; pois √© um recurso bem particular do Github e √© normal algumas pessoas n√£o saberem utilizar esse recurso muito importante.&lt;/p&gt;
&lt;p&gt;Na nossa p√°gina de &lt;a href=&quot;https://opensource.creativecommons.org/internships/project-ideas/all/&quot;&gt;ideias de projetos&lt;/a&gt; os projetos listam as habilidades recomendadas para quem se interessar (listado em &lt;em&gt;Skills recommended&lt;/em&gt;). Verifique se essas habilidades se alinham com as suas.&lt;/p&gt;
&lt;p&gt;Nessa fase inicial, o ideal √© voce come√ßar a fazer algumas contribui√ß√µes nos projetos que te interessam. Por exemplo, se voce se interessou pelo projeto de Acessibilidade e Internacionaliza√ß√£o do CC Search, o reposit√≥rio no Github relacionado √© &lt;a href=&quot;https://github.com/creativecommons/cccatalog-frontend&quot;&gt;https://github.com/creativecommons/cccatalog-frontend&lt;/a&gt;. De uma olhada na &lt;a href=&quot;https://github.com/creativecommons/cccatalog-frontend/issues&quot;&gt;lista de issues&lt;/a&gt; que est√£o marcadas com os labels &lt;a href=&quot;https://github.com/creativecommons/cccatalog-frontend/issues?q=is%3Aissue+is%3Aopen+label%3A%22good+first+issue%22&quot;&gt;&quot;Good First Issue&quot;&lt;/a&gt; e &lt;a href=&quot;https://github.com/creativecommons/cccatalog-frontend/issues?q=is%3Aissue+is%3Aopen+label%3A%22help+wanted%22&quot;&gt;&quot;Help Wanted&quot;&lt;/a&gt;. Essas s√£o as tarefas que n√≥s consideramos as melhores para quem quer come√ßar a contribuir para o projeto. Os nossos principais reposit√≥rios tem todos issues marcadas com esses labels. √â muito importante tamb√©m ler a documenta√ß√£o do projeto. Leia o arquivo README no reposit√≥rio. Nossos projetos tamb√©m possuem um arquivo CONTRIBUTING.md que cont√©m o c√≥digo de conduta para quem for contribuir com o projeto, e tamb√©m um guia sobre como contribuir com aquele projeto em espec√≠fico. Al√©m disso, √© interessante tamb√©m voce &lt;a href=&quot;https://opensource.creativecommons.org/community/&quot;&gt;participar da comunidade&lt;/a&gt;. Entre no nosso Slack e participe dos canais abertos. As pessoas est√£o l√° interagindo, postando comentarios e tirando d√∫vidas conosco e outros membros em um ambiente respeitoso e cordial.&lt;/p&gt;
&lt;p&gt;Durante o periodo de submiss√£o de projetos voce ir√° escrever sua proposta de projeto. √â bastante importante que voce compartilhe o rascunho da sua proposta o mais cedo poss√≠vel conosco para que possamos dar feedback e lhe dizer o que precisa ser melhorado. Se voce s√≥ compartilhar sua proposta no final do per√≠odo de submiss√£o, n√£o teremos a oportunidade de dizer o que est√° bom e ruim e voce n√£o poder√° fazer nenhuma melhoria. Ent√£o recomendamos que voce compartilhe seus rascunhos com os mentores cedo e frequentemente.&lt;/p&gt;
&lt;p&gt;Espero que essas dicas lhe ajudem. Caso voce n√£o seja selecionado(a), o GSoC √© um programa anual, e ano que vem acontece novamente. E no segundo semestre participaremos tamb√©m do programa Outreachy, que acontece duas vezes por ano. Caso voce acabe sendo selecionado(a), ser√° um prazer trabalhar com voce durante esses meses.&lt;/p&gt;
</content>
  </entry>
  <entry xml:base="http://opensource.creativecommons.org/blog/entries/2020-03-05-involucrate-gsoc-outreachy-es/">
    <title type="text">Invol√∫crate con nuestra comunidad de c√≥digo abierto a trav√©s del  Google Summer of Code y Outreachy</title>
    <id>urn:uuid:e28cf21f-757a-32de-a7b0-5c02f0083c21</id>
    <updated>2020-03-05T00:00:00Z</updated>
    <link href="http://opensource.creativecommons.org/blog/entries/2020-03-05-involucrate-gsoc-outreachy-es/" />
    <author>
      <name>hugosolar</name>
    </author>
    <content type="html">&lt;p&gt;En Creative Commons creemos firmemente en que el c√≥digo abierto es una gran herramienta para fomentar y desarrollar productos con un enfoque comunitario y, a su vez, la consolidaci√≥n de una comunidad activa de contribuyentes al  patrimonio com√∫n (o, en ingl√©s, &lt;em&gt;Commons&lt;/em&gt;).&lt;/p&gt;
&lt;p&gt;Con el fin de fomentar la participaci√≥n de estudiantes en nuestros proyectos de c√≥digo abierto, CC es parte de los programas que ofrece Google  (&lt;a href=&quot;https://summerofcode.withgoogle.com/&quot;&gt;Google Summer of Code&lt;/a&gt;) y tambi√©n &lt;a href=&quot;https://www.outreachy.org/&quot;&gt;Outreachy&lt;/a&gt;. En ambos casos, el objetivo es involucrar a estudiantes en el c√≥digo abierto. Para ello, hacemos un llamado abierto a todos y todas quienes tengan inter√©s en colaborar con nuestro equipo, de postular a los llamados cuanto antes.&lt;/p&gt;
&lt;h4 id=&quot;google-summer-of-code&quot;&gt;Google Summer of Code&lt;/h4&gt;&lt;p&gt;Programa impulsado por Google el cual existe desde el a√±o 2005 el cual ha impulsado a mas de 15.000 estudiantes de mas de 118 paises a involucrarse con diversas organizaciones que abogan por el c√≥digo abierto.&lt;/p&gt;
&lt;h4 id=&quot;outreachy&quot;&gt;Outreachy&lt;/h4&gt;&lt;p&gt;Este programa impulsa pasant√≠as de personas en organizaciones que trabajan con c√≥digo abierto. El foco de Outreachy est√° puesto en comunidades que poseen poca representatividad, que sufren prejuicios sist√©micos o discriminaci√≥n en el area de las tecnologias.&lt;/p&gt;
&lt;p&gt;Las pasant√≠as consisten en el desarrollo de un proyecto el cual debe ser llevado a cabo en un periodo de 3 meses. Este proceso se complementa con una mentor√≠a recibida por el estudiante la cual ayuda a guiar el desarrollo y buen t√©rmino del mismo.&lt;/p&gt;
&lt;p&gt;En las versiones pasadas de estos programas tuvimos excelentes resultados llevados a cabo por excelentes personas que pusieron toda su dedicaci√≥n para concretar estos proyectos:&lt;/p&gt;
&lt;h2 id=&quot;gsoc-2019&quot;&gt;GSoC 2019&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;https://github.com/creativecommons/wp-plugin-creativecommons&quot;&gt;Wordpress Plugin&lt;/a&gt; por Ahmad Bilal&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://github.com/creativecommons/ccsearch-browser-extension&quot;&gt;CC Search Browser extension&lt;/a&gt; por Mayank Nader&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://github.com/creativecommons/vue-vocabulary&quot;&gt;CC Vocabulary&lt;/a&gt; por Dhruv Bhanushali&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://github.com/creativecommons/cc-chooser&quot;&gt;Revamping the CC Chooser&lt;/a&gt; por Ari Madian&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://github.com/creativecommons/cccatalog-dataviz&quot;&gt;CC Catalog Data Visualization&lt;/a&gt; por Maria Belen Guaranda&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;outreachy-2019-2020&quot;&gt;Outreachy 2019-2020&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;https://github.com/creativecommons/cc-chooser&quot;&gt;Improve License Chooser&lt;/a&gt; por Olga Bulat&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://github.com/creativecommons/vue-vocabulary&quot;&gt;Extend the scope and/or use of CC Vocabulary&lt;/a&gt; por Chidiebere Onyegbuchulem&lt;/li&gt;
&lt;li&gt;Revamp CC's Platform Toolkit guide por Ana Paula Rocha&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;De esta manera hemos decidido participar de las siguientes rondas de ambos programas, los cuales se encuentran en la fase de ‚Äúcontribuci√≥n a la comunidad‚Äù, por lo tanto, a√∫n est√°s a tiempo de leer documentaci√≥n al respecto, tanto de los programas como de la participaci√≥n en los proyectos de nuestra organizaci√≥n&lt;/p&gt;
&lt;h3 id=&quot;gsoc&quot;&gt;GSoC&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;https://summerofcode.withgoogle.com/organizations/&quot;&gt;Organizaciones participantes&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://summerofcode.withgoogle.com/how-it-works/&quot;&gt;Como funciona&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://google.github.io/gsocguides/student/&quot;&gt;Gu√≠a de estudiante&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&quot;outreachy&quot;&gt;Outreachy&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;https://www.outreachy.org/apply/project-selection/&quot;&gt;Organizaciones / proyectos&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://www.outreachy.org/apply/&quot;&gt;Como funciona&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://www.outreachy.org/docs/internship/&quot;&gt;Guia de estudiante&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&quot;cc-open-source&quot;&gt;CC Open Source&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;https://opensource.creativecommons.org/internships/intern-guide/&quot;&gt;Guia del postulante&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://opensource.creativecommons.org/contributing-code/projects/&quot;&gt;Listado de proyectos&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://opensource.creativecommons.org/contributing-code/&quot;&gt;Lineamientos para contribuir&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;beneficios&quot;&gt;Beneficios&lt;/h2&gt;&lt;p&gt;Estos programas proveen m√∫ltiples beneficios a quienes deseen participar de ellos, por un lado, las organizaciones participantes trabajan en proyectos de c√≥digo abierto utilizados en todo el mundo y en diversas aplicaciones, convirti√©ndose en una oportunidad √∫nica de contribuir a proyectos de gran escala que adem√°s cuentan con comunidades globales transformando adem√°s esta pasant√≠a en una experiencia enriquecedora.&lt;/p&gt;
&lt;p&gt;Por otro lado, t√©cnicamente hablando, tambi√©n comprende un gran desaf√≠o, ya que existe la posibilidad de enfrentarse a la resoluci√≥n de un problema del mundo real, sin embargo, el hecho de poder enfrentarlo con una mentor√≠a exclusiva provee un gran n√∫mero de herramientas para el desarrollo y concreci√≥n del proyecto, los cuales, sin duda, seran de gran ayuda para el futuro desarrollo de la vida profesional de quien participe.&lt;/p&gt;
&lt;p&gt;Adem√°s, estos programas consideran un estipendio por los 3 meses que dura la pasant√≠a. Valores que son variables seg√∫n la ubicaci√≥n que quien desea postular.&lt;/p&gt;
&lt;h2 id=&quot;destrezas&quot;&gt;Destrezas&lt;/h2&gt;&lt;p&gt;Con respecto al idioma, para participar en estos programas no se exige un manejo del ingl√©s al 100%, solo basta que puedas comunicarte de manera razonable, ya que, si bien, existen algunos proyectos en los cuales yo soy el mentor ( &lt;a href=&quot;https://opensource.creativecommons.org/internships/project-ideas/all/#wp-plugin&quot;&gt;WP Plugin&lt;/a&gt; e &lt;a href=&quot;https://opensource.creativecommons.org/internships/project-ideas/all/#vocabulary-integration&quot;&gt;Implementar Vocabulary&lt;/a&gt; ) y podemos tener reuniones en espa√±ol, la comunicaci√≥n p√∫blica y la documentaci√≥n debe ser en Ingl√©s.&lt;/p&gt;
&lt;p&gt;Con respecto a nuestros proyectos, todos se encuentran en &lt;a href=&quot;https://github.com/creativecommons&quot;&gt;Github&lt;/a&gt; por lo tanto debes saber lo b√°sico de &lt;a href=&quot;https://rogerdudler.github.io/git-guide/index.es.html&quot;&gt;Git&lt;/a&gt;. Te recomiendo consultar la &lt;a href=&quot;https://help.github.com/es&quot;&gt;ayuda de Github&lt;/a&gt; para mayor detalle, sugiero poner atenci√≥n a la guia sobre como realizar &lt;a href=&quot;https://help.github.com/es/github/collaborating-with-issues-and-pull-requests/about-pull-requests&quot;&gt;Pull Request&lt;/a&gt; ya que es muy necesario para el flujo de trabajo del equipo tecnico de CC y lo ser√° tambi√©n para tu pasant√≠a.&lt;/p&gt;
&lt;h2 id=&quot;invitacin&quot;&gt;Invitaci√≥n&lt;/h2&gt;&lt;p&gt;Desde y√° los dejamos invitados a participar en estos programas o a participar directamente en nuestra &lt;a href=&quot;https://opensource.creativecommons.org/&quot;&gt;comunidad de c√≥digo abierto&lt;/a&gt; o visitar nuestro &lt;a href=&quot;https://github.com/creativecommons&quot;&gt;Github&lt;/a&gt;, el cual contiene nuestros proyectos. Tambi√©n pueden unirse a nuestra comunidad global en &lt;a href=&quot;https://slack-signup.creativecommons.org/&quot;&gt;Slack&lt;/a&gt; donde me pueden encontrar como @hugo si tienen alguna duda o comentario.&lt;/p&gt;
</content>
  </entry>
  <entry xml:base="http://opensource.creativecommons.org/blog/entries/cc-platform-toolkit-revamp-4/">
    <title type="text">CC Platform Toolkit Revamp - 4</title>
    <id>urn:uuid:99b50998-4560-3b3f-80bd-b03b892c84ab</id>
    <updated>2020-03-04T00:00:00Z</updated>
    <link href="http://opensource.creativecommons.org/blog/entries/cc-platform-toolkit-revamp-4/" />
    <author>
      <name>apdsrocha</name>
    </author>
    <content type="html">&lt;p&gt;Phew, how is it possible that we're already in March? Between my last check-in and today, there was a lot of work and effort into revamping the &lt;a href=&quot;https://creativecommons.org/platform/toolkit/&quot;&gt;Platform Toolkit&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;There were two rounds of user interviews: the first one was done looking only at the wireframe, focusing exclusively on usability and content. This provided a lot of important feedback to adjust the structure and move forward with the UI.  I tried my best to apply the design standards already mapped out by the &lt;a href=&quot;https://github.com/creativecommons/vocabulary/&quot;&gt;Vocabulary&lt;/a&gt; project, so that in the future this wouldn't stand out from other CC materials.&lt;/p&gt;
&lt;p&gt;The second round of user interviews was done with a UI prototype, and was meant to take away some of my doubts regarding a few choices in this project. For instance, would it be best for the user to have the information in a single page, or would that be too much, and best to split in separate pages? There were pros and cons to both scenarios, but in the end we decided to stick with the single-page format because of a particular behavior: one of the ways users search for content is to ctrl+F and look for keywords. That would be drastically less effective with multiple pages.&lt;/p&gt;
&lt;p&gt;After all the feedback (and adjustments) were done, it was time to make things come to life. I built the page from scratch with HTML/CSS/JS, making use of the Vocabulary library - it should be live soon, so yay!&lt;/p&gt;
&lt;p&gt;The last three months have been incredible and this was a wonderful opportunity to tackle a project from start to finish. I feel very grateful for all the time and dedication my mentors put into this project, they guided me every step of the way and made sure I was supported throughout the internship. I plan on staying involved in the CC community, so hopefully soon I will have more to contribute.&lt;/p&gt;
</content>
  </entry>
  <entry xml:base="http://opensource.creativecommons.org/blog/entries/cc-vocabulary-week5-8/">
    <title type="text">CC Vocabulary - Weeks 5-8</title>
    <id>urn:uuid:b30bf3b1-be65-3f4d-a3c5-5ac5c7c9f626</id>
    <updated>2020-02-03T00:00:00Z</updated>
    <link href="http://opensource.creativecommons.org/blog/entries/cc-vocabulary-week5-8/" />
    <author>
      <name>conye</name>
    </author>
    <content type="html">&lt;p&gt;A lot of time and effort have been put in to re-work Vocabulary since my last post and the changes are still ongoing. To understand why these changes are important, we have to better understand Vocabulary.&lt;/p&gt;
&lt;h2 id=&quot;so-why-all-the-changes?&quot;&gt;So Why All The Changes?&lt;/h2&gt;&lt;p&gt;Vocabulary is CC's new design system. This means its design is meant to affect all of CC's websites, applications, and platforms. It is designed to be independent of any language or framework. Its styling will be used by its subsets like Vue-Vocabulary to maintain consistency. The majority of CC's websites and platforms are built with Wordpress, Lektor, and Vue. This means Vue-Vocabulary will inherit its styling from Vocabulary and the same will follow for other subsets of Vocabulary for Wordpress and Lektor which would possibly be developed soon.&lt;/p&gt;
&lt;h2 id=&quot;the-major-change&quot;&gt;The Major Change&lt;/h2&gt;&lt;p&gt;Vocabulary currently uses stylus to easily write the CSS and Webpack as a build system. Stylus will be changed to SASS (actually SCSS). This is because SASS is easier to maintain and the majority of CC's websites are already built with SASS.&lt;/p&gt;
&lt;h2 id=&quot;my-contributions-in-the-past-four-weeks&quot;&gt;My Contributions in the past four weeks&lt;/h2&gt;&lt;p&gt;In the past four weeks, I have been contributing majorly to the re-work of Vocabulary. Some of my contributions include:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Adding vendor prefixes to compiled CSS using autoprefixer&lt;/li&gt;
&lt;li&gt;Updating build script for output CSS token to include CSS custom properties format&lt;/li&gt;
&lt;li&gt;Restyling some components as specified in the new design&lt;/li&gt;
&lt;li&gt;Minifying and cleaning SVGs with SVGOMG&lt;/li&gt;
&lt;li&gt;Removing some components and features not required in the new design&lt;/li&gt;
&lt;li&gt;Fixing broken links&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;There has also been a lot of learning for me too. For example, I have been learning better how Webpack and Docker are used in this project.&lt;/p&gt;
&lt;p&gt;Yeah, I said I would share more in two weeks from my last post but it turned out in four weeks but I will try to make in two weeks for my next post.&lt;/p&gt;
</content>
  </entry>
  <entry xml:base="http://opensource.creativecommons.org/blog/entries/improving-cc-license-chooser-coding/">
    <title type="text">Improving CC License Chooser: Coding</title>
    <id>urn:uuid:bda5e013-2b29-3207-8041-cff3bfab0c22</id>
    <updated>2020-01-24T00:00:00Z</updated>
    <link href="http://opensource.creativecommons.org/blog/entries/improving-cc-license-chooser-coding/" />
    <author>
      <name>obulat</name>
    </author>
    <content type="html">&lt;p&gt;During the last several weeks I have been busy with coding the redesigned version of the License Chooser.&lt;/p&gt;
&lt;p&gt;When I just started working on coding the License Chooser, it wouldn't compile due to some dependency problems. This became a great opportunity to update the project from a Webpack based Vue.js template to a Vue-cli project, which makes managing dependencies much simpler. I also updated the project to a newer version of Creative Commons Vue Vocabulary for styling.&lt;/p&gt;
&lt;p&gt;For the visual styles, we use Buefy component library (based on Bulma and Vue.js), namely, stepper and tabs components. It has been an interesting journey customizing them to our specific use cases.&lt;/p&gt;
&lt;p&gt;While coding the site, I also tried to extract all the text to a separate file so that it would be easier to integrate it into translation workflow later during my internship.&lt;/p&gt;
&lt;p&gt;After several weeks of work, 2 large PRs merged, we are finally ready to conduct usability tests to better understand how users interact with the License Chooser, and what changes we still need to implement to make it easy both for beginners and for advanced users of Creative Commons Licenses to choose the best license for their needs, and help to use the chosen license.&lt;/p&gt;
&lt;p&gt;A new &lt;a href=&quot;https://chooser-beta.creativecommons.org/&quot;&gt;beta version of the License Chooser&lt;/a&gt; is deployed!&lt;/p&gt;
</content>
  </entry>
  <entry xml:base="http://opensource.creativecommons.org/blog/entries/apache-airflow-testing-with-pytest/">
    <title type="text">Apache Airflow testing with Pytest</title>
    <id>urn:uuid:c59eaf57-778e-3d75-8929-537949d119fd</id>
    <updated>2020-01-23T00:00:00Z</updated>
    <link href="http://opensource.creativecommons.org/blog/entries/apache-airflow-testing-with-pytest/" />
    <author>
      <name>mathemancer</name>
    </author>
    <content type="html">&lt;p&gt;CC Catalog is a project that gathers information about images from around the
internet, and stores the information so that these images can eventually be
indexed in &lt;a href=&quot;https://ccsearch.creativecommons.org/&quot;&gt;CC Search&lt;/a&gt;. A portion of the process is directed by
&lt;a href=&quot;https://airflow.apache.org/&quot;&gt;Apache Airflow&lt;/a&gt;, which is a tool commonly used to organize workflows
and data pipelines.&lt;/p&gt;
&lt;p&gt;The nature of Airflow leads to some particular challenges when it comes to
testing, and special care must be taken to make tests independent from the
global state of the system where they are run.  This blog post will describe a
few of the challenges we faced when writing tests for Airflow jobs, and some
tricks we used to solve those challenges.&lt;/p&gt;
&lt;h2 id=&quot;brief-description-of-apache-airflow&quot;&gt;Brief description of Apache Airflow&lt;/h2&gt;&lt;p&gt;Apache Airflow is an open source piece of software that loads Directed Acyclic
Graphs (DAGs) defined via python files.  The DAG is what defines a given
workflow.  The nodes are pieces of jobs that need to be accomplished, and the
directed edges of the graph define dependencies between the various pieces.  By
default, the Airflow daemon only looks for DAGs to load from a global location
in the user's home folder: &lt;code&gt;~/airflow/dags/&lt;/code&gt;. When a DAG is 'run', i.e., the
tasks defined by the nodes of the DAG are each performed in the order defined by
the directed edges of the DAG, the Airflow daemon stores information about the
dag run in &lt;code&gt;~/airflow/&lt;/code&gt;.  The daemon also stores general information about what
DAGs exist on the system, and all of their current statuses in that directory.
For more details, please see &lt;a href=&quot;https://airflow.apache.org/docs/stable/&quot;&gt;the documentation&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&quot;challenge:-localize-airflow-to-the-project-directory&quot;&gt;Challenge:  Localize Airflow to the project directory&lt;/h2&gt;&lt;p&gt;Even when installed using &lt;code&gt;pip&lt;/code&gt; within a &lt;a href=&quot;https://github.com/pypa/virtualenv&quot;&gt;&lt;code&gt;virtualenv&lt;/code&gt;&lt;/a&gt; environment,
all airflow commands will be run against the default locations in the user's
home directory. In particular, if you want to test a DAG from your project
directory, the method given in the &lt;a href=&quot;https://airflow.apache.org/docs/stable/tutorial.html#testing&quot;&gt;Airflow documentation&lt;/a&gt; is to
copy the dag into the default location &lt;code&gt;~/airflow/dags/&lt;/code&gt;, and use the
command-line &lt;code&gt;airflow&lt;/code&gt; tool to run the tasks defined by the nodes.  The
information about success and failure of the tests will be stored by the Airflow
daemon in the &lt;code&gt;~/airflow/&lt;/code&gt; directory.  We'd rather keep all input and output
from our tests to the project directory instead.  This helps avoid any side
effects which might arise by running tests for different projects, and also
ensures that tests can't affect anything in the default directory, which may be
used for production in many cases.&lt;/p&gt;
&lt;p&gt;The solution is to choose a directory in your project, and set the environment
variable &lt;code&gt;$AIRFLOW_HOME&lt;/code&gt; whenever you run the tests, or use the &lt;code&gt;airflow&lt;/code&gt;
command on the project DAGs. I recommend you add the command&lt;/p&gt;
&lt;div class=&quot;hll&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;export&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;AIRFLOW_HOME&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;/your/desired/full/path/
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;to a script (ours is called &lt;code&gt;env.sh&lt;/code&gt;) that will be run in any shell dealing with
the 'localized' Airflow instance, because forgetting to set the variable for
even one &lt;code&gt;airflow&lt;/code&gt; command will corrupt the DAG states stored in the global
area. Note that setting this variable is necessary even when running in a
&lt;code&gt;virtualenv&lt;/code&gt; environment.&lt;/p&gt;
&lt;p&gt;Now that you have &lt;code&gt;$AIRFLOW_HOME&lt;/code&gt; set, you'll likely want to load some DAGs that
you've written.  This is made easier if you put the files defining them into a
&lt;code&gt;dags&lt;/code&gt; directory in the directory denoted by &lt;code&gt;$AIRFLOW_HOME&lt;/code&gt;.  I.e., it's wise
to structure the project sub-directory dealing with Airflow and Airflow DAGs
similarly to the default location, but in your project directory.  At this
point, you should have some &lt;code&gt;$AIRFLOW_HOME&lt;/code&gt; directory as a subdirectory of your
project directory, and then some &lt;code&gt;$AIRFLOW_HOME/dags&lt;/code&gt; directory, where you keep
any python files defining Airflow DAGs, and their dependencies.  Another
advantage of this structure is it's likely the directory structure you'll use in
production, and replicating simplifies deployment.&lt;/p&gt;
&lt;p&gt;Finally, Airflow will leave a number of files in the &lt;code&gt;$AIRFLOW_HOME&lt;/code&gt; directory
which you are not likely to want to track in source control (e.g., &lt;code&gt;git&lt;/code&gt;).
These files are:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;$AIRFLOW_HOME/airflow.cfg&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;$AIRFLOW_HOME/airflow.db&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;$AIRFLOW_HOME/logs/&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;$AIRFLOW_HOME/unittests.cfg&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Add these files to &lt;code&gt;.gitignore&lt;/code&gt; or the equivalent.&lt;/p&gt;
&lt;h2 id=&quot;smoketesting:-can-the-airflow-daemon-load-the-dags?&quot;&gt;Smoketesting:  Can the Airflow daemon load the DAGs?&lt;/h2&gt;&lt;p&gt;Note that we're using &lt;code&gt;pytest&lt;/code&gt; for our unit testing, and so most examples assume
this.&lt;/p&gt;
&lt;p&gt;The most basic test you'll want is to determine whether your DAGs can load
without errors. To do this, you can use the following function:&lt;/p&gt;
&lt;div class=&quot;hll&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;airflow.models&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;DagBag&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;test_dags_load_with_no_errors&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;():&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;dag_bag&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;DagBag&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;include_examples&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;kc&quot;&gt;False&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;dag_bag&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;process_file&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;common_api_workflows.py&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;assert&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dag_bag&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;import_errors&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;We initialize a &lt;code&gt;DagBag&lt;/code&gt; (this loads DAG files). With the &lt;code&gt;process_file&lt;/code&gt; method,
we instruct the Airflow daemon to attempt to load any DAGs defined in the
&lt;code&gt;common_api_workflows.py&lt;/code&gt; file.  We then check to make sure loading the DAGs
didn't produce any errors.&lt;/p&gt;
&lt;h2 id=&quot;hint:-use-functions-to-create-dags.&quot;&gt;Hint: Use functions to create DAGs.&lt;/h2&gt;&lt;p&gt;This will increase testability. You can test the function, bypassing the need to
load the DAG into the &lt;code&gt;DagBag&lt;/code&gt; (except when you're actually testing that it
&lt;em&gt;can&lt;/em&gt; be loaded). This may seem obvious, but none of the Airflow documentation
uses this pattern. Here is an example of a function that creates a simple dag,
and a test of the function:&lt;/p&gt;
&lt;div class=&quot;hll&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;airflow&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;DAG&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;airflow.operators.bash_operator&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;BashOperator&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;create_dag&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;source&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;script_location&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;dag_id&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;crontab_str&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;kc&quot;&gt;None&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;default_args&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;DAG_DEFAULT_ARGS&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;

    &lt;span class=&quot;n&quot;&gt;dag&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;DAG&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;dag_id&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dag_id&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;default_args&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;default_args&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;schedule_interval&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;crontab_str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;catchup&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;kc&quot;&gt;False&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;with&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dag&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;start_task&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;BashOperator&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;task_id&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{}&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;_&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{}&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;format&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;source&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;status&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;bash_command&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;echo Starting &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{}&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt; workflow&amp;#39;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;format&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;status&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;dag&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dag&lt;/span&gt;
        &lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

        &lt;span class=&quot;n&quot;&gt;run_task&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;  &lt;span class=&quot;n&quot;&gt;BashOperator&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;task_id&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;get_&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{}&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;_images&amp;#39;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;format&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;source&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;bash_command&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;python &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{}&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt; --mode default&amp;#39;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;format&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;script_location&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;dag&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dag&lt;/span&gt;
        &lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

        &lt;span class=&quot;n&quot;&gt;start_task&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;run_task&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dag&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;test_create_dag_creates_correct_dependencies&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;():&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;dag&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;create_dag&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
        &lt;span class=&quot;s1&quot;&gt;&amp;#39;test_source&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
        &lt;span class=&quot;s1&quot;&gt;&amp;#39;test_script_location&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
        &lt;span class=&quot;s1&quot;&gt;&amp;#39;test_dag_id&amp;#39;&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;start_id&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&amp;#39;test_source_starting&amp;#39;&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;run_id&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&amp;#39;get_test_source_images&amp;#39;&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;start_task&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dag&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;get_task&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;start_id&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;assert&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;start_task&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;upstream_task_ids&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;set&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;assert&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;start_task&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;downstream_task_ids&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;set&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;run_id&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;run_task&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dag&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;get_task&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;run_id&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;assert&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;run_task&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;upstream_task_ids&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;set&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;start_id&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;assert&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;run_task&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;downstream_task_ids&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;set&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([])&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Here, we assume that &lt;code&gt;DAG_DEFAULT_ARGS&lt;/code&gt; is defined earlier in the file.  See the
Airflow documentation for details about default DAG arguments. Now, this
function is testable (great!) but it doesn't acutally make the DAG it creates
known to the Airflow daemon. To do that, we have to create the created dag into
the global scope of the module defined by the file, which can be done with the
following snippet:&lt;/p&gt;
&lt;div class=&quot;hll&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;globals&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dag_id&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;create_dag&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;source&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;script_location&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;dag_id&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Here, it's assumed that &lt;code&gt;source&lt;/code&gt;, &lt;code&gt;script_location&lt;/code&gt;, and &lt;code&gt;dag_id&lt;/code&gt; are defined
earlier in the python file.&lt;/p&gt;
&lt;p&gt;We hope that these hints are helpful to the reader.  For more, and for the
context around the snippets shown here, please take a look at
&lt;a href=&quot;https://github.com/creativecommons/cccatalog/tree/c4b80600eb5695cc294e1791ba90bdc3a408b7b9/src/cc_catalog_airflow&quot;&gt;the repo&lt;/a&gt;.&lt;/p&gt;
</content>
  </entry>
  <entry xml:base="http://opensource.creativecommons.org/blog/entries/cc-platform-toolkit-revamp-3/">
    <title type="text">CC Platform Toolkit Revamp - 3</title>
    <id>urn:uuid:297bf32e-1761-3ec6-967a-4cb76007305c</id>
    <updated>2020-01-22T00:00:00Z</updated>
    <link href="http://opensource.creativecommons.org/blog/entries/cc-platform-toolkit-revamp-3/" />
    <author>
      <name>apdsrocha</name>
    </author>
    <content type="html">&lt;p&gt;Last time I checked-in, I was working on revisiting the current &lt;a href=&quot;https://creativecommons.org/platform/toolkit/&quot;&gt;Platform Toolkit&lt;/a&gt; and making a first draft suggesting changes in both content and structure.&lt;/p&gt;
&lt;p&gt;It was a lot of work, but I'm finally happy with the wire-frame that came out after all the research and experimentation. The original material went through quite a few modifications, with text rewrites and changes in the order and organization of the content. But now comes the important part: making sure that these changes make sense to the users. My vision is already a little skewed, since I've been immersed in this project for the past 7 weeks. From now on, the process of validating this material needs fresh eyes. That way, improvements can be made based on user feedback, and reflect the best possible version when it the time comes to implement.&lt;/p&gt;
&lt;p&gt;For the next two weeks my schedule is focusing on two different activities: I'll be going over a round of user interviews where I intend to show my wireframe and present a few tasks. The idea is to see how both content and usability perform in this new format. In parallel, I've also began taking these wire-framed components and sketching them out in a more refined UI format by experimenting with color, type, and so on. I really wanted to get an early start on this task‚Äîeven if it's subject to change as the research gives me further insights‚Äîbecause I feel making the visual part come together will be the hardest part for me.&lt;/p&gt;
&lt;p&gt;Thankfully, I have very supportive mentors and help all-around from the CC staff and community. I'm really happy with how this project is coming together and I hope in two weeks I can come back here and report on great progress!&lt;/p&gt;
</content>
  </entry>
  <entry xml:base="http://opensource.creativecommons.org/blog/entries/cc-vocabulary-my-first-four-weeks/">
    <title type="text">CC Vocabulary - My First Four Weeks</title>
    <id>urn:uuid:f0b37b2b-043a-3606-b848-2299619bb41c</id>
    <updated>2020-01-14T00:00:00Z</updated>
    <link href="http://opensource.creativecommons.org/blog/entries/cc-vocabulary-my-first-four-weeks/" />
    <author>
      <name>conye</name>
    </author>
    <content type="html">&lt;p&gt;&lt;a href=&quot;https://cc-vocabulary.netlify.com/&quot;&gt;Vocabulary&lt;/a&gt; is Creative Commons's web design system; an extension of 
&lt;a href=&quot;https://creativecommons.org/wp-content/uploads/2019/10/Creative-Commons-Style-Guide-2019.pdf&quot;&gt;CC Style Guide&lt;/a&gt; 
for the web. This project was originally started by my mentors &lt;a href=&quot;https://opensource.creativecommons.org/blog/authors/dhruvkb&quot;&gt;Dhruv Bhanushali&lt;/a&gt; 
and &lt;a href=&quot;https://opensource.creativecommons.org/blog/authors/hugosolar&quot;&gt;Hugo Solar&lt;/a&gt; to unify all of CC websites and applications. 
Vocabulary has been undergoing a lot of changes lately. As part of my Outreachy internship, 
I will be contributing to extending its scope and usage.&lt;/p&gt;
&lt;h2 id=&quot;my-progress-so-far...&quot;&gt;My Progress so far...&lt;/h2&gt;&lt;p&gt;Before my first contribution, Vocabulary comprised of reusable UI components built with Vue.js and a live styleguide built with Styleguidist. 
My first task was to create an interactive playground experience with Storybook which would eventually replace that built with Styleguidist. 
Storybook was chosen for obvious reasons:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;It provides a workbench environment for your components in isolation where you can play around with, customize and test as you develop.&lt;/li&gt;
&lt;li&gt;It provides Storybook Docs to generate design system documentation, customize, and share best practices with your team. 
Styleguidist majorly creates a UI documentation site that can be done better with Storybook Docs.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;My first three weeks were more of struggling and learning. Coming from a React background, I had to reconfigure my brain to understand Vue 
and Vue storybook. I did a lot of reading of documentation and articles, testing locally and asking for help when stuck. I eventually completed 
the task and created a pull request. A live version of the interactive playground can be seen 
&lt;a href=&quot;https://cc-vue-vocabulary.netlify.com/storybook/?path=/story/vocabulary-welcome--welcome&quot;&gt;here&lt;/a&gt;. 
Please feel free to play around with it and give a feedback.&lt;/p&gt;
&lt;p&gt;The following week, I worked on updating some Vue Vocabulary components with the CC Vocabulary design library.&lt;/p&gt;
&lt;h2 id=&quot;what-s-next...&quot;&gt;What's Next...&lt;/h2&gt;&lt;p&gt;This week, I will be working on extending the usage of vocabulary to other CC websites that are not built with Vue. 
What I worked on previously was &lt;a href=&quot;https://cc-vue-vocabulary.netlify.com/&quot;&gt;Vue-Vocabulary&lt;/a&gt; for CC websites and 
platforms that support Vue. The goal is to use the already developed stylesheets in Vocabulary to build the 
same functional components with vanilla JavaScript.&lt;/p&gt;
&lt;p&gt;Well, all said, the past weeks have been great. I will be sharing more in two weeks.&lt;/p&gt;
</content>
  </entry>
  <entry xml:base="http://opensource.creativecommons.org/blog/entries/improving-cc-license-chooser-weeks-1-2-design/">
    <title type="text">Improving CC License Chooser Weeks 1-2: Design</title>
    <id>urn:uuid:24a0bec2-ab5d-3990-9d96-1c8d52fe24f1</id>
    <updated>2020-01-06T00:00:00Z</updated>
    <link href="http://opensource.creativecommons.org/blog/entries/improving-cc-license-chooser-weeks-1-2-design/" />
    <author>
      <name>obulat</name>
    </author>
    <content type="html">&lt;p&gt;Creative Commons License Chooser has been helping creators to choose the most appropriate license for their work for a long time. As anything on the web, it needs updating. One of my mentors, &lt;a href=&quot;https://opensource.creativecommons.org/blog/authors/akmadian/&quot;&gt;Ari Madian&lt;/a&gt;, has created the new version of this chooser as part of his 2019 GSoC Project. As a 2019-2020 Outreachy intern, I will be working on making it production-ready. The goals of my internship include:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Improving usability of the Chooser and making it easier for licensors to understand the process of selecting the most appropriate license.&lt;/li&gt;
&lt;li&gt;Setting up and automating internalization.&lt;/li&gt;
&lt;li&gt;Extracting License Chooser as a standalone npm package to make integrating Creative Commons licensing in other websites easier.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;During the first two weeks of my internship I mainly worked on redesigning the license selection process based on the usability testing feedback. We decided to set up license selection as a step-by-step process of answering yes/no questions guiding a novice or somewhat experienced user to the CC license that best suits their needs.&lt;/p&gt;
&lt;hr&gt;
&lt;h3 id=&quot;here-is-the-first-draft:&quot;&gt;&lt;strong&gt;Here is the first draft:&lt;/strong&gt;&lt;/h3&gt;&lt;p&gt;&lt;img src=&quot;/blog/entries/improving-cc-license-chooser-weeks-1-2-design/draft-1.png&quot; alt=&quot;draft-1.png&quot;&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Features of this draft that stayed in current version:&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;A card to show the information about currently selected license is prominent on the page.&lt;/li&gt;
&lt;li&gt;Four yes/no questions that help narrow the license choice.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;em&gt;What was changed in final version:&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The openness scale (which is drawn incorrectly, by the way) took up too much space on the first screen, not adding as much to the process.&lt;/li&gt;
&lt;li&gt;Toggles as an answer to yes/no questions are confusing for some users.&lt;/li&gt;
&lt;li&gt;Separate Personalization step was moved together with other steps.&lt;/li&gt;
&lt;li&gt;License attribution information was merged with the selected license card, because the card is supposed to contain all the information about selected license, including author/work url/ source url, if they are available.&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h3 id=&quot;draft-2&quot;&gt;&lt;strong&gt;Draft 2&lt;/strong&gt;&lt;/h3&gt;&lt;p&gt;As a result of continuous communication with my mentors, I this draft to be discussed at our weekly meeting.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/blog/entries/improving-cc-license-chooser-weeks-1-2-design/draft-2.png&quot; alt=&quot;draft-2.png&quot;&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Features that stayed in the current version:&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Two cards: one for the step-by-step process and the other for presenting license information.&lt;/li&gt;
&lt;li&gt;All the information about selected license in the second card.&lt;/li&gt;
&lt;li&gt;Personalization step as the last and optional step of choosing the license.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;em&gt;Features that were suggested during the meeting:&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;License selection dropdown with all available licenses on the selected license card. This is for experienced users who know what license they want to choose and only need to add details, or copy the attribution text or html.&lt;/li&gt;
&lt;li&gt;A link to a page with more information on how to use the license when sharing on the selected license card: for users who need help with that.&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h3 id=&quot;currently-final-draft-:&quot;&gt;&lt;strong&gt;Currently Final Draft :)&lt;/strong&gt;&lt;/h3&gt;&lt;p&gt;&lt;img src=&quot;/blog/entries/improving-cc-license-chooser-weeks-1-2-design/draft-3.png&quot; alt=&quot;draft-3.png&quot;&gt;&lt;/p&gt;
&lt;h4 id=&quot;license-chooser-stepper-card&quot;&gt;&lt;strong&gt;License Chooser Stepper Card&lt;/strong&gt;&lt;/h4&gt;&lt;ul&gt;
&lt;li&gt;Stepper Card shows five steps to selecting a license, one for each feature of CC licenses and an optional personalization step. The stepper icons show current selection status: selected/unselected features and current feature being displayed. Clicking on an icon opens the corresponding step.&lt;/li&gt;
&lt;li&gt;Each license feature has a yes/no question. A user clicks on a yes or no button to answer, and can immediately see what changed in the license, and the text beneath the buttons shows what current selection of the feature actually means. Default answer for each step besides the first one (attribution - 'BY') is 'no', so if a user simply clicks 'next' on each step, or clicks on the last step icon at the top, they get CC BY 4.0 license.&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&quot;selected-license-card&quot;&gt;&lt;strong&gt;Selected License Card&lt;/strong&gt;&lt;/h4&gt;&lt;ul&gt;
&lt;li&gt;Current selection dropdown is for experienced users who can quickly select a license that they know they want to use. It also updates when a feature in the license selection process is changed.&lt;/li&gt;
&lt;li&gt;Selected license information displays information about the license and its clauses, as well as its icons. The wording of this part will probably change the most after discussion with the community and legal team.&lt;/li&gt;
&lt;li&gt;Attribution information for the license, with a choice between rich text or html code. These are displayed in tabs to save on space. &lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;I created the wireframes in Figma, and I tried to integrate CC Vocabulary elements as much as possible.&lt;/p&gt;
&lt;p&gt;Next steps for my project will include coding to update the license chooser Vue.js project, and iterating over the design based on community feedback.&lt;/p&gt;
&lt;p&gt;You can follow my work at &lt;a href=&quot;https://github.com/creativecommons/cc-chooser&quot;&gt;https://github.com/creativecommons/cc-chooser&lt;/a&gt;.&lt;/p&gt;
</content>
  </entry>
  <entry xml:base="http://opensource.creativecommons.org/blog/entries/cc-platform-toolkit-revamp-2/">
    <title type="text">CC Platform Toolkit Revamp - 2</title>
    <id>urn:uuid:dba4dc6a-e8b6-3f06-9b03-2d58dd440755</id>
    <updated>2020-01-06T00:00:00Z</updated>
    <link href="http://opensource.creativecommons.org/blog/entries/cc-platform-toolkit-revamp-2/" />
    <author>
      <name>apdsrocha</name>
    </author>
    <content type="html">&lt;p&gt;Time is really flying! I can hardly believe this is already week 5 as of my internship with CC (I'm part of the Outreachy program for the 2019-2020 round). I've been having a wonderful time working on this project (I'm helping revamp the &lt;a href=&quot;https://creativecommons.org/platform/toolkit/&quot;&gt;Platform Toolkit&lt;/a&gt;) and I'm excited to report on what's been going on for the past couple of weeks.&lt;/p&gt;
&lt;p&gt;Since the holidays got a bit in the way of user testing existing platform implementations, my mentors and I slightly altered the schedule. These past weeks have been dedicated to reworking the content that is currently online (revisiting writing and format) and suggesting an entirely new structure. I've been documenting that process &lt;a href=&quot;https://drive.google.com/open?id=1g7_76zFmgtqq7khb_aBS-l2Wx8tScMgR1NPBO0vOdkM&quot;&gt;here&lt;/a&gt; as I tackle each section.&lt;/p&gt;
&lt;p&gt;What I really loved about this process is the fact that I'm able to see the platform toolkit through a holistic lens: I'm thinking about how the user is currently interacting with this content, how the information could be made more palatable, how that can be achieved visually, and finally, how to do it in a way that won't be impossible to implement.&lt;/p&gt;
&lt;p&gt;I'm excited about the questions and answers that have been coming up during this process. Even though I'm far from delivering a final version, I believe this first rough draft already brings important improvements. My focus has been on diminishing cognitive load. That means taking very dense content and delivering the same amount of information with an approach that steps away from full copy and comes closer to a UI format. I've been learning a lot with each step of this project and I'm eager to make a positive contribution by the end of the internship. Soon enough I'll be checking in again soon to give a new follow up!&lt;/p&gt;
</content>
  </entry>
  <entry xml:base="http://opensource.creativecommons.org/blog/entries/freesound-intro/">
    <title type="text">An Introduction to Freesound</title>
    <id>urn:uuid:9d8021b4-7645-3213-a8ff-ced7633a4488</id>
    <updated>2019-12-19T00:00:00Z</updated>
    <link href="http://opensource.creativecommons.org/blog/entries/freesound-intro/" />
    <author>
      <name>ffont</name>
    </author>
    <content type="html">&lt;h3 id=&quot;about-freesound&quot;&gt;About Freesound&lt;/h3&gt;&lt;p&gt;To the best of our knowledge, &lt;a href=&quot;https://freesound.org&quot;&gt;Freesound&lt;/a&gt; is the biggest website for sharing Creative Commons audio clips in the &lt;em&gt;observable universe&lt;/em&gt;. It was started in 2005 as a research effort of the &lt;a href=&quot;https://www.upf.edu/web/mtg/&quot;&gt;Music Technology Group&lt;/a&gt; in &lt;a href=&quot;https://upf.edu&quot;&gt;Universitat Pompeu Fabra&lt;/a&gt;, Barcelona. The initial goal was to gather a collection of audio clips that could be shared among researchers to carry out computational analysis of sounds and learn about them. Creative Commons licenses had been introduced to the world only a couple of years before, and it seemed a perfect fit for the goals of the Freesound platform. Currently Freesound hosts more than &lt;strong&gt;430k audio clips&lt;/strong&gt; uploaded by more than &lt;strong&gt;20k contributors&lt;/strong&gt;. Freesound sounds have been &lt;strong&gt;downloaded more than 145M times&lt;/strong&gt; by &lt;strong&gt;9M users&lt;/strong&gt; all over the world. It contains all sorts of sounds, from field recordings to music instrument samples, foley, speech and music loops; but not &lt;em&gt;songs&lt;/em&gt; in the traditional sense of &lt;em&gt;finished music compositions&lt;/em&gt;. The aim of Freesound is to provide audio &lt;em&gt;building blocks&lt;/em&gt; to be transformed and combined into other sounds, and reused elsewhere. Here are some nice examples of the variety of sounds to be found in Freesound:&lt;/p&gt;
&lt;div style=&quot;text-align:center;&quot;&gt;
  &lt;iframe frameborder=&quot;0&quot; scrolling=&quot;no&quot; src=&quot;https://freesound.org/embed/sound/iframe/264287/simple/full_size/&quot; style=&quot;width:800px;height:245px;&quot;&gt;&lt;/iframe&gt;

  &lt;iframe frameborder=&quot;0&quot; scrolling=&quot;no&quot; src=&quot;https://freesound.org/embed/sound/iframe/261328/simple/full_size/&quot; style=&quot;width:800px;height:245px;&quot;&gt;&lt;/iframe&gt;

  &lt;iframe frameborder=&quot;0&quot; scrolling=&quot;no&quot; src=&quot;https://freesound.org/embed/sound/iframe/392090/simple/full_size/&quot; style=&quot;width:800px;height:245px;&quot;&gt;&lt;/iframe&gt;

  &lt;iframe frameborder=&quot;0&quot; scrolling=&quot;no&quot; src=&quot;https://freesound.org/embed/sound/iframe/447776/simple/full_size/&quot; style=&quot;width:800px;height:245px;&quot;&gt;&lt;/iframe&gt;

  &lt;iframe frameborder=&quot;0&quot; scrolling=&quot;no&quot; src=&quot;https://freesound.org/embed/sound/iframe/161478/simple/full_size/&quot; style=&quot;width:800px;height:245px;&quot;&gt;&lt;/iframe&gt;

  &lt;iframe frameborder=&quot;0&quot; scrolling=&quot;no&quot; src=&quot;https://freesound.org/embed/sound/iframe/416984/simple/full_size/&quot; style=&quot;width:800px;height:245px;&quot;&gt;&lt;/iframe&gt;
&lt;/div&gt;&lt;p&gt;Freesound has been featured in the Creative Commons blog several times in the past: &lt;a href=&quot;https://creativecommons.org/2005/04/12/overinspaincreatinganonlinecollaborativedatabaseofsounds/&quot;&gt;here&lt;/a&gt;, &lt;a href=&quot;https://creativecommons.org/2005/10/01/freesound/&quot;&gt;here&lt;/a&gt;, &lt;a href=&quot;https://creativecommons.org/2006/07/08/freesoundviaccmixter20kfreesounds/&quot;&gt;here&lt;/a&gt;, &lt;a href=&quot;https://creativecommons.org/2007/01/17/freesound-sample-in-children-of-men/&quot;&gt;here&lt;/a&gt;, &lt;a href=&quot;https://creativecommons.org/2008/03/13/freesound-20/&quot;&gt;here&lt;/a&gt;, &lt;a href=&quot;https://creativecommons.org/2008/09/29/freesoundorg/&quot;&gt;here&lt;/a&gt; and &lt;a href=&quot;https://creativecommons.org/2011/09/12/celebrating-freesound-2-0-retiring-sampling-licenses/&quot;&gt;here&lt;/a&gt;. Also you'll find plenty of information about Freesound, statistics and the like in the &lt;a href=&quot;https://blog.freesound.org&quot;&gt;Freesound Blog&lt;/a&gt;.&lt;/p&gt;
&lt;p style=&quot;text-align:center;&quot;&gt;&lt;img src=&quot;freesound_logo.png&quot; width=1000px/&gt;&lt;/p&gt;&lt;h3 id=&quot;the-freesound-api&quot;&gt;The Freesound API&lt;/h3&gt;&lt;p&gt;In 2011 a web API endpoint was added to Freesound and since then it has been evolving and incorporating new functionalities together with the site. The current version of the API, &lt;strong&gt;Freesound APIv2&lt;/strong&gt;, can be used by 3rd party developers and researchers to programatically search sounds in Freesound, filter results (including CC license), download audio analysis and the sounds themselves. It can also be used to upload new sounds, describe, rate and comment existing ones. In summary, it provides an alternative interface to that of the web browser so that &lt;strong&gt;Freesound content can be easily integrated in all sorts of projects&lt;/strong&gt; outside Freesound itself.&lt;/p&gt;
&lt;p&gt;The Freesound API is a RESTful API that can be used similarly to other web APIs. To facilitate access to the API, we provide clients in &lt;a href=&quot;/blog/entries/freesound-intro/(https://github.com/mtg/freesound-python&quot;&gt;Python&lt;/a&gt;), &lt;a href=&quot;https://github.com/g-roma/freesound.js&quot;&gt;Javascript&lt;/a&gt; and &lt;a href=&quot;https://github.com/mtg/freesound-juce&quot;&gt;Juce (C++)&lt;/a&gt; frameworks, but there are also &lt;a href=&quot;https://freesound.org/docs/api/client_libs.html&quot;&gt;community-developed clients&lt;/a&gt; for other programming languages including Max/MSP, Perl, Supercollider, Objective-C, Scala and QT (C++). As an example, using the Python Freesound API client a search for &lt;em&gt;dog&lt;/em&gt; sounds would look like this:&lt;/p&gt;
&lt;div class=&quot;hll&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;freesound&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;client&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;freesound&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;FreesoundClient&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;client&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;set_token&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;&amp;lt;Your API key obtained from https://freesound.org/apiv2/apply&amp;gt;&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&amp;#39;token&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;results&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;client&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;text_search&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;query&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;dog&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;The query could be further refined and, for instance, include only dog sounds which are shorter than 5 seconds, with a high average rating, and in CC0 license like this:&lt;/p&gt;
&lt;div class=&quot;hll&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;results&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;client&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;text_search&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;query&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;dog&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;filter&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;duration:[0.0 TO 15.0] avg_rating:[4.5 TO 5.0] license:&amp;quot;Creative Commons 0&amp;quot;&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Search results can also be easily downloaded:&lt;/p&gt;
&lt;div class=&quot;hll&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;results&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;retrieve_preview&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;/direcotry/to/save/the/file/&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;One of the features that make the Freesound API unique is the ability to retrieve and filter sounds using &lt;em&gt;audio features&lt;/em&gt; extracted with a &lt;strong&gt;computational analysis of the sounds uploaded to Freesound&lt;/strong&gt;. For that purpose we use a powerful open source audio analysis library called &lt;a href=&quot;https://essentia.upf.edu/&quot;&gt;Essentia&lt;/a&gt; that is also developed at the Music Technology Group. This allows the implementation of features like audio similarity search (i.e. searching for sounds given another sound as a &lt;em&gt;target&lt;/em&gt;), or advanced exploration interfaces in which audio clips are displayed in a space according to some automtically estimated acoustic properties (see the &lt;em&gt;Freesound Explorer&lt;/em&gt; example below).&lt;/p&gt;
&lt;p&gt;The Freesound API is a very powerful tool to facilitate the reuse of Freesound content. You can find more information about the API and its features in the &lt;a href=&quot;https://freesound.org/docs/api/&quot;&gt;Freesound API documentation&lt;/a&gt;. The Freesound API is currently being used by companies like Acoustica, AudioGaming, Google, Mozilla, Soundly, Spotify, Waves Audio, Wolfram, and others.&lt;/p&gt;
&lt;h3 id=&quot;spreading-cc-content-in-the-world&quot;&gt;Spreading CC content in the world&lt;/h3&gt;&lt;p&gt;The audio content hosted in Freesound has a second life outside the website. It is very hard to track all the projects in which Freesound content is used, but with 50k unique visits per day, the accumulated millions and millions of download records and the integration with 3rd party applications, it becomes clear that &lt;strong&gt;Freesound is spreading Creative Commons audio virtually everywhere&lt;/strong&gt;. Some users choose to use the Freesound forums to &lt;a href=&quot;https://freesound.org/forum/your-work-made-with-freesounds/&quot;&gt;explain the work they do using Freesound sounds&lt;/a&gt;, including music, videogames, animations, movies, theater plays, education, etc. Unfortunately this is just a small minority of users. To try to keep track of some of the applications, research proejcts and other initiatives that use Freesound content, the &lt;a href=&quot;https://labs.freesound.org&quot;&gt;Freesound Labs&lt;/a&gt; platform was introduced back in 2015. Currently it lists more than 40 projects and over 50 research papers using Freesound data. Some of these projects include &lt;strong&gt;CTAG's Str√§mpler&lt;/strong&gt;, an eurorack sample streaming and sound synthesis module; &lt;strong&gt;Spotify's Sountrap&lt;/strong&gt;, an online DAW with direct integration of Freesound search; &lt;strong&gt;Le Sound's AudioTexture&lt;/strong&gt;, a granular synthetizer that transforms Freesound clips; and &lt;strong&gt;Freesound Explorer&lt;/strong&gt;, a visual interface for exploring Freesound in a 2-dimensional space and create music at the same time.&lt;/p&gt;
&lt;p style=&quot;text-align:center;&quot;&gt;&lt;img src=&quot;strampler.png&quot; width=500px/&gt;&lt;br&gt;
&lt;a href=&quot;https://www.creative-technologies.de/ctag-strampler-a-eurorack-sample-streaming-and-sound-synthesis-module/&quot;&gt;Str√§mpler&lt;/a&gt; (see &lt;a href=&quot;https://www.youtube.com/watch?v=zmj8tKPHV8g&quot;&gt;video here&lt;/a&gt;)&lt;/p&gt;&lt;p style=&quot;text-align:center;&quot;&gt;&lt;img src=&quot;soundtrap.png&quot; width=500px/&gt;&lt;br&gt;
&lt;a href=&quot;https://www.soundtrap.com&quot;&gt;Soundtrap&lt;/a&gt;&lt;/p&gt;&lt;p style=&quot;text-align:center;&quot;&gt;&lt;img src=&quot;audiotexturefree.png&quot; width=500px/&gt;&lt;br&gt;
&lt;a href=&quot;https://lesound.io/product/audiotexture-free/&quot;&gt;Audio Texture&lt;/a&gt; (see &lt;a href=&quot;https://www.youtube.com/watch?v=pv1ozaJ3K2o&quot;&gt;video here&lt;/a&gt;)&lt;/p&gt;&lt;p style=&quot;text-align:center;&quot;&gt;&lt;img src=&quot;freesound_explorer2.png&quot; width=500px/&gt;&lt;br&gt;
&lt;a href=&quot;http://labs.freesound.org/fse/&quot;&gt;Freesound Explorer&lt;/a&gt;&lt;/p&gt;&lt;h3 id=&quot;under-the-hood&quot;&gt;Under the hood&lt;/h3&gt;&lt;p&gt;Both the Freesound website and API run on a modern technology stack which was built with high load and scalability in mind. Below is a diagram with the main blocks of the architecture. The main website consists of a &lt;a href=&quot;https://www.djangoproject.com&quot;&gt;Django&lt;/a&gt; application and HTML/CSS/JS frontend connected to a &lt;a href=&quot;https://www.postgresql.org&quot;&gt;PostgreSQL&lt;/a&gt; database. This implements sound browsing and basic social interaction features (forum, sound comments, sound ratings, private messaging, etc.). Text indexing is supported by an Apache &lt;a href=&quot;https://lucene.apache.org/solr/&quot;&gt;Solr&lt;/a&gt; server including text descriptions and tags, which allows for sophisticated sound text queries using the Solr query syntax. A distributed architecture is used for processing incoming sounds, producing compressed previews and waveform/spectrogram images (using Python's &lt;a href=&quot;https://pillow.readthedocs.io/en/stable/&quot;&gt;Pillow&lt;/a&gt; package), as well as for audio feature extraction. Feature extraction and the similarity search service are supported with the abovementioned Essentia library. Finally, Freesound uses &lt;a href=&quot;https://www.nginx.com&quot;&gt;NGINX&lt;/a&gt; webserver to serve the Django app and static content in the appservers, and &lt;a href=&quot;http://www.haproxy.org&quot;&gt;HAProxy&lt;/a&gt; loadbalancers to balance the load of incoming requests across the appservers.&lt;/p&gt;
&lt;p style=&quot;text-align:center;&quot;&gt;&lt;img src=&quot;diagram.png&quot; width=600px/&gt;&lt;/p&gt;&lt;p&gt;The code of the Freesound website is &lt;strong&gt;open source&lt;/strong&gt;, and all development happens in our &lt;a href=&quot;https://github.com/mtg/freesound/&quot;&gt;public source code repository&lt;/a&gt;. External contributions are welcome so if you want to participate don't hesitate to get in touch with us. Of course if you're not interested in devleopment but still want to contribute to Freesound you can upload sounds or &lt;a href=&quot;https://freesound.org/donations/donate/&quot;&gt;consider making a donation&lt;/a&gt; :)&lt;/p&gt;
</content>
  </entry>
  <entry xml:base="http://opensource.creativecommons.org/blog/entries/cc-platform-toolkit-revamp/">
    <title type="text">CC Platform Toolkit Revamp</title>
    <id>urn:uuid:076e809b-c084-3977-8ca5-7bbd76064c50</id>
    <updated>2019-12-16T00:00:00Z</updated>
    <link href="http://opensource.creativecommons.org/blog/entries/cc-platform-toolkit-revamp/" />
    <author>
      <name>apdsrocha</name>
    </author>
    <content type="html">&lt;p&gt;I've just finished my second week as an intern for CC (part of the Outreachy program 2019-2020 round), helping revamp the &lt;a href=&quot;https://creativecommons.org/platform/toolkit/&quot;&gt;Platform Toolkit&lt;/a&gt; and it's been a great learning experience so far.&lt;/p&gt;
&lt;p&gt;Before we get into what I've been doing, I wanted to quickly explain why I think this is such a cool project - maybe you'll think it's cool too and want to collaborate as well at some point :) See, the better this toolkit is, the more we increase our chances of having really great, user-friendly implementations in partner platforms. Providing a helpful toolkit is one of the ways we can guide users towards finding better information, understanding licenses, and making better use of content -- not to mention that getting this right ensures we reach a ton of people.&lt;/p&gt;
&lt;p&gt;So in order to start, we began by taking a step back and  studying in detail how platforms are addressing licenses today. These first weeks I went through a lot of user flows, seeing what works, and what were possible points to address and improve. The greatest challenge so far was trying to break down what were good UX/UI practices that could benefit any platform -- regardless of the type of content or current layout. Once I analyzed the material through this point of view, it was easier to filter the kind of information that must be addressed in our new version of the toolkit. This first study also gave me a lot of material to begin thinking about our next step: user research. It's important to find out how much of this process is intuitive to users and what flies under the radar -- having more answers is crucial so that we can be assertive when making suggestions.&lt;/p&gt;
&lt;p&gt;I'll keep checking in every two weeks with updates on how this project is going. Trust me, there's still a lot of really exciting tasks to be done in the following months :)&lt;/p&gt;
</content>
  </entry>
  <entry xml:base="http://opensource.creativecommons.org/blog/entries/aws_grant/">
    <title type="text">Creative Commons Awarded AWS Imagine Grant</title>
    <id>urn:uuid:4d147a26-5b4d-3f51-a551-0df926143964</id>
    <updated>2019-12-12T00:00:00Z</updated>
    <link href="http://opensource.creativecommons.org/blog/entries/aws_grant/" />
    <author>
      <name>aldenpage</name>
    </author>
    <content type="html">&lt;p&gt;Creative Commons was recently awarded a $125,000 AWS Imagine grant, which will cover infrastructure costs associated with some of the key features we intend to add to CC Search in 2020. In particular, some of the key outcomes we hope to have achieved at the end of the year are:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Machine-generated tags using cutting edge computer vision technology produced by Amazon Rekognition. In addition to surfacing metadata-sparse images in our catalog, we may be able to offer features like filtering by artistic medium (painting, photo, pencil sketch, etc).&lt;/li&gt;
&lt;li&gt;Produce CC-hosted thumbnails for every image instead of relying on third-party images, which are often suffer from unreliable availability, are resistant to embedding, or are otherwise too low quality for our purposes.&lt;/li&gt;
&lt;li&gt;Acquire knowledge of other features of images, such as their resolution or filesize. Since we often scrape links to images without any further processing, we rely on the data upstream providers give us, which is often missing this information.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Because cutting-edge computer vision typically requires specialized hardware and expertise, outsourcing this task to AWS ends up being economical in comparison to implementing it ourselves. Nonetheless, due to the volume of images we need to classify, this will take up a significant amount of the grant budget; we intend to hand-pick which data sources get tagged in order to make the best use of the resources available to us.&lt;/p&gt;
&lt;p&gt;When we‚Äôre discussing computer vision, generating thumbnails and collecting resolution sounds  comparatively mundane, but it is actually a significant technical challenge that will require a serious investment in infrastructure as well. For one thing, in order to feed images to Rekognition, we need to have a copy of the image in the first place, which you may be surprised to find that we currently do not! All of our content is hosted by the original third party sources and embedded in the search results page. Sometimes, we will sneakily proxy images through our own infrastructure (in cases where the source does not offer HTTPS or an appropriately sized thumbnail), but in most instances, we have to place complete trust in what the source makes available to us. This has lead to problems with availability. Nobody likes it when the images in their search results are inexplicably broken because a third-party datacenter is having issues. Using the funds from the grant, we will at the very least be able to generate thumbnails just before they are served to the user, and possibly even bulk thumbnail our catalog of 325 million images. That‚Äôs a huge task - there may very well be petabytes of image data to scrape.&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;In order to thumbnail and label our entire catalog, we are going to need to build some additional infrastructure. For the thumbnailing component, we intend to use Scrapy Cluster (composed of an MSK queue, an Elasticache instance, some utility EC2 instances for controlling the cluster and communicating between components, and a large cluster of EC2 instances running web scrapers) to build a distributed system for rapidly downloading and resizing images. A controller instance will feed image URLs into the job queue. Once the destination image URLs have been fed to the cluster, Scrapy Cluster dispatches the URLs to a scalable group of crawler bots, which fetch the image, collect some metadata (such as dimensions), resize the images, and then upload the thumbnails to S3 while pushing the new image metadata back to our image database on RDS. We will then be able to start serving up the thumbnails to our end users. While we initially plan to only use this cluster for producing thumbnails, we expect it could be valuable for discovering and indexing additional CC licensed content in the future. See below for a visualization of the distributed scraping and thumbnailing system.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Scraping and thumbnailing system:&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/blog/entries/aws_grant/scraping_cluster.png&quot; alt=&quot;Image scraping and thumbnailing system&quot;&gt;&lt;/p&gt;
&lt;p&gt;Image recognition pipeline:&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/blog/entries/aws_grant/object_recognition.jpg&quot; alt=&quot;Object recognition pipeline&quot;&gt;&lt;/p&gt;
</content>
  </entry>
  <entry xml:base="http://opensource.creativecommons.org/blog/entries/building-distributed-indexer/">
    <title type="text">Building a Distributed Indexer for a Search Engine</title>
    <id>urn:uuid:707d616c-8953-3a17-925b-02567a4c9516</id>
    <updated>2019-12-11T00:00:00Z</updated>
    <link href="http://opensource.creativecommons.org/blog/entries/building-distributed-indexer/" />
    <author>
      <name>aldenpage</name>
    </author>
    <content type="html">&lt;p&gt;With &lt;a href=&quot;https://search.creativecommons.org&quot;&gt;CC Search&lt;/a&gt;, we want to make it possible to search all of the estimated 1.6 billion Creative Commons works on the internet. In order to make it possible for thousands of people to search billions of records in a reasonable period of time, we have to build a big inverted index (a data structure similar to the index in the back of a textbook), which allows very fast lookups of documents related to the user‚Äôs search query. To populate this index, we have to build a large database of Creative Commons works and then replicate it to our search index, which is powered by Elasticsearch.&lt;/p&gt;
&lt;p&gt;It turns out that, once your search index contains more than just a few million documents, maintaining the index is a non-trivial problem. Some of the concerns we had for our implementation:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;p&gt;How often do we update the index as new Creative Commons licensed works are discovered? What if we need to make a change to every single document in the index, such as when we modify our search algorithm?&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;How can we rebuild the entire index quickly?&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Can we rebuild the index without users noticing degraded search performance or, worse yet, not being able to serve results while reindexing?&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Can we make this a completely automated process and avoid further operations tedium?&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;There is no off-the-shelf solution for this, particularly when performance is of concern; anybody in the business of writing a large search engine is going to have to write a custom indexer at some point.&lt;/p&gt;
&lt;p&gt;In the end, given the size of our dataset was in the range of a few hundred gigabytes, it turned out that bulk reindexing every week would be good enough for our purposes; our current upstream data sources don‚Äôt update much more frequently than that anyway. We wrote a program that automated the procedure of refreshing our database with the latest upstream data and pushing it to Elasticsearch, all completely online and without negative impact to production performance. A single server was responsible for moving all of our image data around to the appropriate data stores and juggling temporary tables and indices to hide the indexing process from the end user. I wrote a little bit about the design of this piece in &lt;a href=&quot;https://opensource.creativecommons.org/blog/entries/searching-300-million/&quot;&gt;a previous blog post&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/blog/entries/building-distributed-indexer/one_server_indexing.png&quot; alt=&quot;Ingestion Server architecture&quot;&gt;&lt;/p&gt;
&lt;p&gt;At this point, we could reindex all 325 million images in about 1.5 days. That‚Äôs not exactly fast, but it could be scheduled to run over the weekend in a ‚Äúset and forget‚Äù manner. That was good enough for about a year.&lt;/p&gt;
&lt;p&gt;However, in practice, we need to refresh our data more than once a week. For instance, if something went wrong with the indexing job (as often does while new search features are being tested on real data), we would have to start the process all over again, which means that the cost of even a small bug in indexing logic can dramatically lengthen the time it takes to deliver a new feature. More importantly, we wanted to iterate on our search algorithm, which meant we had to reindex our data quite frequently. We hoped to avoid this by performing tests on mock data or smaller subsets of the real data, but this ends up being only weakly correlated with search quality in the complete production dataset (in my experience, search result quality is inseparable from the quality of the underlying data). It became clear that indexing performance was slowing down the software development lifecycle, and further optimization was needed.&lt;/p&gt;
&lt;p&gt;Our single-node indexer had a throughput of about 2,500 records per second, which is far below Elasticsearch‚Äôs advertised indexing rates (although there are &lt;a href=&quot;https://www.elastic.co/guide/en/elasticsearch/reference/current/tune-for-indexing-speed.html&quot;&gt;numerous factors unique to each workload&lt;/a&gt; that affect indexing speed). Further profiling revealed that in our case we were likely bottlenecked by our Python code rather than I/O to the cluster: writing to the search index was reasonably fast (7,000 per second), but the indexer spent a ton of CPU time on deserializing records pulled in from database chunks, accounting for 2/3rds of the indexing process. A possible solution would be rewriting the indexer in a faster language, but there are a lot of drawbacks to this approach in that rewrites are costly, the likely performance improvement is not foreseeable, and we had already sunk plenty of time into writing the logic in Python. Instead, we decided to distribute the existing process across multiple machines, which would allow us to reuse existing code and scale up to an arbitrary number of nodes as our indexing performance requirements inevitably increase with the size of our data set.&lt;/p&gt;
&lt;p&gt;A few weeks of coding later, we had a solution in place that increased throughput to 15,000 records per second, or a 6-fold increase in performance, by splitting the work across 6 nodes. Indexing responsibilities are offloaded from Ingestion Server, which instead acts as a central point for coordinating the multiple indexing workers through a simple RPC API.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/blog/entries/building-distributed-indexer/indexing1.jpg&quot; alt=&quot;Partitioning the data&quot;&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/blog/entries/building-distributed-indexer/indexing2.jpg&quot; alt=&quot;Simultaneous indexing&quot;&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/blog/entries/building-distributed-indexer/indexing3.jpg&quot; alt=&quot;Notification and promotion&quot;&gt;&lt;/p&gt;
&lt;p&gt;There appears to be ample room for us to increase the node count before we become I/O bound by the database or Elasticsearch. I‚Äôm assuming doubling our node count would approximately halve our indexing time. Eventually, if our search index becomes as big as we anticipate it will, we are going to have to make the indexer workers better utilize the underlying hardware somehow, perhaps by rewriting the ‚Äúhot‚Äù parts in a lower level language than Python, but that seems to be a distant concern as of today. Additionally, since workers only run when indexing is in progress, the cost of maintaining these additional nodes is low; it costs about $10 in cloud time to perform a full reindex of all 325MM images.&lt;/p&gt;
</content>
  </entry>
  <entry xml:base="http://opensource.creativecommons.org/blog/entries/2019-11-25-empowering-collaboration/">
    <title type="text">Empowering Collaboration in the Commons</title>
    <id>urn:uuid:c9d7d6f2-545c-3adb-95b7-c51cdee22ed4</id>
    <updated>2019-11-25T00:00:00Z</updated>
    <link href="http://opensource.creativecommons.org/blog/entries/2019-11-25-empowering-collaboration/" />
    <author>
      <name>TimidRobot</name>
    </author>
    <content type="html">&lt;p&gt;In the past few months I have been privileged to attend &lt;a href=&quot;https://wikimania.wikimedia.org/wiki/2019:Program&quot;&gt;Wikimania
2019&lt;/a&gt; and the Google Summer of Code &lt;a href=&quot;https://sites.google.com/view/gsoc-mentorsummit2019/home&quot;&gt;2019 Mentor
Summit&lt;/a&gt;. At these events I was overwhelmed with the amount of
care and effort people are putting into their projects and communities.&lt;/p&gt;
&lt;p&gt;At Wikimania 2019, I was impressed with how much overlap there is between the
Creative Commons and Wikimedia communities. Both communities are actively
engaged in expanding the content and participation in the commons--in the
collection and communities empowered by open content. I have a lot of hope in
what existing and future collaborations will allow. At the conference, I got to
see just the tip of the iceberg representing volunteers‚Äô work across the globe.
I hope we at Creative Commons can continue to keep the demands of our daily
workloads in perspective and increase collaboration with the global effort.&lt;/p&gt;
&lt;p&gt;At the GSoC 2019 Mentor Summit I was able to attend a good number of sessions
on increasing and maintaining participation. Based on the session discussions
and the work already being done by other organizations, I expect we‚Äôll pursue
the following strategies:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Improved support for first timers--people who are engaging with code
repositories for the first time&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Improve tagging of issues&lt;/li&gt;
&lt;li&gt;Dedicated documentation&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Improve support for GSoC and Outreachy program applicants&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Provide application templates&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Participate in social media networks to actively recruit groups who are
underrepresented in FOSS (free and open source software)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;Collect anonymous demographic data &lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;A couple of organization examples:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Public Lab: &lt;a href=&quot;https://code.publiclab.org/&quot;&gt;Community toolbox&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Python Software Foundation: &lt;a href=&quot;https://python-gsoc.org/index.html&quot;&gt;Python GSoC ‚Äì Home&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Thank you to the community and the work you‚Äôre doing &amp;lt;3&lt;/p&gt;
</content>
  </entry>
  <entry xml:base="http://opensource.creativecommons.org/blog/entries/ssr-ccsearch/">
    <title type="text">Server Side Rendering with Vue.JS on CC Search</title>
    <id>urn:uuid:1dcdb6c2-1f17-364b-8ec0-9454ba69a338</id>
    <updated>2019-11-01T00:00:00Z</updated>
    <link href="http://opensource.creativecommons.org/blog/entries/ssr-ccsearch/" />
    <author>
      <name>brenoferreira</name>
    </author>
    <content type="html">&lt;p&gt;The frontend of CC Search is built with Vue.JS, which is a Javascript library for managing and rendering DOM elements in the browser, similar to React and Angular. But, as it is usually the case with applications built with those libraries, the application was rendered completely on the users' browser. It means that when users loaded CC Search, the server would send a blank HTML page and some Javascript files that would be downloaded by the user. Only once those JS assets were loaded and parsed, would the rendering begin.&lt;/p&gt;
&lt;p&gt;While easier to implement initially, when we needed to ship the initial versions of CC Search faster to validate our ideas, this approach has some significant disadvantages:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;p&gt;Performance: The page initially loaded doesn't contain any visual elements. The user still has to download a few KBs of JS, which have to be parsed and interpreted by the browser before anything is rendered. On faster connections and devices, this performance hit can be negligible, but on slower and older devices and slow mobile networks, this can degrade performance significantly.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Empty HTML page: When the initial HTML sent by the server is empty, meaning no visual elements, any internet bots that parse a page HTML wouldn't work properly, that is: SEO, social media websites (when users share a link to CC Search on Twitter or Facebook, those nice previews wouldn't work), the Web Archive, etc..&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;So on July 26th we deployed our first release of CC Search with Server Side Rendering. You can see the work that went into it on this &lt;a href=&quot;https://github.com/creativecommons/cccatalog-frontend/pull/411&quot;&gt;Pull Request on Github&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;My goal with this blog post will be to explain some of the challenges that we faced while both coding the SSR support on the VueJS codebase and also the operations side with deployment and maintenance.&lt;/p&gt;
&lt;p&gt;If you are interested in learning how to do SSR with VueJS, I highly recommend reading its &lt;a href=&quot;https://ssr.vuejs.org/&quot;&gt;documentation first&lt;/a&gt;, as it provides a really helpful and comprehensive getting started guide.&lt;/p&gt;
&lt;h2 id=&quot;initial-coding-challenges&quot;&gt;Initial coding challenges&lt;/h2&gt;&lt;p&gt;Browser specific APIs&lt;/p&gt;
&lt;p&gt;A few modules and components of CC Search have dependencies on browser specific APIs, such as the &lt;code&gt;window&lt;/code&gt; and &lt;code&gt;document&lt;/code&gt; objects. This causes a problem with SSR because on the server, the Vue application is running on a Node.JS environment where those APIs don't exist. Therefore we need to do a couple of things to remove all possible calls to these APIs on the server. We adopted a few different strategies depending on each case.&lt;/p&gt;
&lt;p&gt;On some cases, a simple check for undefined values is sufficient, for example:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;const queryParams = !(typeof window === 'undefined') ? window.location.search : '';
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;em&gt;link to change diff &lt;a href=&quot;https://github.com/creativecommons/cccatalog-frontend/pull/411/files#diff-e3b1ca4ad5a207c170c97a435b3d1ff3L15&quot;&gt;here&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;There were also cases of components that accessed browser APIs directly on, for example, &lt;code&gt;computed&lt;/code&gt; values. Since those values are eagerly evaluated during render of a component, it would break on server rendering.&lt;/p&gt;
&lt;p&gt;The solution adopted was to set those values on the &lt;code&gt;mounted&lt;/code&gt; lifecycle method, which runs exclusively on the browser, not on the server. For example:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;mounted() {
  // for SSR, sets the value with window.location, which is only available on client
  this.shareURL = window.location.href;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;em&gt;link to change diff &lt;a href=&quot;https://github.com/creativecommons/cccatalog-frontend/pull/411/files#diff-f987cb63f02cb3471ab3cfae238746f7R37&quot;&gt;here&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;But there was a more complicated case in which we had dependencies to visual components which in turn depended on these browser APIs to render. One in particular was the image search result grid, which is a responsive grid layout that fits all images nicely on whatever screen size the users have.&lt;/p&gt;
&lt;p&gt;One of the cases, we had a dependency tree that looked like this:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;- BrowsePage
  - SearchGrid
    - GridLayoutComponent // specific component with browser API render dependency
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;A few other page components also depended on this &lt;code&gt;GridLayoutComponent&lt;/code&gt; component. Our solution was to split the higher level components into server and client versions. The browser version would render the search grid, and the server version wouldn't.&lt;/p&gt;
&lt;p&gt;You can an example of this case with the client version of the component &lt;a href=&quot;https://github.com/creativecommons/cccatalog-frontend/pull/411/commits/d3e05c01262d4fbc5bed1eceb1c256fc8da9ea80#diff-15c47fe052b8e07589e6cd5c7ce126fe&quot;&gt;here&lt;/a&gt; and the server version &lt;a href=&quot;https://github.com/creativecommons/cccatalog-frontend/pull/411/commits/d3e05c01262d4fbc5bed1eceb1c256fc8da9ea80#diff-9bfa3295d81a84c0fee1b5af98992561&quot;&gt;here&lt;/a&gt;. We used a mixin to provide the component interaction logic &lt;a href=&quot;https://github.com/creativecommons/cccatalog-frontend/pull/411/commits/d3e05c01262d4fbc5bed1eceb1c256fc8da9ea80#diff-b4102772ceac63ff8d35545a2d003200&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Since we had different components, we also needed different routers that mapped to the &lt;a href=&quot;https://github.com/creativecommons/cccatalog-frontend/pull/411/files#diff-96a7306e1ed8bbbc4982aac42b5ef8df&quot;&gt;server&lt;/a&gt; and &lt;a href=&quot;https://github.com/creativecommons/cccatalog-frontend/pull/411/files#diff-9b23694ae94e6ff902037f3d79772bae&quot;&gt;client&lt;/a&gt; components.&lt;/p&gt;
&lt;h2 id=&quot;deployment&quot;&gt;Deployment&lt;/h2&gt;&lt;p&gt;One thing we did, and still do, is build the assets for both server and client rendering. One reason is that we need both anyways, because on the client we need to do something called &lt;a href=&quot;https://ssr.vuejs.org/guide/hydration.html&quot;&gt;client side hydration&lt;/a&gt;, and also because if there's a problem on the server renderer that breaks our production environment, we can easily revert back to the old way of serving an empty HTML page and do client side rendering and keep CC Search up. We had to do that on the first few days after the initial deployment when we identified a few problems. I'll cover some of them below.&lt;/p&gt;
&lt;h2 id=&quot;optimizations&quot;&gt;Optimizations&lt;/h2&gt;&lt;h3 id=&quot;micro-cache&quot;&gt;Micro cache&lt;/h3&gt;&lt;p&gt;Soon after we deployed the initial release of SSR, we noticed that our Node servers were sometimes crashing, for memory exhaustion reasons, or sometimes taking too long to respond due to GC running. It seems that rendering Vue apps has a &lt;a href=&quot;https://ssr.vuejs.org/guide/caching.html#page-level-caching&quot;&gt;high memory footprint from components and their Virtual DOM Nodes&lt;/a&gt;. Because of that, we decided to adopt a micro-caching of every server response, as you can see &lt;a href=&quot;https://github.com/creativecommons/cccatalog-frontend/pull/475/commits/aa5ee97101d38443416ef19a954dff63031e293a&quot;&gt;here&lt;/a&gt;. Important caveat: no CC Search page has user specific content. They all serve the same content, no matter which user requests it. So that makes it trivial to cache the responses, since the response never changes for individual users. If that were the case, we either wouldn't be able to cache the response or only cache some request responses but not others.&lt;/p&gt;
&lt;p&gt;After implementing this cache, we saw that the memory consumption dropped dramatically and response times were now constant of a few milliseconds. Node wasn't crashing because it ran out of memory and GC wasn't being triggered as much lowering response times.&lt;/p&gt;
&lt;h3 id=&quot;not-loading-data-twice&quot;&gt;Not loading data twice&lt;/h3&gt;&lt;p&gt;Another optimization was to not repeat requests, which were made on the server, again on the client.
One example is the &lt;a href=&quot;https://ccsearch.creativecommons.org/photos/df2e7f75-7fe9-457b-a58f-edc1833a1ed8&quot;&gt;image details page&lt;/a&gt;. The image can be loaded both on the server and the client, but we don't want the user to request the image data if it was already loaded on the server.&lt;/p&gt;
&lt;p&gt;We did this by using the &lt;code&gt;serverPrefetch&lt;/code&gt; method to load the data on the server, but on the client, in the &lt;code&gt;mounted&lt;/code&gt; method, we check if the data isn't already available before making the request. You can see how that works &lt;a href=&quot;https://github.com/creativecommons/cccatalog-frontend/pull/411/files#diff-e33cf6c2e6f63a3ac958ac500eeabcaaR87&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id=&quot;future-improvements&quot;&gt;Future improvements&lt;/h2&gt;&lt;p&gt;As said before, we have a dependency on a component that uses browser APIs which doesn't work on the server side. That dependency is &lt;a href=&quot;https://github.com/shershen08/vue-masonry&quot;&gt;Masonry Layout&lt;/a&gt;. And because of that, we had to split components and router into server and client versions.&lt;/p&gt;
&lt;p&gt;To remove that complexity, we will probably try to use a pure-CSS approach to generate the responsive grid, as described in &lt;a href=&quot;https://github.com/creativecommons/cccatalog-frontend/issues/489&quot;&gt;this issue on Github&lt;/a&gt;. If that doesn't work, we'll use something like &lt;a href=&quot;https://github.com/egoist/vue-client-only&quot;&gt;vue-client-only&lt;/a&gt;.&lt;/p&gt;
</content>
  </entry>
  <entry xml:base="http://opensource.creativecommons.org/blog/entries/2019-09-25-ccgn-redesign/">
    <title type="text">Revamping the Creative Commons Global Network website</title>
    <id>urn:uuid:f7cf9cf1-939f-397e-981f-87ad4e9c50d5</id>
    <updated>2019-09-25T00:00:00Z</updated>
    <link href="http://opensource.creativecommons.org/blog/entries/2019-09-25-ccgn-redesign/" />
    <author>
      <name>hugosolar</name>
    </author>
    <content type="html">&lt;p&gt;The &lt;a href=&quot;https://network.creativecommons.org&quot;&gt;CC Global Network&lt;/a&gt; website is the face of our global community; it is the home for a community of advocates, activists, scholars, artists, and users working to strengthen the Commons worldwide.
One of our organizational goals regarding the global network is to ‚Äúcreate value for members, toward impact at global scale‚Äù and that‚Äôs why we plan on redesigning the Global Network website.&lt;/p&gt;
&lt;h2 id=&quot;increase-value-for-members&quot;&gt;Increase value for members&lt;/h2&gt;&lt;p&gt;When we think of a website focused on members and their possible needs, we have to think about how different users interact with the website. We established three differents users/personas:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;em&gt;Not logged in users:&lt;/em&gt; users looking for global network general information or how to begin the sign up process&lt;/li&gt;
&lt;li&gt;&lt;em&gt;Logged in but not approved yet&lt;/em&gt;: users looking for information about their membership approval status&lt;/li&gt;
&lt;li&gt;&lt;em&gt;Logged in and approved members&lt;/em&gt;: users utilizing the site‚Äôs search function and contacting other members&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Keeping this in mind, three differents homepages were designed according to each identified profile.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/blog/entries/2019-09-25-ccgn-redesign/blog-ccgn-home.png&quot; alt=&quot;CCGN differents homepages&quot;&gt;&lt;/p&gt;
&lt;h2 id=&quot;improved-user-search&quot;&gt;Improved user search&lt;/h2&gt;&lt;p&gt;We listened to the community feedback and developed a major revamp of the member section. We improved the member list and the search section by adding useful filters to help identify specific people or groups of people based on a range of factors, such as nationality or language.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/blog/entries/2019-09-25-ccgn-redesign/user-search.png&quot; alt=&quot;User search filters&quot;&gt;&lt;/p&gt;
&lt;h2 id=&quot;member-profiles&quot;&gt;Member profiles&lt;/h2&gt;&lt;p&gt;Member profiles were redesigned to take advantage of the current metadata of users so we can show the information in a better way. In addition, the profile shows more/less information if you are/aren‚Äôt approved as a member.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/blog/entries/2019-09-25-ccgn-redesign/member-profile.png&quot; alt=&quot;Member profile&quot;&gt;&lt;/p&gt;
&lt;h2 id=&quot;chapters-section&quot;&gt;Chapters section&lt;/h2&gt;&lt;p&gt;Giving more visibility for the local chapters‚Äô infrastructure, this entire section was redesigned considering the network‚Äôs global reach and the necessity of easily searching for details and specific chapters. The new interface supports switching between the map and the sortable list.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/blog/entries/2019-09-25-ccgn-redesign/chapters-map.png&quot; alt=&quot;Map from chapters around the world&quot;&gt;
&lt;img src=&quot;/blog/entries/2019-09-25-ccgn-redesign/chapters-list.png&quot; alt=&quot;Chapters list with details&quot;&gt;&lt;/p&gt;
&lt;h2 id=&quot;keeping-forward-the-global-network-website&quot;&gt;Keeping forward the global network website&lt;/h2&gt;&lt;p&gt;This is certainly not the end of our revamp of the CC Global Network website, we're always working on giving the members a better experience by fixing bugs and updating the interface. If you have any feedback, feature request, or bug report please feel free to &lt;a href=&quot;https://github.com/creativecommons/commoners/issues&quot;&gt;open an issue&lt;/a&gt; in the &lt;a href=&quot;https://github.com/creativecommons/commoners&quot;&gt;Commoners repository&lt;/a&gt; on Github or reach out to us on Slack.&lt;/p&gt;
</content>
  </entry>
  <entry xml:base="http://opensource.creativecommons.org/blog/entries/2019-09-11-google-docs-plugin/">
    <title type="text">Creative Commons Google Docs Add-on</title>
    <id>urn:uuid:ba029f48-4750-335c-b171-9d4a4f73f956</id>
    <updated>2019-09-11T00:00:00Z</updated>
    <link href="http://opensource.creativecommons.org/blog/entries/2019-09-11-google-docs-plugin/" />
    <author>
      <name>brandonopened</name>
    </author>
    <content type="html">&lt;p&gt;A few years ago I published a &lt;a href=&quot;https://gsuite.google.com/marketplace/app/creative_commons_license_chooser/803008856330&quot;&gt;Google Docs Add-on that allowed users to insert a Creative Commons license image and link into their Google doc&lt;/a&gt;. Since then it‚Äôs been used thousands of times and I‚Äôve gotten some great feedback from teachers about how nice it is to teach their students about digital literacy.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/blog/entries/2019-09-11-google-docs-plugin/image1.png&quot; alt=&quot;Plugin screenshot 1&quot;&gt;&lt;/p&gt;
&lt;h3 id=&quot;why&quot;&gt;Why&lt;/h3&gt;&lt;p&gt;I created the add-on after inspiration from students in one of the classes I teach at &lt;a href=&quot;http://www.fresno.edu/&quot;&gt;Fresno Pacific University‚Äôs Graduate School of Education&lt;/a&gt;. I was teaching a course on digital literacy, and open licenses and fair use was a large portion of the course.&lt;/p&gt;
&lt;p&gt;To get started, I used the &lt;a href=&quot;https://developers.google.com/apps-script/overview&quot;&gt;templates Google provided about building an addon&lt;/a&gt;, took a look at the html etc on the Creative Commons License Chooser page itself, and eventually got something working! It took a couple of days off and on and mostly was me remembering javascriptI admit I had to pay a guy on Upwork to help clean up the code before I published it because sometimes the chooser would keep selecting hundreds of license images‚Ä¶ of course, this was also before I was a bona fide contributor to the open source project I Product Manage, &lt;a href=&quot;http://www.github.com/opensalt/opensalt&quot;&gt;OpenSALT&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;My hope is that folks are able to normalize the idea of putting a Creative Commons license on their public documents, as well as when &lt;a href=&quot;https://support.google.com/youtube/answer/2797468?hl=en&quot;&gt;uploading creative content to Youtube&lt;/a&gt; etc. Teachers in particular would be served by publishing a license so that if their work shows up unauthorized on &lt;a href=&quot;https://www.edweek.org/ew/articles/2018/12/19/on-teachers-pay-teachers-some-sellers-are.html&quot;&gt;Teachers Pay Teachers without attribution or for commercial purposes&lt;/a&gt;, they have a legal avenue to pursue it to be taken down. Even &lt;a href=&quot;https://creativecommons.org/2015/05/06/medium-embraces-cc-licenses/&quot;&gt;Medium has an option to publish documents with a CC license&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;My nine year teaching career in Fresno Unified School District plus my career in Edtech (OpenEd.com, ACT) have opened my eyes to the need for a more open Web. Creative Commons licenses allow ‚Äòfree‚Äô to not just be free, but able to conform to the five &lt;a href=&quot;https://opencontent.org/definition/&quot;&gt;R‚Äôs of open content&lt;/a&gt;(retained, reused, revised, remixed, and redistributed) and enable greater opportunities for innovation and equity.&lt;/p&gt;
&lt;h3 id=&quot;what&quot;&gt;What&lt;/h3&gt;&lt;p&gt;This month I‚Äôve finally updated it from the old Google Docs add-on store to the Gsuite Marketplace and updated some links. I‚Äôve also updated the &lt;a href=&quot;https://github.com/brandonopened/creativecommons_gdocs&quot;&gt;Github sit&lt;/a&gt;e as the main website for the app and hope to implement some changes based on the work in&lt;a href=&quot;https://github.com/creativecommons/cc-license-chooser&quot;&gt; this Github repo&lt;/a&gt; with an updated license chooser process etc. The add-on has been installed thousands of times and usually has couple of hundred uses a month based on statistics.&lt;/p&gt;
&lt;p&gt;I hope in the future to use an API call to support different languages, and perhaps embed RDF into the Google doc if that is possible to make the license machine-searchable. This is a fun project that is useful and helping teach me more about coding and best practices for open source software.&lt;/p&gt;
&lt;h3 id=&quot;how&quot;&gt;How&lt;/h3&gt;&lt;ol&gt;
&lt;li&gt;In Google Docs, select ‚ÄúGet Add-ons‚Äù &lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;img src=&quot;/blog/entries/2019-09-11-google-docs-plugin/image2.png&quot; alt=&quot;How-to screenshot 1&quot;&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Input Creative Commons and press enter&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;img src=&quot;/blog/entries/2019-09-11-google-docs-plugin/image3.png&quot; alt=&quot;How-to screenshot 2&quot;&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Install and use!&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;img src=&quot;/blog/entries/2019-09-11-google-docs-plugin/image4.png&quot; alt=&quot;How-to screenshot 3&quot;&gt;&lt;/p&gt;
&lt;h4 id=&quot;video-tutorial&quot;&gt;Video tutorial&lt;/h4&gt;&lt;p&gt;&lt;a href=&quot;https://youtu.be/sQZFlNXEVZ4&quot;&gt;A video tutorial is available here&lt;/a&gt; or by clicking on the image below.&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://www.youtube.com/watch?feature=player_embedded&amp;v=sQZFlNXEVZ4
&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://img.youtube.com/vi/sQZFlNXEVZ4/0.jpg&quot; 
alt=&quot;Video tutorial&quot; border=&quot;10&quot; /&gt;&lt;/a&gt;&lt;/p&gt;
</content>
  </entry>
</feed>
